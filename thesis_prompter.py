from __future__ import annotations

import re
from dataclasses import dataclass, field
from typing import List, Optional, Set

from loguru import logger

try:
    from semantic_matcher import SemanticMatcher  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –∫–∞–∫ —Ñ–æ–ª–ª–±—ç–∫
except Exception:  # noqa: BLE001
    SemanticMatcher = None  # type: ignore

try:
    from thesis_judge import GeminiJudge  # –æ—Å–Ω–æ–≤–Ω–æ–π —Å—É–¥—å—è
except Exception:  # noqa: BLE001
    GeminiJudge = None  # type: ignore


def _default_stopwords() -> Set[str]:
    return {
        "–∏",
        "–≤",
        "–≤–æ",
        "–Ω–∞",
        "–Ω–æ",
        "–∞",
        "–∫",
        "–∫–æ",
        "—á—Ç–æ",
        "—ç—Ç–æ",
        "–∫–∞–∫",
        "–∂–µ",
        "–∏–∑",
        "–∑–∞",
        "–¥–ª—è",
        "–ø–æ",
        "—Å",
        "—Å–æ",
        "—É",
        "–º—ã",
        "–≤—ã",
        "–æ–Ω–∏",
        "–æ–Ω",
        "–æ–Ω–∞",
        "–æ–Ω–æ",
        "–∫–æ–≥–¥–∞",
        "–≥–¥–µ",
        "—Ç–∞–º",
        "—Ç—É—Ç",
        "—Ç–æ–≥–¥–∞",
        "—Ç–æ–∂–µ",
        "—Ç–∞–∫",
        "—Ç–∞–∫–∂–µ",
        "–µ—Å–ª–∏",
        "—á—Ç–æ–±—ã",
        "–ø—Ä–∏",
        "–æ—Ç",
        "–¥–æ",
        "–±—ã",
        "–±—É–¥–µ—Ç",
        "–±—É–¥—É",
        "–±—É–¥–µ–º",
        "–µ—Å—Ç—å",
        "–Ω–µ—Ç",
    }


@dataclass
class ThesisPrompter:
    """–ü—Ä–æ—Å—Ç–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–æ–º —Ç–µ–∑–∏—Å–æ–≤ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∏–∑–Ω–µ—Å—ë–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤."""

    theses: List[str]
    match_threshold: float = 0.6
    min_token_len: int = 3
    stopwords: Set[str] = field(default_factory=_default_stopwords)
    enable_semantic: bool = True
    semantic_threshold: float = 0.55
    semantic_model_id: Optional[str] = None
    # Gemini-—Å—É–¥—å—è
    enable_gemini: bool = True
    gemini_min_conf: float = 0.60

    def __post_init__(self) -> None:
        self.theses = [t.strip() for t in self.theses if t and t.strip()]
        self.match_threshold = max(0.0, min(1.0, self.match_threshold))
        self.semantic_threshold = max(0.0, min(1.0, self.semantic_threshold))
        self.gemini_min_conf = max(0.0, min(1.0, self.gemini_min_conf))
        self._index = 0
        self._announced = False
        self._current_tokens: Set[str] = set()
        self._thesis_tokens: List[Set[str]] = [self._extract_tokens(t) for t in self.theses]
        self._current_text: str = ""
        self._dialogue_context: List[tuple[str, str]] = []  # (role, text) - —Ä–æ–ª—å: "—ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä" –∏–ª–∏ "—Å—Ç—É–¥–µ–Ω—Ç"
        # Tracking –¥–ª—è Pro upgrades
        self._pro_snapshots = {}  # thesis -> {"index": int, "context_size": int, "timestamp": float}
        # –°–µ–º–∞–Ω—Ç–∏–∫–∞ (—Ñ–æ–ª–ª–±—ç–∫)
        self._semantic_enabled = bool(self.enable_semantic) and (SemanticMatcher is not None)
        self._semantic_matcher: Optional[SemanticMatcher] = None
        if self._semantic_enabled:
            try:
                self._semantic_matcher = SemanticMatcher(model_id=self.semantic_model_id)  # type: ignore
            except Exception as e:  # noqa: BLE001
                logger.exception(f"SemanticMatcher –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                self._semantic_enabled = False
        # Gemini-—Å—É–¥—å—è (–æ—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å) - –û–¢–ö–õ–Æ–ß–ê–ï–ú Pro –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        self._gemini_enabled = bool(self.enable_gemini) and (GeminiJudge is not None)
        self._gemini_judge: Optional[GeminiJudge] = None
        if self._gemini_enabled:
            try:
                # –£–°–ö–û–†–ï–ù–ò–ï: enable_pro=False - —É–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π Pro –≤—ã–∑–æ–≤ (~500–º—Å —ç–∫–æ–Ω–æ–º–∏–∏)
                self._gemini_judge = GeminiJudge(enable_pro=False)  # type: ignore
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –æ—Ç Pro
                self._gemini_judge.set_upgrade_callback(self._on_pro_upgrade)
            except Exception as e:  # noqa: BLE001
                logger.exception(f"GeminiJudge –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                self._gemini_enabled = False

    def has_pending(self) -> bool:
        return self._index < len(self.theses)

    def need_announce(self) -> bool:
        return self.has_pending() and not self._announced

    def current_text(self) -> Optional[str]:
        if not self.has_pending():
            return None
        return self.theses[self._index]

    def mark_announced(self) -> None:
        if self.has_pending():
            self._announced = True

    def reset_announcement(self) -> None:
        if self.has_pending():
            self._announced = False

    def consume_transcript(self, transcript: str, role: str = "—Å—Ç—É–¥–µ–Ω—Ç") -> bool:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–ø–ª–∏–∫—É –¥–∏–∞–ª–æ–≥–∞.
        role: "—Å—Ç—É–¥–µ–Ω—Ç" (–º–æ–π –æ—Ç–≤–µ—Ç) –∏–ª–∏ "—ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä" (–≤–æ–ø—Ä–æ—Å)
        """
        if not transcript:
            return False
        text = transcript.strip()
        if not text:
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –° –õ–ò–ú–ò–¢–û–ú (–º–∞–∫—Å 10 —Ä–µ–ø–ª–∏–∫ = 5 –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç)
        self._dialogue_context.append((role, text))
        if len(self._dialogue_context) > 10:
            self._dialogue_context = self._dialogue_context[-10:]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–¥–ª—è —Å—Ç–∞—Ä—ã—Ö –º–µ—Ç–æ–¥–æ–≤)
        if self._current_text:
            self._current_text += " "
        self._current_text += text
        
        if not self.has_pending():
            return False
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º snapshot –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º Gemini (–¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Pro –æ—Ç–≤–µ—Ç–∞)
        import time
        thesis_text = self.theses[self._index]
        self._pro_snapshots[thesis_text] = {
            "index": self._index,
            "context_size": len(self._dialogue_context),
            "timestamp": time.time()
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ Gemini (—É–±—Ä–∞–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã)
        if self._gemini_enabled and self._gemini_judge is not None:
            covered, conf = self._gemini_judge.judge(thesis_text, self._dialogue_context)
            logger.debug(
                f"GeminiJudge –¥–ª—è —Ç–µ–∑–∏—Å–∞ '{thesis_text[:40]}...': covered={covered}, conf={conf:.3f}"
            )
            if covered and conf >= self.gemini_min_conf:
                self._advance()
                return True
        
        return False

    def _advance(self) -> None:
        self._index += 1
        self._announced = False
        self._current_tokens.clear()
        self._current_text = ""
        self._dialogue_context.clear()

    # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –º–µ—Ç–æ–¥–æ–º
    def _extract_tokens(self, text: str) -> Set[str]:
        tokens = re.findall(r"[\w-]+", text.lower(), flags=re.UNICODE)
        cleaned = {
            tok
            for tok in tokens
            if len(tok) >= self.min_token_len and tok not in self.stopwords
        }
        return cleaned

    @staticmethod
    def _coverage(spoken: Set[str], thesis_tokens: Set[str]) -> float:
        if not thesis_tokens:
            return 1.0
        matched = len(spoken & thesis_tokens)
        return matched / float(len(thesis_tokens))

    # –ù–æ–≤—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –ª–æ–≥–æ–≤ –∏ –æ–∑–≤—É—á–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    def remaining_count(self) -> int:
        return max(0, len(self.theses) - self._index)

    def coverage_of_current(self) -> float:
        if not self.has_pending():
            return 1.0
        thesis_tokens = self._thesis_tokens[self._index]
        return self._coverage(self._current_tokens, thesis_tokens)

    def remaining_list(self, limit: int = 3) -> List[str]:
        if self._index >= len(self.theses):
            return []
        return self.theses[self._index : self._index + max(0, int(limit))]

    def remaining_announcement(self, limit: int = 3) -> str:
        items = self.remaining_list(limit=limit)
        if not items:
            return ""
        nums = []
        for i, t in enumerate(items, 1):
            nums.append(f"{i}) {t}")
        return "–û—Å—Ç–∞–ª–∏—Å—å —Ç–µ–∑–∏—Å—ã: " + "; ".join(nums)
    
    def _on_pro_upgrade(
        self, 
        thesis: str, 
        covered: bool, 
        confidence: float,
        snapshot_timestamp: float,
        snapshot_context_size: int,
        response_timestamp: float
    ) -> bool:
        """
        Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –æ—Ç Pro –º–æ–¥–µ–ª–∏.
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–æ–∂–Ω–æ –ª–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ Pro.
        
        Returns:
            True –µ—Å–ª–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ Pro, False –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É—Å—Ç–∞—Ä–µ–ª
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å snapshot –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ–∑–∏—Å–∞
        if thesis not in self._pro_snapshots:
            logger.debug(f"‚è≠Ô∏è  Pro: –Ω–µ—Ç snapshot –¥–ª—è —Ç–µ–∑–∏—Å–∞ {thesis[:50]}...")
            return False
        
        snapshot = self._pro_snapshots[thesis]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –¢–µ–∑–∏—Å –Ω–µ —Å–º–µ–Ω–∏–ª—Å—è (–∏–Ω–¥–µ–∫—Å —Ç–æ—Ç –∂–µ –∏–ª–∏ —Ç–µ–∑–∏—Å —É–∂–µ –∑–∞–∫—Ä—ã—Ç)
        current_thesis_text = self.theses[self._index] if self.has_pending() else None
        if current_thesis_text != thesis:
            # –¢–µ–∑–∏—Å —É–∂–µ –∑–∞–∫—Ä—ã–ª—Å—è –∏–ª–∏ —Å–º–µ–Ω–∏–ª—Å—è
            logger.debug(f"‚è≠Ô∏è  Pro: —Ç–µ–∑–∏—Å —Å–º–µ–Ω–∏–ª—Å—è (–±—ã–ª–æ: {thesis[:30]}..., —Å–µ–π—á–∞—Å: {current_thesis_text[:30] if current_thesis_text else 'None'}...)")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è (–Ω–æ–≤—ã—Ö —Ä–µ–ø–ª–∏–∫ –Ω–µ –±—ã–ª–æ)
        if len(self._dialogue_context) != snapshot_context_size:
            logger.debug(f"‚è≠Ô∏è  Pro: –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑–º–µ–Ω–∏–ª—Å—è (–±—ã–ª–æ {snapshot_context_size} —Ä–µ–ø–ª–∏–∫, —Å–µ–π—á–∞—Å {len(self._dialogue_context)})")
            return False
        
        # –í—Å—ë –≤ –ø–æ—Ä—è–¥–∫–µ - –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ Pro
        logger.info(f"‚úÖ Pro —Ä–µ—à–µ–Ω–∏–µ –≤–∞–ª–∏–¥–Ω–æ –¥–ª—è —Ç–µ–∑–∏—Å–∞ {thesis[:50]}...")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—à–µ–Ω–∏–µ Pro
        if covered:
            logger.info(f"üîÑ Pro –∑–∞–∫—Ä—ã–≤–∞–µ—Ç —Ç–µ–∑–∏—Å (conf={confidence:.2f})")
            self._advance()
        
        return True


__all__ = ["ThesisPrompter"]
