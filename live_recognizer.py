from __future__ import annotations

import os
import queue
import sys
import threading
import time
from dataclasses import dataclass
from collections import deque
from pathlib import Path
from typing import Optional, List, Callable
from datetime import date

import numpy as np
import io
import wave
from loguru import logger

# –ú—è–≥–∫–∏–µ –∏–º–ø–æ—Ä—Ç—ã —Ç—è–∂—ë–ª—ã—Ö/–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, —á—Ç–æ–±—ã —é–Ω–∏—Ç-—Ç–µ—Å—Ç—ã —Ä–∞–±–æ—Ç–∞–ª–∏ –æ—Ñ—Ñ–ª–∞–π–Ω
try:  # sound I/O
    import sounddevice as sd  # type: ignore
except Exception:  # noqa: BLE001
    sd = None  # type: ignore

try:  # torch (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ CI)
    import torch  # type: ignore
except Exception:  # noqa: BLE001
    torch = None  # type: ignore

try:  # WebRTC VAD
    import webrtcvad  # type: ignore
except Exception:  # noqa: BLE001
    webrtcvad = None  # type: ignore

try:  # —ç–º–±–µ–¥–¥–µ—Ä –≥–æ–ª–æ—Å–∞
    from pyannote.audio.pipelines.speaker_verification import (  # type: ignore
        PretrainedSpeakerEmbedding,
    )
except Exception:  # noqa: BLE001
    PretrainedSpeakerEmbedding = None  # type: ignore

try:  # ASR (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from asr_transcriber import FasterWhisperTranscriber  # type: ignore
except Exception:  # noqa: BLE001
    FasterWhisperTranscriber = None  # type: ignore
try:  # LLM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from llm_answer import LLMResponder  # type: ignore
except Exception:  # noqa: BLE001
    LLMResponder = None  # type: ignore
try:  # Silero TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from tts_silero import SileroTTS  # type: ignore
except Exception:  # noqa: BLE001
    SileroTTS = None  # type: ignore
try:  # Silero VAD (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from vad_silero import SileroVAD  # type: ignore
except Exception:  # noqa: BLE001
    SileroVAD = None  # type: ignore
from thesis_prompter import ThesisPrompter
try:
    from thesis_generator import GeminiThesisGenerator  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
except Exception:  # noqa: BLE001
    GeminiThesisGenerator = None  # type: ignore


LOGGING_CONFIGURED = False
CURRENT_LOG_DIR: Optional[Path] = None


def setup_logging(
    log_dir: Optional[Path] = None,
    console_level: str = os.getenv("CONSOLE_LOG_LEVEL", "INFO"),
    file_level: str = os.getenv("FILE_LOG_LEVEL", "DEBUG"),
) -> Path:
    """Configure loguru sinks and return the file sink path.
    If log_dir is provided, reconfigure sinks to write there.
    """
    global LOGGING_CONFIGURED, CURRENT_LOG_DIR
    target_dir = Path(log_dir or os.getenv("LOG_DIR", "logs"))
    # Reconfigure if not configured yet OR explicit log_dir differs from current
    need_reconfigure = (not LOGGING_CONFIGURED) or (
        log_dir is not None and (CURRENT_LOG_DIR is None or target_dir != CURRENT_LOG_DIR)
    )
    if not need_reconfigure and CURRENT_LOG_DIR is not None:
        return CURRENT_LOG_DIR / "assistant.log"

    target_dir.mkdir(parents=True, exist_ok=True)
    log_file = target_dir / "assistant.log"

    logger.remove()
    logger.add(sys.stderr, level=console_level.upper(), enqueue=True, backtrace=False)
    logger.add(
        log_file,
        level=file_level.upper(),
        enqueue=False,  # —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å, —á—Ç–æ–±—ã —Ñ–∞–π–ª –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å–æ–∑–¥–∞–≤–∞–ª—Å—è –≤ —Ç–µ—Å—Ç–∞—Ö
        mode="w",
        encoding="utf-8",
        backtrace=True,
        diagnose=True,
    )
    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏—è sink
    try:
        log_file.touch(exist_ok=True)
    except Exception:
        pass
    logger.info(f"–õ–æ–≥–∏ –ø–∏—à—É—Ç—Å—è –≤ {log_file.resolve()}")
    LOGGING_CONFIGURED = True
    CURRENT_LOG_DIR = target_dir
    return log_file


DEFAULT_ENROLL_PARAGRAPHS: list[str] = [
    (
        "–≠—Ç–æ—Ç –∞–±–∑–∞—Ü –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã —Å–∏—Å—Ç–µ–º–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ –∑–∞–ø–æ–º–Ω–∏–ª–∞ –º–æ–π –≥–æ–ª–æ—Å. "
        "–Ø –≥–æ–≤–æ—Ä—é —Ä–∞–∑–º–µ—Ä–µ–Ω–Ω–æ, –¥–µ—Ä–∂—É –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ –Ω–µ —Å–ø–µ—à—É. "
        "–í –∫–æ–Ω—Ü–µ –¥–µ–ª–∞—é –∫–æ—Ä–æ—Ç–∫—É—é –ø–∞—É–∑—É, —á—Ç–æ–±—ã –∑–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ."
    ),
    (
        "–í —Ä–∞–±–æ—á–µ–º –¥–Ω–µ –º–Ω–µ —á–∞—Å—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –æ–±—ä—è—Å–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∏–¥–µ–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º. "
        "–ü–æ—ç—Ç–æ–º—É –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —á—ë—Ç–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–ª –º–æ–∏ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —Ç–µ–º–±—Ä. "
        "–Ø –ø—Ä–æ–∏–∑–Ω–æ—à—É —Å–ª–æ–≤–∞ —è—Å–Ω–æ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ, —Å–ª–æ–≤–Ω–æ –æ—Ç–≤–µ—á–∞—é –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞."
    ),
    (
        "–ß—Ç–æ–±—ã –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—É—á–∏–ª—Å—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º, —è —á–∏—Ç–∞—é —Ç–µ–∫—Å—Ç, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä –æ –ø—Ä–æ–µ–∫—Ç–∞—Ö. "
        "–Ø –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞—é –∑–∞–¥–∞—á–∏, —Ä–µ—à–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –∂–∏–≤—É—é –∏ —Å–ø–æ–∫–æ–π–Ω—É—é —Ä–µ—á—å. "
        "–¢–∞–∫ –∞–ª–≥–æ—Ä–∏—Ç–º —É–ª–æ–≤–∏—Ç –º–æ–π —Ä–µ–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è."
    ),
]


def _split_paragraphs(text: str) -> list[str]:
    if not text:
        return []
    parts = [p.strip() for p in text.replace("\r", "").split("\n\n")]
    return [p for p in parts if p]


SAMPLE_RATE = 16000  # required by WebRTC VAD and recommended for embeddings
FRAME_MS = 20  # WebRTC VAD supports 10, 20, or 30 ms
FRAME_SIZE = int(SAMPLE_RATE * FRAME_MS / 1000)  # samples per frame
CHANNELS = 1


def float_to_pcm16(x: np.ndarray) -> bytes:
    """Convert float32 (-1..1) to 16-bit PCM bytes."""
    x = np.clip(x, -1.0, 1.0)
    x_int16 = (x * 32767.0).astype(np.int16)
    return x_int16.tobytes()


def median_spectral_flatness(
    wav: np.ndarray, sample_rate: int = SAMPLE_RATE, frame_len: int = 512, hop: int = 256
) -> float:
    """–û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—É—é –ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ—Å—Ç—å (0..1), –≥–¥–µ –±–ª–∏–∂–µ –∫ 1 ‚Äî —à—É–º–æ–ø–æ–¥–æ–±–Ω—ã–π —Å–∏–≥–Ω–∞–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–µ–¥–∏–∞–Ω—É –ø–æ –æ–∫–Ω–∞–º.
    """
    if wav.ndim != 1:
        wav = wav.reshape(-1)
    if wav.size < frame_len:
        return 1.0  # —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ —à—É–º
    # –û–∫–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    n_frames = 1 + (wav.size - frame_len) // hop
    if n_frames <= 0:
        return 1.0
    window = np.hanning(frame_len).astype(np.float32)
    sf_values: list[float] = []
    eps = 1e-10
    for i in range(n_frames):
        start = i * hop
        frame = wav[start : start + frame_len]
        if frame.size < frame_len:
            break
        frame = frame * window
        spec = np.fft.rfft(frame)
        p = (spec.real ** 2 + spec.imag ** 2) + eps
        # –ú–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–ª–æ—Å—É [80..4000] –ì—Ü, —á—Ç–æ–±—ã —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–µ—á–∏
        freqs = np.fft.rfftfreq(frame_len, d=1.0 / sample_rate)
        band = (freqs >= 80) & (freqs <= 4000)
        p_band = p[band]
        if p_band.size == 0:
            continue
        gm = np.exp(np.mean(np.log(p_band)))
        am = np.mean(p_band)
        sf = float(gm / (am + eps))
        sf_values.append(sf)
    if not sf_values:
        return 1.0
    return float(np.median(np.asarray(sf_values)))


@dataclass
class VoiceProfile:
    embedding: np.ndarray  # shape (d,)

    @staticmethod
    def load(path: Path) -> Optional["VoiceProfile"]:
        if not path.exists():
            return None
        data = np.load(path)
        return VoiceProfile(embedding=data["embedding"])  # type: ignore[index]

    def save(self, path: Path) -> None:
        path.parent.mkdir(parents=True, exist_ok=True)
        np.savez_compressed(path, embedding=self.embedding)


@dataclass
class QueuedSegment:
    kind: str
    audio: np.ndarray
    timestamp: float
    distance: float = 0.0


class LiveVoiceVerifier:
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ª–∞–π–≤-–º–æ–¥—É–ª—å:
    - WebRTC VAD, —á—Ç–æ–±—ã –æ—Ç–¥–µ–ª—è—Ç—å —Ä–µ—á—å –æ—Ç —à—É–º–æ–≤/—Ç–∏—à–∏–Ω—ã.
    - –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ (ECAPA) –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–æ—Ñ–∏–ª–µ–º –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏.
    - –í—ã–≤–æ–¥: "–º–æ–π –≥–æ–ª–æ—Å" / "–Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å".
    """

    def __init__(
        self,
        model_id: str = "speechbrain/spkrec-ecapa-voxceleb",
        device: Optional[str] = None,
        embedder: Optional[PretrainedSpeakerEmbedding] = None,
        vad_aggressiveness: int = 2,
        vad_backend: str = "webrtc",  # "webrtc" | "silero"
        silero_vad_threshold: float = 0.5,
        silero_vad_window_ms: int = 100,
        threshold: float = 0.30,  # cosine distance threshold: <= is my voice
        min_consec_speech_frames: int = 5,  # >=5 * 20ms = 100ms –ø–æ–¥—Ä—è–¥ —Ä–µ—á–∏ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
        flatness_reject_threshold: float = 0.60,  # > -> —à—É–º, —Å–µ–≥–º–µ–Ω—Ç –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º
        # ASR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        asr_enable: bool = False,
        asr_model_size: str = "large-v3-turbo",
        asr_language: Optional[str] = None,
        asr_device: Optional[str] = None,
        asr_compute_type: Optional[str] = None,
        # LLM –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        llm_enable: bool = False,
        # Thesis –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç—ã –∏–∑ ThesisConfig)
        thesis_match_threshold: float = 0.6,
        thesis_semantic_enable: bool = True,
        thesis_semantic_threshold: float = 0.55,
        thesis_semantic_model: Optional[str] = None,
        thesis_gemini_enable: bool = True,
        thesis_gemini_min_conf: float = 0.60,
        thesis_autogen_enable: bool = True,
        thesis_autogen_batch: int = 3,
    ) -> None:
        if device is None:
            # –ë–µ–∑ torch —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ CPU
            if 'cuda' in str(os.getenv('ASR_DEVICE', '')).lower():
                device = 'cuda'
            else:
                try:
                    device = "cuda" if (torch is not None and getattr(torch, "cuda", None) and torch.cuda.is_available()) else "cpu"
                except Exception:
                    device = "cpu"
        # –ï—Å–ª–∏ torch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫—É, –∏–Ω–∞—á–µ torch.device
        self.device = torch.device(device) if torch is not None else device  # type: ignore[assignment]
        self._device_str = self.device.type
        self._embedder_model_id = model_id
        self._embedder: Optional[PretrainedSpeakerEmbedding] = embedder
        # VAD backend selection
        self.vad_backend = vad_backend.lower().strip()
        if self.vad_backend not in ("webrtc", "silero"):
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π vad_backend={vad_backend}, –∏—Å–ø–æ–ª—å–∑—É–µ–º 'webrtc'")
            self.vad_backend = "webrtc"
        if self.vad_backend == "webrtc":
            if webrtcvad is None:
                logger.warning("webrtcvad –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî VAD –≤—ã–∫–ª—é—á–µ–Ω –¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω-—Ç–µ—Å—Ç–æ–≤")
                self._vad_fn = lambda frame: False
            else:
                self.vad_webrtc = webrtcvad.Vad(vad_aggressiveness)
                self._vad_fn = lambda frame: self.vad_webrtc.is_speech(
                    float_to_pcm16(frame), SAMPLE_RATE
                )
        else:
            if SileroVAD is None:
                logger.warning("SileroVAD –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî VAD –≤—ã–∫–ª—é—á–µ–Ω –¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω-—Ç–µ—Å—Ç–æ–≤")
                self._vad_fn = lambda frame: False
            else:
                self.vad_silero = SileroVAD(
                    sample_rate=SAMPLE_RATE,
                    threshold=float(silero_vad_threshold),
                    window_ms=int(silero_vad_window_ms),
                    device=self._device_str,
                )
                self._vad_fn = lambda frame: self.vad_silero.is_speech(frame)
        self.threshold = threshold
        self.min_consec_speech_frames = max(1, int(min_consec_speech_frames))
        self.flatness_reject_threshold = float(flatness_reject_threshold)
        # ASR
        self.asr_enable = bool(asr_enable)
        self.asr_model_size = asr_model_size
        self.asr_language = asr_language
        self.asr_device = asr_device
        self.asr_compute_type = asr_compute_type
        self._asr: Optional[FasterWhisperTranscriber] = None
        # LLM
        self.llm_enable = bool(llm_enable)
        self._llm: Optional[LLMResponder] = None
        # TTS –¥–ª—è –æ–∑–≤—É—á–∫–∏ –æ—Ç–≤–µ—Ç–∞ LLM
        self._tts: Optional[SileroTTS] = None
        self._suppress_until: float = 0.0  # –ø–æ–¥–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Ö–æ–¥–∞ –Ω–∞ –≤—Ä–µ–º—è TTS
        self._is_announcing: bool = False  # —Ñ–ª–∞–≥ —á—Ç–æ —Å–µ–π—á–∞—Å –æ–∑–≤—É—á–∏–≤–∞–µ—Ç—Å—è —Ç–µ–∑–∏—Å
        # –í–Ω–µ—à–Ω–∏–π –ø–æ–ª—É—á–∞—Ç–µ–ª—å –∞—É–¥–∏–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, WebSocket-–∫–ª–∏–µ–Ω—Ç). –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ‚Äî
        # TTS –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Ç—É–¥–∞, –∞ –Ω–µ –ø—Ä–æ–∏–≥—Ä—ã–≤–∞—Ç—å—Å—è –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ sounddevice
        self._audio_sink: Optional[Callable[[bytes, int], None]] = None

        # –¢–µ–∑–∏—Å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫
        self.thesis_prompter: Optional[ThesisPrompter] = None
        self._thesis_done_notified = False
        self._last_question: str = ""  # –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–º–æ—â–Ω–∏–∫–∞
        self._thesis_match_threshold = float(thesis_match_threshold)
        self._thesis_semantic_enable = bool(thesis_semantic_enable)
        self._thesis_semantic_threshold = float(thesis_semantic_threshold)
        self._thesis_semantic_model = thesis_semantic_model
        self._thesis_gemini_enable = bool(thesis_gemini_enable)
        self._thesis_gemini_min_conf = float(thesis_gemini_min_conf)
        # –ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        self._thesis_autogen_enable = bool(thesis_autogen_enable)
        self._thesis_autogen_batch = max(1, int(thesis_autogen_batch))
        self._thesis_generator: Optional[GeminiThesisGenerator] = None
        self._theses_history: set[str] = set()
        self._question_context: str = ""
        self._max_question_context_chars: int = 2000
        self._last_announce_ts: float = 0.0
        self._segment_queue: "queue.Queue[QueuedSegment]" = queue.Queue(maxsize=4)
        self._segment_worker: Optional[threading.Thread] = None
        self._segment_stop = threading.Event()
        # –§–æ–Ω–æ–≤—ã–π –ø–æ–≤—Ç–æ—Ä —Ç–µ–∑–∏—Å–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø—Ä–∏—Ö–æ–¥–∞ –∞—É–¥–∏–æ
        self._thesis_repeat_worker: Optional[threading.Thread] = None
        self._thesis_repeat_stop = threading.Event()
        # –ò–Ω–¥–µ–∫—Å –¥–ª—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–µ–∑–∏—Å–æ–≤
        self._thesis_cycle_idx: int = 0
        # –ö–∞–∫ —á–∞—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è—Ç—å —Ç–µ–∫—É—â–∏–π —Ç–µ–∑–∏—Å (—Å–µ–∫—É–Ω–¥—ã), –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ –∑–∞–∫—Ä—ã—Ç
        try:
            # –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø–æ–≤—Ç–æ—Ä–∞ —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ–∑–∏—Å–∞ (—Å–µ–∫)
            self._thesis_repeat_sec: float = float(os.getenv("THESIS_REPEAT_SEC", "10"))
        except Exception:
            self._thesis_repeat_sec = 10.0
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è ¬´–Ω–µ-–≤–æ–ø—Ä–æ—Å–æ–≤¬ª: heuristic | gemini (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gemini)
        self._question_filter_mode: str = os.getenv("QUESTION_FILTER_MODE", "gemini").strip().lower()
        try:
            self._question_min_len: int = int(os.getenv("QUESTION_MIN_LEN", "8"))
        except Exception:
            self._question_min_len = 8
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∫ –æ—Ç–≤–µ—Ç—É LLM (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª)
        try:
            _aq = os.getenv("APPEND_QUESTION_TO_ANSWER", "0").strip().lower()
            self._append_question_to_answer: bool = _aq in ("1", "true", "yes", "on")
        except Exception:
            self._append_question_to_answer = False
        # –†–µ–∂–∏–º: –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –ò–ò-—ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –∏–∑ —á—É–∂–æ–π —Ä–µ—á–∏
        self._ai_only_thesis: bool = os.getenv("AI_ONLY_THESIS", "1").strip() not in ("0", "false", "False")
        # –ù–æ–≤—ã–π —Ä–µ–∂–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–∫—Ç-–∑–∞–º–µ—Ç–∫–∏ –¥–∞–∂–µ –±–µ–∑ —è–≤–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        self._commentary_mode: bool = os.getenv("COMMENTARY_MODE", "0").strip() not in ("0", "false", "False", "no", "No")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—É—à–Ω–∏–∫–∏ (True = –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞)
        self._use_headphones: bool = os.getenv("USE_HEADPHONES", "1").strip() not in ("0", "false", "False")
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Ç–µ–∑–∏—Å–æ–≤ (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω)
        if GeminiThesisGenerator is not None:
            try:
                self._thesis_generator = GeminiThesisGenerator()  # type: ignore
                logger.info("–ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ Gemini –≤–∫–ª—é—á–µ–Ω–∞")
            except Exception as e:  # noqa: BLE001
                logger.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å ThesisGenerator: {e}")
        else:
            logger.warning("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ–∑–∏—Å–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ thesis_generator/google-genai")

        if self.asr_enable:
            try:
                self._ensure_asr()
            except Exception as e:  # noqa: BLE001
                logger.exception(f"ASR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

        if self.llm_enable and LLMResponder is not None:
            try:
                self._llm = LLMResponder()
            except Exception as e:  # noqa: BLE001
                logger.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å LLMResponder: {e}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º TTS (RU –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –µ—Å–ª–∏ –æ–Ω –Ω—É–∂–µ–Ω –¥–ª—è LLM –∏–ª–∏ —Ç–µ–∑–∏—Å–æ–≤
        if self.llm_enable or self.thesis_prompter is not None:
            if SileroTTS is not None:
                try:
                    self._tts = SileroTTS(
                        language="ru", model_id="v4_ru", speaker="eugene", sample_rate=24000
                    )
                except Exception as e:  # noqa: BLE001
                    logger.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å TTS: {e}")
            else:
                logger.debug("SileroTTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –æ–∑–≤—É—á–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞")

        logger.info(
            f"LiveVoiceVerifier initialized | model={model_id}, device={self.device}, threshold={threshold}, VAD={self.vad_backend}"
        )

        # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–µ–π, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å –∑–∞–¥–µ—Ä–∂–∫—É –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏
        try:
            self._warmup_models()
        except Exception as e:  # noqa: BLE001
            logger.debug(f"Warmup error (ignored): {e}")

    # ==== –í–Ω–µ—à–Ω–∏–π –ø—Ä–∏—ë–º–Ω–∏–∫ –∞—É–¥–∏–æ (–¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã) ====
    def set_audio_sink(self, sink: Callable[[bytes, int], None]) -> None:
        """–ó–∞–¥–∞—Ç—å –≤–Ω–µ—à–Ω–∏–π –ø—Ä–∏—ë–º–Ω–∏–∫ –∞—É–¥–∏–æ.
        sink –ø—Ä–∏–Ω–∏–º–∞–µ—Ç (wav_bytes, sample_rate). –ï—Å–ª–∏ –∑–∞–¥–∞–Ω, TTS –±—É–¥–µ—Ç
        –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Ç—É–¥–∞ –≤–º–µ—Å—Ç–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è."""
        self._audio_sink = sink

    @staticmethod
    def cosine_distance(a: np.ndarray, b: np.ndarray) -> float:
        a = a / (np.linalg.norm(a) + 1e-8)
        b = b / (np.linalg.norm(b) + 1e-8)
        return float(1.0 - np.dot(a, b))

    def _ensure_embedder(self) -> PretrainedSpeakerEmbedding:
        if self._embedder is None:
            self._embedder = PretrainedSpeakerEmbedding(
                self._embedder_model_id,
                device=self.device,
            )
        return self._embedder

    def embedding_from_waveform(self, wav: np.ndarray) -> np.ndarray:
        """wav: mono float32 in [-1, 1], shape (n_samples,) at 16kHz"""
        if wav.ndim != 1:
            wav = wav.reshape(-1)
        # Ensure tensor shape (batch=1, channels=1, samples)
        if torch is not None and hasattr(torch, "from_numpy"):
            tensor = torch.from_numpy(wav).float().unsqueeze(0).unsqueeze(0)  # (1,1,n)
            ctx = getattr(torch, "inference_mode", None)
            if callable(ctx):
                cm = ctx()
            else:
                class _Dummy:
                    def __enter__(self):
                        return None
                    def __exit__(self, exc_type, exc, tb):
                        return False
                cm = _Dummy()
            with cm:  # type: ignore
                out = self._ensure_embedder()(tensor)  # expected shape (1, dim)
        else:
            # –§–æ–ª–ª–±—ç–∫: —ç–º–±–µ–¥–¥–µ—Ä—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—ä–µ–∫—Ç–∞ —Å shape, DummyEmbedder –∏–∑ —Ç–µ—Å—Ç–æ–≤ —ç—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
            class _DummyTensor:
                def __init__(self, n: int):
                    self.shape = (1, 1, n)
            out = self._ensure_embedder()(_DummyTensor(wav.size))  # type: ignore
        # out can be numpy array or torch tensor depending on backend
        if isinstance(out, np.ndarray):
            return out[0]
        else:
            try:
                return out[0].detach().cpu().numpy()
            except Exception:
                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ np.ndarray –∏–ª–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ç–∏–ø
                try:
                    return np.asarray(out)[0]
                except Exception:
                    # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ ‚Äî –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                    return np.zeros((192,), dtype=np.float32)

    # ==== –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ====
    def _start_segment_worker(self) -> None:
        if self._segment_worker and self._segment_worker.is_alive():
            return
        self._segment_stop.clear()
        self._segment_worker = threading.Thread(
            target=self._segment_worker_loop,
            name="segment-worker",
            daemon=True,
        )
        self._segment_worker.start()
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ–ª—è —Ç–µ–∑–∏—Å–æ–≤
        self._start_thesis_repeater()

    def _stop_segment_worker(self) -> None:
        self._segment_stop.set()
        if self._segment_worker is not None:
            self._segment_worker.join(timeout=2.0)
            self._segment_worker = None
        while not self._segment_queue.empty():
            try:
                self._segment_queue.get_nowait()
                self._segment_queue.task_done()
            except queue.Empty:
                break
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ–ª—è —Ç–µ–∑–∏—Å–æ–≤
        self._stop_thesis_repeater()

    def _start_thesis_repeater(self) -> None:
        if self._thesis_repeat_worker and self._thesis_repeat_worker.is_alive():
            return
        self._thesis_repeat_stop.clear()
        self._thesis_repeat_worker = threading.Thread(
            target=self._thesis_repeater_loop,
            name="thesis-repeater",
            daemon=True,
        )
        self._thesis_repeat_worker.start()

    def _stop_thesis_repeater(self) -> None:
        self._thesis_repeat_stop.set()
        if self._thesis_repeat_worker is not None:
            self._thesis_repeat_worker.join(timeout=2.0)
            self._thesis_repeat_worker = None

    def _thesis_repeater_loop(self) -> None:
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —Ç–µ–∑–∏—Å, –¥–∞–∂–µ –≤ —Ç–∏—à–∏–Ω–µ
        logger.debug(f"üîÅ –§–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ thesis_repeater –∑–∞–ø—É—â–µ–Ω (–∏–Ω—Ç–µ—Ä–≤–∞–ª={self._thesis_repeat_sec}—Å)")
        while not self._thesis_repeat_stop.is_set():
            try:
                time_since_last = time.time() - self._last_announce_ts
                has_pending = self.thesis_prompter is not None and self.thesis_prompter.has_pending()
                not_suppressed = time.time() >= self._suppress_until
                not_announcing = not self._is_announcing
                
                # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                if has_pending:
                    logger.debug(
                        f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–≤—Ç–æ—Ä–∞: time_since_last={time_since_last:.1f}—Å, "
                        f"threshold={self._thesis_repeat_sec}—Å, suppressed={not not_suppressed}, announcing={not not_announcing}"
                    )
                
                if has_pending and time_since_last >= self._thesis_repeat_sec and not_suppressed and not_announcing:
                    logger.debug(f"‚úÖ –ü–æ–≤—Ç–æ—Ä —Ç–µ–∑–∏—Å–∞ —á–µ—Ä–µ–∑ {time_since_last:.1f}—Å (–∏–Ω—Ç–µ—Ä–≤–∞–ª={self._thesis_repeat_sec}—Å)")
                    self._announce_next_thesis_in_cycle()
            except Exception as e:
                logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –≤ thesis_repeater: {e}")
            # –ß–∞—Å—Ç–æ—Ç–∞ –æ–ø—Ä–æ—Å–∞ –Ω–µ–±–æ–ª—å—à–∞—è, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å CPU
            time.sleep(0.2)
        logger.debug("üõë –§–æ–Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ thesis_repeater –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    def _announce_next_thesis_in_cycle(self) -> None:
        tp = self.thesis_prompter
        if tp is None or not tp.has_pending():
            return
        # —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ —Ü–∏–∫–ª–∞ —Å –ø–µ—Ä–≤—ã–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–º
        start_idx = getattr(tp, "_index", 0)
        total = len(getattr(tp, "theses", []))
        if self._thesis_cycle_idx < start_idx or self._thesis_cycle_idx >= total:
            self._thesis_cycle_idx = start_idx
        
        # –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∑–∏—Å –ø–æ —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–º—É –∏–Ω–¥–µ–∫—Å—É –ë–ï–ó —Å–º–µ–Ω—ã _index
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ —Ç–µ–∑–∏—Å—ã, –Ω–æ –Ω–µ —Å–±–∏–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π
        tp.reset_announcement()
        self._announce_thesis(thesis_index=self._thesis_cycle_idx)
        
        # –≤—ã—á–∏—Å–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å —Ü–∏–∫–ª–∞ —Å—Ä–µ–¥–∏ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è
        total2 = len(getattr(tp, "theses", []))
        current_idx = getattr(tp, "_index", start_idx)
        if not tp.has_pending():
            self._thesis_cycle_idx = 0
            return
        # —Å–ª–µ–¥—É—é—â–∏–π ‚Äî —ç—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–π —Ç–µ–∑–∏—Å
        self._thesis_cycle_idx = self._thesis_cycle_idx + 1
        if self._thesis_cycle_idx >= total2:
            self._thesis_cycle_idx = current_idx

    def _enqueue_segment(self, kind: str, audio: np.ndarray, distance: float = 0.0) -> None:
        if audio.size == 0:
            return
        segment = QueuedSegment(kind=kind, audio=audio, timestamp=time.time(), distance=distance)
        try:
            self._segment_queue.put_nowait(segment)
        except queue.Full:
            try:
                dropped = self._segment_queue.get_nowait()
                self._segment_queue.task_done()
                logger.warning(
                    f"–û—á–µ—Ä–µ–¥—å —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –æ—Ç–±—Ä–∞—Å—ã–≤–∞—é {dropped.kind} —Å–µ–≥–º–µ–Ω—Ç"
                )
            except queue.Empty:
                pass
            try:
                self._segment_queue.put_nowait(segment)
            except queue.Full:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç –≤ –æ—á–µ—Ä–µ–¥—å ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é —Å–∏–≥–Ω–∞–ª")

    def _segment_worker_loop(self) -> None:
        while not self._segment_stop.is_set() or not self._segment_queue.empty():
            try:
                segment = self._segment_queue.get(timeout=0.2)
            except queue.Empty:
                continue
            
            # –í–ê–ñ–ù–û: –í–æ –≤—Ä–µ–º—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∑–∏—Å–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –°–í–û–ò —Å–µ–≥–º–µ–Ω—Ç—ã
            # (—á—Ç–æ–±—ã –Ω–µ –∑–∞–∫—Ä—ã—Ç—å —Ç–µ–∑–∏—Å –∫–æ—Ç–æ—Ä—ã–π —Å–µ–π—á–∞—Å –æ–∑–≤—É—á–∏–≤–∞–µ—Ç—Å—è)
            # –ù–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–ª—É—à–∞—Ç—å –ß–£–ñ–ò–ï —Å–µ–≥–º–µ–Ω—Ç—ã (–Ω–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã)
            if self._is_announcing:
                if segment.kind == "self":
                    logger.debug("‚è∏Ô∏è –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–≤–æ–π –≥–æ–ª–æ—Å –≤–æ –≤—Ä–µ–º—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∑–∏—Å–∞")
                    self._segment_queue.task_done()
                    continue
                else:
                    logger.debug(f"‚úÖ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á—É–∂–æ–π —Å–µ–≥–º–µ–Ω—Ç –¥–∞–∂–µ –≤–æ –≤—Ä–µ–º—è –æ–∑–≤—É—á–∫–∏")
            
            try:
                if segment.kind == "self":
                    self._handle_self_segment(segment)
                else:
                    self._handle_foreign_segment(segment)
            except Exception as e:  # noqa: BLE001
                logger.exception(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            finally:
                self._segment_queue.task_done()

    def _handle_self_segment(self, segment: QueuedSegment) -> None:
        logger.info("–º–æ–π –≥–æ–ª–æ—Å")
        if not self.asr_enable:
            logger.debug("ASR –æ—Ç–∫–ª—é—á—ë–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ—á–∏")
            return
        try:
            transcript = self._ensure_asr().transcribe_np(segment.audio, SAMPLE_RATE)
        except Exception as e:  # noqa: BLE001
            logger.exception(f"ASR –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –º–æ–µ–≥–æ –≥–æ–ª–æ—Å–∞: {e}")
            return
        self._handle_self_transcript(transcript)

    def _handle_foreign_segment(self, segment: QueuedSegment) -> None:
        if self.asr_enable:
            try:
                text = self._ensure_asr().transcribe_np(segment.audio, SAMPLE_RATE)
            except Exception as e:  # noqa: BLE001
                logger.exception(f"ASR –æ—à–∏–±–∫–∞: {e}")
                return
            self._handle_foreign_text(text)
        else:
            logger.info("–Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å")

    def _handle_foreign_text(self, text: Optional[str]) -> None:
        t = (text or "").strip()
        if not t:
            logger.info("–Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å (ASR: –ø—É—Å—Ç–æ)")
            return
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ —Ä–∞–Ω–æ –ø–æ—Å–ª–µ TTS (–º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ö–æ)
        # –ù–æ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—É—à–Ω–∏–∫–∏ (–≤ –Ω–∞—É—à–Ω–∏–∫–∞—Ö –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS)
        if not self._use_headphones and time.time() < self._suppress_until:
            time_left = self._suppress_until - time.time()
            logger.debug(f"–ò–≥–Ω–æ—Ä–∏—Ä—É—é –≤—Ö–æ–¥ (suppress –µ—â—ë {time_left:.1f}—Å): {t}")
            return
        logger.info(f"–Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å (ASR): {t}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ç–µ–∑–∏—Å–æ–≤
        self._last_question = t
        # –ë—ã—Å—Ç—Ä—ã–π —Ö—ç–Ω–¥–ª–µ—Ä –ø—Ä–æ—Å—Ç—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        try:
            math_ans = self._answer_math_if_any(t)
        except Exception:
            math_ans = None
        if math_ans:
            logger.info(f"–û—Ç–≤–µ—Ç: {math_ans}")
            self._speak_text(math_ans)
            return
        # –ñ—ë—Å—Ç–∫–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –Ω–µ —Å—á–∏—Ç–∞–µ–º –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        try:
            if self._should_ignore_non_question_text(t):
                logger.debug("–ò–≥–Ω–æ—Ä–∏—Ä—É—é –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ç—Ä–∏–≥–≥–µ—Ä (–º—É–∑—ã–∫–∞ –∏ —Ç.–ø.)")
                return
        except Exception:
            pass
        # –†–µ–∂–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–∫—Ç-–∑–∞–º–µ—Ç–∫–∏ –¥–∞–∂–µ –±–µ–∑ —è–≤–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        if getattr(self, "_commentary_mode", False):
            try:
                facts = self._extract_commentary_facts(t)
            except Exception:
                facts = []
            if facts:
                items = facts[: min(3, len(facts))]
                self.thesis_prompter = ThesisPrompter(
                    theses=items,
                    match_threshold=self._thesis_match_threshold,
                    enable_semantic=False,
                    semantic_threshold=self._thesis_semantic_threshold,
                    semantic_model_id=self._thesis_semantic_model,
                    enable_gemini=True,
                    gemini_min_conf=self._thesis_gemini_min_conf,
                )
                self._thesis_done_notified = False
                logger.info(f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–Ω–æ–≤—ã–µ): {', '.join(items)}")
                self._announce_thesis()
                return
        # –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω LLM ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç —Å—Ä–∞–∑—É
        # –ò –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–¢–í–ï–¢ –ö–ê–ö –¢–ï–ó–ò–°!
        llm_answer = None
        if self.llm_enable and self._llm is not None:
            try:
                prompt = t
                ans = (self._llm.generate(prompt) or "").strip()
                if ans:
                    try:
                        ans = self._enforce_answer_then_question(ans)
                    except Exception:
                        pass
                    # –ü–æ –∂–µ–ª–∞–Ω–∏—é –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å –≤ –∫–æ–Ω–µ—Ü –æ—Ç–≤–µ—Ç–∞
                    if getattr(self, "_append_question_to_answer", False):
                        try:
                            import re
                            qs = self._extract_questions(t)
                            if qs:
                                q_joined = " ".join(qs).strip()
                                # –î–æ–±–∞–≤–∏–º –≤–æ–ø—Ä–æ—Å, –µ—Å–ª–∏ –µ–≥–æ –µ—â—ë –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ –æ—Ç–≤–µ—Ç–∞
                                norm = lambda x: re.sub(r"[\s\.!?]+", " ", (x or "").strip().lower())
                                if norm(q_joined) not in norm(ans):
                                    ans = f"{ans} {q_joined}".strip()
                        except Exception:
                            pass
                    logger.info(f"–û—Ç–≤–µ—Ç: {ans}")
                    self._speak_text(ans)
                    llm_answer = ans  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∫ —Ç–µ–∑–∏—Å
            except Exception as e:  # noqa: BLE001
                logger.exception(f"LLM –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ —Ç–µ–∑–∏—Å (–µ—Å–ª–∏ —ç—Ç–æ –ù–ï –æ—Ç–∫–∞–∑)
        if llm_answer:
            # –§–∏–ª—å—Ç—Ä—É–µ–º "–ø–ª–æ—Ö–∏–µ" –æ—Ç–≤–µ—Ç—ã - –Ω–µ —Å–æ–∑–¥–∞—ë–º —Ç–µ–∑–∏—Å –∏–∑ –Ω–∏—Ö
            bad_patterns = [
                "–Ω–µ —è—Å–µ–Ω",
                "–Ω–µ –ø–æ–Ω—è–ª",
                "–Ω–µ –ø–æ–Ω—è—Ç–µ–Ω", 
                "–ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π—Ç–µ",
                "—É—Ç–æ—á–Ω–∏—Ç–µ",
                "–Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å",
                "–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
            ]
            is_bad_answer = any(pattern.lower() in llm_answer.lower() for pattern in bad_patterns)
            
            if is_bad_answer:
                logger.warning(f"‚ö†Ô∏è –û—Ç–≤–µ—Ç LLM –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ–∑–∏—Å–∞ (–æ—Ç–∫–∞–∑): {llm_answer[:50]}...")
                # –ù–µ —Å–æ–∑–¥–∞—ë–º —Ç–µ–∑–∏—Å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—ã—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            else:
                # –£–ú–ù–ê–Ø –ó–ê–ú–ï–ù–ê: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞–±–æ—Ä —Ç–µ–∑–∏—Å–æ–≤
                # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Ç–µ–∑–∏—Å—ã - –í–°–ï–ì–î–ê –¥–æ–±–∞–≤–ª—è–µ–º (–Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ)
                has_pending = self.thesis_prompter is not None and self.thesis_prompter.has_pending()
                
                if has_pending:
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Ç–µ–∑–∏—Å—ã - –¥–æ–±–∞–≤–ª—è–µ–º –∫ –Ω–∏–º
                    should_replace = False
                    logger.debug("–ï—Å—Ç—å –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Ç–µ–∑–∏—Å—ã - –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π")
                else:
                    # –ï—Å–ª–∏ –≤—Å–µ —Ç–µ–∑–∏—Å—ã –∑–∞–∫—Ä—ã—Ç—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–º–µ–Ω—É —Ç–µ–º—ã
                    should_replace = self._should_replace_thesis_set(new_question=t, new_thesis=llm_answer)
                
                if should_replace or self.thesis_prompter is None:
                    # –°–æ–∑–¥–∞—ë–º –ù–û–í–´–ô –Ω–∞–±–æ—Ä —Ç–µ–∑–∏—Å–æ–≤ (—Å–º–µ–Ω–∞ —Ç–µ–º—ã)
                    self.thesis_prompter = ThesisPrompter(
                        theses=[llm_answer],
                        match_threshold=self._thesis_match_threshold,
                        enable_semantic=False,
                        semantic_threshold=self._thesis_semantic_threshold,
                        semantic_model_id=self._thesis_semantic_model,
                        enable_gemini=True,
                        gemini_min_conf=self._thesis_gemini_min_conf,
                    )
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –°–†–ê–ó–£ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
                    if self._last_question:
                        self.thesis_prompter._dialogue_context.append(("—ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä", self._last_question))
                    self._thesis_done_notified = False
                    logger.info(f"üîÑ –ù–û–í–´–ô –Ω–∞–±–æ—Ä —Ç–µ–∑–∏—Å–æ–≤ (—Å–º–µ–Ω–∞ —Ç–µ–º—ã): {llm_answer}")
                else:
                    # –î–û–ë–ê–í–õ–Ø–ï–ú –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–º—ã)
                    current_theses = getattr(self.thesis_prompter, "theses", [])
                    current_theses.append(llm_answer)
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 —Ç–µ–∑–∏—Å–æ–≤ –º–∞–∫—Å–∏–º—É–º
                    if len(current_theses) > 5:
                        current_theses = current_theses[-5:]
                        logger.debug("–û–≥—Ä–∞–Ω–∏—á–∏–ª–∏ –Ω–∞–±–æ—Ä –¥–æ 5 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–µ–∑–∏—Å–æ–≤")
                    self.thesis_prompter.theses = current_theses
                    logger.info(f"‚ûï –î–û–ë–ê–í–õ–ï–ù —Ç–µ–∑–∏—Å –∫ –Ω–∞–±–æ—Ä—É (–≤—Å–µ–≥–æ: {len(current_theses)}): {llm_answer}")
                
                self._announce_thesis()
                return
        # –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∑–∏—Å–æ–≤ —á–µ—Ä–µ–∑ AI
        if self._ai_only_thesis:
            theses = self._extract_theses_ai(t)
            if theses:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∑–∏—Å–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                limited_theses = theses[:min(3, len(theses))]
                self.thesis_prompter = ThesisPrompter(
                    theses=limited_theses,
                    match_threshold=self._thesis_match_threshold,
                    enable_semantic=False,
                    semantic_threshold=self._thesis_semantic_threshold,
                    semantic_model_id=self._thesis_semantic_model,
                    enable_gemini=True,
                    gemini_min_conf=self._thesis_gemini_min_conf,
                )
                self._thesis_done_notified = False
                logger.info(f"–¢–µ–∑–∏—Å—ã (–Ω–æ–≤—ã–µ): {', '.join(limited_theses)}")
                # –ê–Ω–æ–Ω—Å–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –æ–±—â–∏–π –º–µ—Ö–∞–Ω–∏–∑–º, —á—Ç–æ–±—ã –ø–∏—Å–∞–ª–æ—Å—å –≤ –ª–æ–≥–∏ –∏ —Ä–∞–±–æ—Ç–∞–ª –∞–≤—Ç–æ–ø–æ–≤—Ç–æ—Ä
                self._announce_thesis()
            else:
                logger.debug("–ò–ò –Ω–µ –Ω–∞—à—ë–ª –≤–æ–ø—Ä–æ—Å–æ–≤/—Ç–µ–∑–∏—Å–æ–≤ –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é")
            return
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤ - —É–ø—Ä–æ—â–∞–µ–º
        questions = self._extract_questions(t)
        questions = self._filter_questions_by_importance(questions)
        if questions:
            q_joined = " ".join(questions)
            self._append_question_context(q_joined)
            self._maybe_generate_theses()
        else:
            logger.debug("–ü—Ä–æ–ø—É—Å–∫–∞—é –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π/–Ω–µ-–≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞")

    @staticmethod
    def _answer_math_if_any(text: str) -> Optional[str]:
        """–†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –ø—Ä–æ—Å—Ç—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—Ä–∞–∑—ã –∏ —Å—Ç—Ä–æ–∏—Ç –æ—Ç–≤–µ—Ç.
        –°–µ–π—á–∞—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —à–∞–±–ª–æ–Ω: "<int> –≤ —Å—Ç–µ–ø–µ–Ω–∏ <int>".
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—É—é —Ñ—Ä–∞–∑—É –≤–∏–¥–∞: "<—Ä–µ–∑—É–ª—å—Ç–∞—Ç> –±—É–¥–µ—Ç <–æ—Å–Ω–æ–≤–∞–Ω–∏–µ> –≤ —Å—Ç–µ–ø–µ–Ω–∏ <–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å>".
        """
        if not text:
            return None
        import re
        t = text.strip().lower()
        # –ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–π –∏ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: —Ü–∏—Ñ—Ä—ã + "–≤ —Å—Ç–µ–ø–µ–Ω–∏" + —Ü–∏—Ñ—Ä—ã
        m = re.search(r"\b(\d{1,9})\s+–≤\s+—Å—Ç–µ–ø–µ–Ω[–µ–∏]\s+(\d{1,3})\b", t)
        if not m:
            return None
        try:
            base = int(m.group(1))
            exp = int(m.group(2))
        except Exception:
            return None
        # –ó–∞—â–∏—Ç–∞ –æ—Ç —á—Ä–µ–∑–º–µ—Ä–Ω–æ –±–æ–ª—å—à–∏—Ö —Ä–∞—Å—á—ë—Ç–æ–≤
        if exp > 1000:
            return None
        try:
            res = pow(base, exp)
        except Exception:
            return None
        # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—É—é —Ñ—Ä–∞–∑—É: —Å–Ω–∞—á–∞–ª–∞ –æ—Ç–≤–µ—Ç, –∑–∞—Ç–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏–µ
        base_w = None
        exp_w = None
        try:
            from num2words import num2words  # type: ignore
            base_w = num2words(base, lang="ru")
            exp_w = num2words(exp, lang="ru")
        except Exception:
            pass
        base_part = base_w if base_w else str(base)
        exp_part = exp_w if exp_w else str(exp)
        # –ï—Å–ª–∏ —á–∏—Å–ª–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º –≤—Å–µ —Ü–∏—Ñ—Ä—ã
        res_s = str(res)
        if len(res_s) > 30:
            # –î–∞–¥–∏–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –≤ –Ω–∞—É—á–Ω–æ–π —Ñ–æ—Ä–º–µ
            try:
                import math as _math
                # mantissa * 10^k
                k = len(res_s) - 1
                mantissa = float(res_s[0] + "." + res_s[1: min(6, len(res_s))])
                approx = f"–ø—Ä–∏–º–µ—Ä–Ω–æ {mantissa:.3f} –Ω–∞ –¥–µ—Å—è—Ç—å –≤ —Å—Ç–µ–ø–µ–Ω–∏ {k}"
                return f"{approx}. {base_part} –≤ —Å—Ç–µ–ø–µ–Ω–∏ {exp_part}."
            except Exception:
                return f"–ß–∏—Å–ª–æ –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–µ. {base_part} –≤ —Å—Ç–µ–ø–µ–Ω–∏ {exp_part}."
        return f"{res_s} –±—É–¥–µ—Ç {base_part} –≤ —Å—Ç–µ–ø–µ–Ω–∏ {exp_part}."

    def _should_replace_thesis_set(self, new_question: str, new_thesis: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á–µ—Ä–µ–∑ Gemini: –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞–±–æ—Ä —Ç–µ–∑–∏—Å–æ–≤ –Ω–∞ –Ω–æ–≤—ã–π,
        –∏–ª–∏ –Ω–æ–≤—ã–π —Ç–µ–∑–∏—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–æ–π –∂–µ —Ç–µ–º–µ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞).
        
        Returns:
            True - —Å–º–µ–Ω–∞ —Ç–µ–º—ã, –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞–±–æ—Ä
            False - –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–º—ã, –¥–æ–±–∞–≤–∏—Ç—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º
        """
        if self.thesis_prompter is None or not hasattr(self.thesis_prompter, "theses"):
            return True  # –ù–µ—Ç —Å—Ç–∞—Ä—ã—Ö —Ç–µ–∑–∏—Å–æ–≤ - —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä
        
        old_theses = getattr(self.thesis_prompter, "theses", [])
        if not old_theses:
            return True  # –ù–µ—Ç —Å—Ç–∞—Ä—ã—Ö —Ç–µ–∑–∏—Å–æ–≤ - —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä
        
        try:
            import json
            from google import genai  # type: ignore
            from google.genai import types  # type: ignore
            key = os.getenv("GEMINI_API_KEY")
            if not key:
                return True  # –ù–µ—Ç –∫–ª—é—á–∞ - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–º–µ–Ω—è–µ–º
            
            client = genai.Client(api_key=key)
            
            # –ü—Ä–æ–º–ø—Ç –¥–ª—è Gemini
            old_theses_text = "\n".join([f"- {t}" for t in old_theses])
            prompt = f"""–ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ –≤–æ–ø—Ä–æ—Å–æ–≤:

–¢–ï–ö–£–©–ò–ï –¢–ï–ó–ò–°–´:
{old_theses_text}

–ù–û–í–´–ô –í–û–ü–†–û–°:
{new_question}

–ù–û–í–´–ô –¢–ï–ó–ò–°:
{new_thesis}

–û–ø—Ä–µ–¥–µ–ª–∏: –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω —Å —Ç–µ–∫—É—â–∏–º–∏ —Ç–µ–∑–∏—Å–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–±–∞ –ø—Ä–æ –∫–æ—Å–º–æ–Ω–∞–≤—Ç–æ–≤, –∏—Å—Ç–æ—Ä–∏—é, –≥–µ–æ–≥—Ä–∞—Ñ–∏—é –∏ —Ç.–¥.) –∏–ª–∏ —ç—Ç–æ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–∞—è —Ç–µ–º–∞?

–í–ê–ñ–ù–û: –í–æ–ø—Ä–æ—Å—ã "–ü–µ—Ä–≤—ã–π —á–µ–ª–æ–≤–µ–∫ –≤ –∫–æ—Å–º–æ—Å–µ" –∏ "–ü–µ—Ä–≤–∞—è –∂–µ–Ω—â–∏–Ω–∞ –≤ –∫–æ—Å–º–æ—Å–µ" - —ç—Ç–æ –û–î–ù–ê —Ç–µ–º–∞ (–∫–æ—Å–º–æ–Ω–∞–≤—Ç–∏–∫–∞), –ø–æ—ç—Ç–æ–º—É decision="continue".

–û—Ç–≤–µ—Ç—å JSON:
{{"decision": "continue"}}  - –µ—Å–ª–∏ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω—ã (–¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–∑–∏—Å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º)
{{"decision": "replace"}}   - –µ—Å–ª–∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã (–∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞–±–æ—Ä)
"""
            
            cfg = types.GenerateContentConfig(
                system_instruction="–¢—ã - –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –û–ø—Ä–µ–¥–µ–ª—è–π —Å–º–µ–Ω—É —Ç–µ–º—ã —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.",
                max_output_tokens=50,
                temperature=0.1,
                response_mime_type="application/json",
                thinking_config=types.ThinkingConfig(thinking_budget=0),
            )
            
            resp = client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                config=cfg,
            )
            
            result = json.loads(resp.text)
            decision = result.get("decision", "replace")
            
            should_replace = (decision == "replace")
            logger.debug(f"ü§ñ Gemini —Ä–µ—à–µ–Ω–∏–µ: {decision} ({'–ó–ê–ú–ï–ù–ò–¢–¨' if should_replace else '–î–û–ë–ê–í–ò–¢–¨'})")
            return should_replace
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∑–∏—Å–æ–≤: {e}")
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–º–µ–Ω—è–µ–º (–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
            return True

    def _extract_commentary_facts(self, text: str) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ–∞–∫—Ç-–∑–∞–º–µ—Ç–æ–∫ –ø–æ —Ç–µ–º–µ —Ä–µ–ø–ª–∏–∫–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞.
        –î–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Ç—Ä–∞–∫—Ç JSON —á–µ—Ä–µ–∑ _parse_theses_from_raw.
        """
        t = (text or "").strip()
        if not t:
            return []
        try:
            import json
            from google import genai  # type: ignore
            from google.genai import types  # type: ignore
            key = os.getenv("GEMINI_API_KEY")
            if not key:
                return []
            client = genai.Client(api_key=key)

            def _call_and_parse(force_json_start: bool = False) -> List[str]:
                sys_instr = (
                    "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–∫–æ–º–º–µ–Ω—Ç–∞—Ç–æ—Ä. –°–ª—É—à–∞–π –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–ø–ª–∏–∫–∏ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ –∏ —Ñ–æ—Ä–º–∏—Ä—É–π"
                    " 2‚Äì3 –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö, —É–º–µ—Å—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç-–∑–∞–º–µ—Ç–∫–∏ –ø–æ —Ç–µ–º–µ (–∏—Å—Ç–æ—Ä–∏—è, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —Ü–∏—Ñ—Ä—ã)."
                    " –ï—Å–ª–∏ —Ç–µ–º–∞ –ª–∏—á–Ω–∞—è/–±—ã—Ç–æ–≤–∞—è –∏ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç ‚Äî –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫."
                    " –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ —Å—Ç—Ä–æ–≥–æ JSON: {\"theses\": [\"...\"]}."
                )
                if force_json_start:
                    sys_instr += " –û—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å —Å–∏–º–≤–æ–ª–∞ { –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ JSON."
                prompt = json.dumps({"transcript": t}, ensure_ascii=False)
                cfg = types.GenerateContentConfig(
                    system_instruction=sys_instr,
                    max_output_tokens=96,
                    temperature=0.2,
                    top_p=0.9,
                    thinking_config=types.ThinkingConfig(thinking_budget=0),
                    response_mime_type="application/json",
                )
                resp = client.models.generate_content(
                    model="gemini-2.5-flash-lite",
                    contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                    config=cfg,
                )
                raw = (resp.text or "").strip()
                return LiveVoiceVerifier._parse_theses_from_raw(raw, n_max=3)

            out = _call_and_parse(False)
            if not out:
                out = _call_and_parse(True)
            return out
        except Exception as e:  # noqa: BLE001
            logger.debug(f"Commentary extraction failed: {e}")
            return []

    @staticmethod
    def _should_ignore_non_question_text(text: str) -> bool:
        """–§–∏–ª—å—Ç—Ä —è–≤–Ω—ã—Ö –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞–¥–æ —Ç—Ä–∞–∫—Ç–æ–≤–∞—Ç—å –∫–∞–∫ –≤–æ–ø—Ä–æ—Å—ã.
        –ü—Ä–∏–º–µ—Ä—ã: "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –º—É–∑—ã–∫–∞" –∏ —Ç.–ø.
        """
        if not text:
            return False
        import re
        s = text.strip().lower()
        patterns = [
            r"\b–¥–∏–Ω–∞–º–∏—á\w*\s+–º—É–∑—ã–∫\w*\b",
        ]
        for p in patterns:
            try:
                if re.search(p, s):
                    return True
            except Exception:
                continue
        return False

    @staticmethod
    def _enforce_answer_then_question(text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç-–æ—Ç–≤–µ—Ç.
        –†–∞–∑–¥–µ–ª—è–µ—Ç –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π.
        –ï—Å–ª–∏ —É—Ç–≤–µ—Ä–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.
        """
        if not text:
            return text
        import re
        s = text.strip()
        s = re.sub(r"\s+", " ", s)
        parts = re.split(r"([\.!?]+\s+)", s)
        sentences: list[str] = []
        for i in range(0, len(parts), 2):
            chunk = parts[i].strip()
            sep = parts[i + 1] if i + 1 < len(parts) else ""
            sent = (chunk + (sep or "")).strip()
            if sent:
                sentences.append(sent)
        if not sentences:
            return s

        def _is_question_like(t: str) -> bool:
            if not t:
                return False
            t2 = t.strip().lower()
            if t2.endswith("?"):
                return True
            # –ß–∞—Å—Ç—ã–µ —Ä—É—Å—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–∞–∂–µ –±–µ–∑ –∑–Ω–∞–∫–∞ –≤–æ–ø—Ä–æ—Å–∞
            patterns = [
                r"^–∫—Ç–æ\b", r"^—á—Ç–æ\b", r"^–∫–æ–≥–¥–∞\b", r"^–≥–¥–µ\b", r"^–ø–æ—á–µ–º—É\b", r"^–∑–∞—á–µ–º\b",
                r"^–∫–∞–∫\b", r"^–∫–∞–∫–æ–π\b", r"^–∫–∞–∫–æ–≤–∞\b", r"^–∫–æ—Ç–æ—Ä\w*\b", r"^—Å–∫–æ–ª—å–∫–æ\b",
                r"^–≤ –∫–∞–∫–æ–º –≥–æ–¥—É\b", r"^–ø—Ä–∞–≤–¥–∞ –ª–∏\b", r"^–º–æ–∂–Ω–æ –ª–∏\b", r"^–≤–µ—Ä–Ω–æ –ª–∏\b",
            ]
            for p in patterns:
                try:
                    if re.search(p, t2):
                        return True
                except Exception:
                    continue
            return False

        declarative: list[str] = []
        questions: list[str] = []
        for sent in sentences:
            if _is_question_like(sent):
                questions.append(sent)
            else:
                declarative.append(sent)
        if not declarative:
            return s
        out = " ".join(declarative).strip()
        return out

    def _handle_self_transcript(self, transcript: Optional[str]) -> None:
        t = (transcript or "").strip()
        if not t:
            return
        logger.info(f"–ú–æ—è —Ä–µ—á—å (ASR): {t}")
        if self.thesis_prompter is None:
            logger.debug("–¢–µ–∑–∏—Å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑")
            return
        if self.thesis_prompter.consume_transcript(t, role="—Å—Ç—É–¥–µ–Ω—Ç"):
            logger.info("–¢–µ–∑–∏—Å –∑–∞–∫—Ä—ã—Ç")
            if not self.thesis_prompter.has_pending():
                self._maybe_generate_theses()
            else:
                self._announce_thesis()
            return
        try:
            cov = self.thesis_prompter.coverage_of_current()
            logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ–∑–∏—Å–∞: {int(cov*100)}%")
        except Exception:
            pass
        self._announce_thesis()

    def simulate_dialogue(self, events: List[tuple[str, str]]) -> None:
        """–ü—Ä–æ–≥–æ–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–µ–ø–ª–∏–∫ –±–µ–∑ –∞—É–¥–∏–æ.

        events: —Å–ø–∏—Å–æ–∫ ("self"|"other", —Ç–µ–∫—Å—Ç), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–æ–≥–Ω–∞—Ç—å
        –∫–æ–Ω–≤–µ–π–µ—Ä —Å –≥–æ—Ç–æ–≤—ã–º–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞–º–∏. –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤.
        """
        for role, content in events:
            kind = (role or "").strip().lower()
            if kind in {"self", "me", "candidate"}:
                self._handle_self_transcript(content)
            elif kind in {"other", "interviewer", "question"}:
                self._handle_foreign_text(content)
        if (
            self.thesis_prompter is not None
            and self.thesis_prompter.has_pending()
            and self.thesis_prompter.need_announce()
        ):
            self._announce_thesis()

    # ==== –ê—É–¥–∏–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: –ø—Ä–æ—Å—Ç–æ–π highpass + AGC –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ====
    @staticmethod
    def _highpass_simple(wav: np.ndarray, sr: int = SAMPLE_RATE, cutoff_hz: int = 80) -> np.ndarray:
        if wav.ndim != 1:
            wav = wav.reshape(-1)
        # –û–¥–Ω–æ–ø–æ–ª—é—Å–Ω—ã–π HPF
        rc = 1.0 / (2 * np.pi * float(cutoff_hz))
        dt = 1.0 / float(sr)
        alpha = rc / (rc + dt)
        y = np.zeros_like(wav, dtype=np.float32)
        prev_y = 0.0
        prev_x = 0.0
        for i in range(wav.size):
            x = float(wav[i])
            hp = alpha * (prev_y + x - prev_x)
            y[i] = hp
            prev_y = hp
            prev_x = x
        return y

    @staticmethod
    def _apply_agc(wav: np.ndarray, target_rms: float = 0.03, max_gain: float = 10.0) -> np.ndarray:
        if wav.ndim != 1:
            wav = wav.reshape(-1)
        rms = float(np.sqrt(np.mean(np.square(wav)) + 1e-12))
        if rms <= 1e-6:
            return wav
        gain = min(max_gain, max(0.1, target_rms / rms))
        out = np.clip(wav * gain, -1.0, 1.0)
        return out.astype(np.float32)

    @staticmethod
    def _preprocess_segment(wav: np.ndarray, sr: int = SAMPLE_RATE) -> np.ndarray:
        y = LiveVoiceVerifier._highpass_simple(wav, sr=sr, cutoff_hz=80)
        y = LiveVoiceVerifier._apply_agc(y, target_rms=0.03)
        return y

    # ==== –£—Å—Ç–æ–π—á–∏–≤—ã–π –ø–∞—Ä—Å–µ—Ä —Ç–µ–∑–∏—Å–æ–≤ –∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ ====
    @staticmethod
    def _parse_theses_from_raw(raw: str, n_max: int = 3) -> List[str]:
        import json, re
        s = (raw or "").strip()
        if not s:
            return []
        # –£–±–µ—Ä—ë–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ–±—Ä–∞–º–ª—è—é—â–∏–µ –∫–∞–≤—ã—á–∫–∏, –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –µ—Å—Ç—å —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏
        if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
            if '{' in s and '}' in s:
                s = s[1:-1].strip()

        def _from_dict(d: dict) -> List[str]:
            items = d.get("theses", []) if isinstance(d, dict) else []
            out: List[str] = []
            for it in items:
                if isinstance(it, str):
                    t = it.strip()
                    if t:
                        out.append(t)
            return out

        # –°–Ω–∏–º–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ code fences ```...```
        if s.startswith("```"):
            # –≤–æ–∑—å–º—ë–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–µ–∂–¥—É –ø–µ—Ä–≤–æ–π –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç—Ä–æ–π–Ω–æ–π –∫–∞–≤—ã—á–∫–æ–π
            m = re.findall(r"```[a-zA-Z]*\n([\s\S]*?)\n```", s)
            if m:
                s = m[-1].strip()

        # –ü–æ–ø—ã—Ç–∫–∞ 1: –ø—Ä—è–º–æ–π JSON / –∏–ª–∏ JSON-—Å—Ç—Ä–æ–∫–∞
        try:
            obj = json.loads(s)
            if isinstance(obj, str):
                # –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞ JSON
                try:
                    obj2 = json.loads(obj)
                    if isinstance(obj2, dict):
                        vals = _from_dict(obj2)
                        if vals:
                            return vals[:n_max]
                except Exception:
                    pass
            elif isinstance(obj, dict):
                vals = _from_dict(obj)
                if vals:
                    return vals[:n_max]
            elif isinstance(obj, list):
                # –∏–Ω–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—ë—Ç –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
                out: List[str] = []
                for it in obj:
                    if isinstance(it, str):
                        t = it.strip()
                        if t:
                            out.append(t)
                if out:
                    return out[:n_max]
        except Exception:
            pass

        # –ü–æ–ø—ã—Ç–∫–∞ 2: –≤—ã—Ç–∞—â–∏—Ç—å –ø–µ—Ä–≤—ã–π JSON-–æ–±—ä–µ–∫—Ç –ø–æ —Ñ–∏–≥—É—Ä–Ω—ã–º —Å–∫–æ–±–∫–∞–º
        try:
            start = s.find("{")
            end = s.rfind("}")
            if start != -1 and end != -1 and end > start:
                sub = s[start : end + 1]
                d = json.loads(sub)
                vals = _from_dict(d)
                if vals:
                    return vals[:n_max]
        except Exception:
            pass

        # –ü–æ–ø—ã—Ç–∫–∞ 3: —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
        parts: List[str] = []
        s2 = s.replace(";", "\n")
        for line in s2.splitlines():
            t = line.strip()
            # –£–±–µ—Ä—ë–º –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤ –∏ –Ω—É–º–µ—Ä–∞—Ü–∏—é
            t = re.sub(r"^[\-‚Ä¢*\s]*", "", t)
            t = re.sub(r"^\d+[\).]\s*", "", t)
            # –û—Ç–±—Ä–æ—Å–∏–º —è–≤–Ω—ã–µ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if not t or t in {"[", "]", "{", "}", "},", "],"}:
                continue
            # –ü—Ä–æ–ø—É—Å—Ç–∏–º —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è/–∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–µ—Å—è —Å–∫–æ–±–∫–∞–º–∏ ‚Äî —ç—Ç–æ, –≤–µ—Ä–æ—è—Ç–Ω–æ, JSON
            if t.startswith("{") or t.startswith("[") or t.endswith("}") or t.endswith("]"):
                continue
            # –£–±–µ—Ä—ë–º –∑–∞–≤–µ—Ä—à–∞—é—â–∏–µ –∑–∞–ø—è—Ç—ã–µ
            if t.endswith(","):
                t = t[:-1].strip()
            # –£–±–µ—Ä—ë–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
            if (t.startswith('"') and t.endswith('"')) or (t.startswith("'") and t.endswith("'")):
                t = t[1:-1].strip()
            # –ü—Ä–æ–ø—É—Å—Ç–∏–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ key: value (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ JSON-–∫–ª—é—á–∏, –Ω–∞–ø—Ä. "theses": [)
            if re.match(r'^"?[A-Za-z_][\w\s\-]*"?\s*:\s*', t):
                continue
            # –ü—Ä–æ–ø—É—Å—Ç–∏–º –ø—É—Å—Ç—è–∫–æ–≤—ã–µ —Å–∫–æ–±–∫–∏
            if t in {"[", "]"}:
                continue
            # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç c –±—É–∫–≤–∞–º–∏
            if not any(ch.isalpha() for ch in t):
                continue
            parts.append(t)
        return parts[:n_max]

    def _collect_enrollment_audio(
        self,
        seconds: float = 5.0,
        min_voiced_seconds: float = 2.0,
        silence_stop_sec: float = 1.2,
    ) -> np.ndarray:
        """–°–æ–±–∏—Ä–∞–µ–º —Å–∏–≥–Ω–∞–ª —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ–∑–≤—É—á–µ–Ω–Ω—ã–µ (VAD) —Ñ—Ä–µ–π–º—ã."""
        q: "queue.Queue[np.ndarray]" = queue.Queue()

        def callback(indata, frames, time_info, status):  # noqa: ANN001
            if status:
                logger.warning(f"InputStream status: {status}")
            q.put(indata.copy())

        voiced_samples: List[np.ndarray] = []
        voiced_duration = 0.0
        silence_stop_sec = max(0.6, float(silence_stop_sec))
        target_end = time.time() + max(1.0, float(seconds))
        last_voiced_ts: Optional[float] = None

        with sd.InputStream(
            channels=CHANNELS,
            samplerate=SAMPLE_RATE,
            dtype="float32",
            blocksize=FRAME_SIZE,  # deliver 20ms blocks
            callback=callback,
        ):
            logger.info("–ì–æ–≤–æ—Ä–∏—Ç–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –ø—Ä–æ—Ñ–∏–ª—è...")
            while True:
                now = time.time()
                if now >= target_end:
                    logger.debug("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –ø—Ä–æ—Ñ–∏–ª—è: –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
                    break
                if (
                    voiced_duration >= min_voiced_seconds
                    and last_voiced_ts is not None
                    and (now - last_voiced_ts) >= silence_stop_sec
                ):
                    logger.debug("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –ø—Ä–æ—Ñ–∏–ª—è: –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ —Ç–∏—à–∏–Ω–∞ –ø–æ—Å–ª–µ —Ä–µ—á–∏")
                    break
                try:
                    block = q.get(timeout=0.5)[:, 0]  # mono
                except queue.Empty:
                    continue
                # VAD on 20ms subframes
                # block may be larger than FRAME_SIZE if sounddevice batches; split it
                i = 0
                while i + FRAME_SIZE <= len(block):
                    frame = block[i : i + FRAME_SIZE]
                    i += FRAME_SIZE
                    is_speech = self._vad_fn(frame)
                    if is_speech:
                        voiced_samples.append(frame)
                        voiced_duration += FRAME_MS / 1000.0
                        last_voiced_ts = time.time()

        if voiced_duration < min_voiced_seconds:
            logger.warning(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—á–∏ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è: {voiced_duration:.2f}s < {min_voiced_seconds:.2f}s"
            )

        if len(voiced_samples) == 0:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –≥–æ–ª–æ—Å –¥–ª—è —ç–Ω—Ä–æ–ª–ª–º–µ–Ω—Ç–∞")

        logger.info(
            "–°–µ–≥–º–µ–Ω—Ç –ø—Ä–æ—Ñ–∏–ª—è —Å–æ–±—Ä–∞–Ω: –æ–∑–≤—É—á–µ–Ω–æ {dur:.2f}s, –∫–∞–¥—Ä–æ–≤ {frames}",
            dur=voiced_duration,
            frames=len(voiced_samples),
        )

        return np.concatenate(voiced_samples, axis=0)

    def enroll(
        self,
        path: Path,
        seconds: float = 20.0,
        min_voiced_seconds: float = 2.0,
        silence_stop_sec: float = 1.2,
    ) -> VoiceProfile:
        wav = self._collect_enrollment_audio(
            seconds=seconds,
            min_voiced_seconds=min_voiced_seconds,
            silence_stop_sec=silence_stop_sec,
        )
        emb = self.embedding_from_waveform(wav)
        profile = VoiceProfile(embedding=emb)
        profile.save(path)
        logger.info(f"–ü—Ä–æ—Ñ–∏–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path}")
        return profile

    def live_verify(
        self,
        profile: VoiceProfile,
        min_segment_ms: int = 500,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        max_silence_ms: int = 400,  # –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –ø–∞—É–∑—ã
        pre_roll_ms: int = 160,     # –ø—Ä–µ–¥–∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –¥–æ —Å—Ç–∞—Ä—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
        run_seconds: float = 0.0,   # –∞–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ (0 = –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ)
    ) -> None:
        """–°–ª—É—à–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º —Ä–µ—á–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        —Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ —Ä–µ—à–∞–µ–º: –º–æ–π –≥–æ–ª–æ—Å –∏–ª–∏ –Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å.
        –ü–µ—á–∞—Ç–∞–µ–º –≤—ã–≤–æ–¥ —Å—Ä–∞–∑—É –≤ –∫–æ–Ω—Å–æ–ª—å.
        """

        q: "queue.Queue[np.ndarray]" = queue.Queue()

        def callback(indata, frames, time_info, status):  # noqa: ANN001
            if status:
                logger.warning(f"InputStream status: {status}")
            q.put(indata.copy())

        seg_audio: List[np.ndarray] = []
        pre_frames: List[np.ndarray] = []  # –±—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–∞–ø–ª–∏–≤–∞–Ω–∏—è –ø–æ–¥—Ä—è–¥ —Ä–µ—á–µ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤ –¥–æ —Å—Ç–∞—Ä—Ç–∞
        # –ë—É—Ñ–µ—Ä –ø—Ä–µ–¥–∑–∞—Ö–≤–∞—Ç–∞: –ø–æ—Å–ª–µ–¥–Ω–∏–µ pre_roll_ms –¥–æ —Å—Ç–∞—Ä—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
        pre_roll_frames_cnt = max(0, int(np.ceil(pre_roll_ms / FRAME_MS)))
        pre_roll = deque(maxlen=pre_roll_frames_cnt)
        voiced_ms = 0
        silence_ms = 0
        in_speech = False
        consec_speech = 0

        logger.info(
            "–°—Ç–∞—Ä—Ç –ª–∞–π–≤-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è. –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏. –ì–æ–≤–æ—Ä–∏—Ç–µ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω."
        )
        # –ù–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∑–∏—Å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ - –∂–¥—ë–º –≤–æ–ø—Ä–æ—Å–∞

        stop_at = time.time() + run_seconds if run_seconds and run_seconds > 0 else None
        try:
            self._start_segment_worker()
            with sd.InputStream(
                channels=CHANNELS,
                samplerate=SAMPLE_RATE,
                dtype="float32",
                blocksize=FRAME_SIZE,  # deliver 20ms blocks
                callback=callback,
            ):
                while True:
                    if stop_at is not None and time.time() >= stop_at:
                        logger.info("–ê–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ —Ç–∞–π–º–µ—Ä—É run_seconds")
                        break
                    try:
                        block = q.get(timeout=0.5)[:, 0]
                    except queue.Empty:
                        continue

                    # –µ—Å–ª–∏ —Å–µ–π—á–∞—Å –∏–¥—ë—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ TTS ‚Äî –≥–ª—É—à–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (–∏–∑–±–µ–≥–∞–µ–º —Å–∞–º–æ–ø–æ–¥—Ö–≤–∞—Ç–∞)
                    if time.time() < self._suppress_until:
                        continue

                    i = 0
                    while i + FRAME_SIZE <= len(block):
                        frame = block[i : i + FRAME_SIZE]
                        # –æ–±–Ω–æ–≤–ª—è–µ–º pre-roll –≤—Å–µ–≥–¥–∞ (–≤ —Ç–æ–º —á–∏—Å–ª–µ –≤ —Ç–∏—à–∏–Ω–µ)
                        if pre_roll_frames_cnt > 0:
                            pre_roll.append(frame.copy())
                        i += FRAME_SIZE
                        is_speech = self._vad_fn(frame)

                        if is_speech:
                            consec_speech += 1
                            if not in_speech:
                                # –µ—â—ë –Ω–µ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª–∏ —Å–µ–≥–º–µ–Ω—Ç: –∫–æ–ø–∏–º pre_frames
                                pre_frames.append(frame)
                                if consec_speech >= self.min_consec_speech_frames:
                                    # —Å—Ç–∞—Ä—Ç —Å–µ–≥–º–µ–Ω—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–∑–∞—Ö–≤–∞—Ç, –∑–∞—Ç–µ–º pre_frames
                                    if pre_roll_frames_cnt > 0 and len(pre_roll) > 0:
                                        seg_audio.extend(list(pre_roll))
                                        pre_roll.clear()
                                    seg_audio.extend(pre_frames)
                                    pre_frames.clear()
                                    in_speech = True
                                    voiced_ms = self.min_consec_speech_frames * FRAME_MS
                            else:
                                seg_audio.append(frame)
                                voiced_ms += FRAME_MS
                            silence_ms = 0
                        else:
                            consec_speech = 0
                            pre_frames.clear()
                            if in_speech:
                                silence_ms += FRAME_MS

                        # –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞
                        if in_speech and silence_ms >= max_silence_ms:
                            in_speech = False
                            total_ms = voiced_ms
                            wav = (
                                np.concatenate(seg_audio, axis=0)
                                if len(seg_audio) > 0
                                else np.array([], dtype=np.float32)
                            )
                            seg_audio.clear()
                            voiced_ms = 0
                            silence_ms = 0

                            if total_ms < min_segment_ms or wav.size < FRAME_SIZE:
                                # —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                                continue

                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–±—Ä–∞–∫–æ–≤–∫–∞ —à—É–º–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–π –ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ—Å—Ç–∏
                            sf_med = median_spectral_flatness(wav, SAMPLE_RATE)
                            if sf_med >= self.flatness_reject_threshold:
                                # —à—É–º–æ–ø–æ–¥–æ–±–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–µ–∑ –≤—ã–≤–æ–¥–∞
                                continue

                            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: highpass + AGC
                            wav = self._preprocess_segment(wav, sr=SAMPLE_RATE)

                            # —Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
                            emb = self.embedding_from_waveform(wav)
                            dist = self.cosine_distance(emb, profile.embedding)
                            if dist <= self.threshold:
                                self._enqueue_segment("self", wav, dist)
                            else:
                                self._enqueue_segment("other", wav, dist)

                        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π —Ç–µ–∑–∏—Å, –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–∫—Ä—ã—Ç (–µ—Å–ª–∏ –Ω–µ—Ç —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ–ª—è)
                        try:
                            if (
                                self.thesis_prompter is not None
                                and self.thesis_prompter.has_pending()
                                and (time.time() - self._last_announce_ts) >= self._thesis_repeat_sec
                                and time.time() >= self._suppress_until
                                and not (self._thesis_repeat_worker and self._thesis_repeat_worker.is_alive())
                            ):
                                self.thesis_prompter.reset_announcement()
                                self._announce_thesis()
                        except Exception:
                            pass

        except KeyboardInterrupt:
            logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        finally:
            self._stop_segment_worker()

    def _ensure_asr(self) -> FasterWhisperTranscriber:
        if self._asr is None:
            if FasterWhisperTranscriber is None:
                raise RuntimeError("ASR –º–æ–¥—É–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            self._asr = FasterWhisperTranscriber(
                model_size=self.asr_model_size,
                device=self.asr_device,
                compute_type=self.asr_compute_type,
                language=self.asr_language,
            )
        return self._asr  # type: ignore[return-value]

    def _speak_text(self, text: str) -> None:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ TTS –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚Äî –≤—ã—Ö–æ–¥–∏–º
        if not text or self._tts is None:
            return
        try:
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º JSON-–ø–æ–¥–æ–±–Ω—ã–µ –∫–ª—é—á–∏ –∏ –ø—É—Å—Ç—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            s = (text or "").strip()
            if not s:
                return
            # –£–¥–∞–ª–∏–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
            if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
                s = s[1:-1].strip()
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ: –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ,
            # –∞ —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ–º –µ–≥–æ
            try:
                if "–ø—Ä—è–º—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ" in s.lower():
                    logger.info("–ø—Ä—è–º—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                    return
            except Exception:
                # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –¥–∞–∂–µ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ
                # —Å—Ç—Ä–æ–∫–∏ ‚Äî –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ª–æ–≥–∏–∫—É
                pass
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "theses": [], –∞ —Ç–∞–∫–∂–µ –ª—é–±—ã–µ –∫–ª—é—á: –∑–Ω–∞—á–µ–Ω–∏–µ –±–µ–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            import re as _re
            if _re.match(r'^"?\w+"?\s*:\s*(\[.*\]|\{.*\}|".*"|\d+|true|false|null)?\s*$', s, flags=_re.IGNORECASE):
                return
            # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –±—É–∫–≤—ã (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞)
            if not any(ch.isalpha() for ch in s):
                return
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ—Ä–∞–∑—ã, —á—Ç–æ–±—ã TTS –Ω–µ –æ–±—Ä–µ–∑–∞–ª—Å—è –∏ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª –±—ã—Å—Ç—Ä–µ–µ
            def _split_for_tts(t: str, max_len: int = 180) -> list[str]:
                parts: list[str] = []
                # –¥–µ–ª–∏–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                sent = _re.split(r'([\.\!\?]+\s+)', t)
                buf = ""
                for i in range(0, len(sent), 2):
                    chunk = sent[i]
                    sep = sent[i + 1] if i + 1 < len(sent) else ""
                    piece = (chunk + sep).strip()
                    if not piece:
                        continue
                    if len((buf + " " + piece).strip()) <= max_len:
                        buf = (buf + " " + piece).strip()
                    else:
                        if buf:
                            parts.append(buf)
                        if len(piece) > max_len:
                            words = piece.split()
                            cur = ""
                            for w in words:
                                if len((cur + " " + w).strip()) <= max_len:
                                    cur = (cur + " " + w).strip()
                                else:
                                    if cur:
                                        parts.append(cur)
                                    cur = w
                            if cur:
                                parts.append(cur)
                            buf = ""
                        else:
                            buf = piece
                if buf:
                    parts.append(buf)
                return parts or [t]

            chunks = _split_for_tts(s)

            for part in chunks:
                audio = self._tts.synth(part)
                if audio.size <= 0:
                    continue
                duration = float(audio.shape[0]) / float(self._tts.sample_rate)
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º suppress –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—É—à–Ω–∏–∫–∏
                # (–≤ –Ω–∞—É—à–Ω–∏–∫–∞—Ö –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞)
                if not self._use_headphones:
                    self._suppress_until = time.time() + duration + 2.5
                    logger.debug(f"–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ {duration + 2.5:.1f}—Å (–¥–∏–Ω–∞–º–∏–∫–∏)")
                else:
                    logger.debug(f"–ù–∞—É—à–Ω–∏–∫–∏ - –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞")
                if self._audio_sink is not None:
                    import io, wave
                    pcm16 = (np.clip(audio, -1.0, 1.0) * 32767.0).astype(np.int16)
                    buf = io.BytesIO()
                    with wave.open(buf, "wb") as wf:
                        wf.setnchannels(1)
                        wf.setsampwidth(2)
                        wf.setframerate(int(self._tts.sample_rate))
                        wf.writeframes(pcm16.tobytes())
                    wav_bytes = buf.getvalue()
                    try:
                        self._audio_sink(wav_bytes, int(self._tts.sample_rate))
                    except Exception as _e:  # noqa: F841, BLE001
                        logger.debug("Audio sink send failed", _e)
                else:
                    if sd is None:
                        continue
                    sd.stop()
                    # –í–ê–ñ–ù–û: self._is_announcing –±–ª–æ–∫–∏—Ä—É–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Ç–µ–∑–∏—Å–æ–≤
                    # –°–ø–∏–º –ø–æ–ª–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ —á—Ç–æ–±—ã –¥–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    sd.play(audio, samplerate=self._tts.sample_rate)
                    time.sleep(duration + 0.1)  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
        except Exception as e:  # noqa: BLE001
            logger.exception(f"TTS –æ—à–∏–±–∫–∞: {e}")

    # ==== –õ–∞–π–≤ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–æ—Ç–æ–∫–∞ –∫–∞–¥—Ä–æ–≤ (20–º—Å) ====
    def live_verify_stream(
        self,
        profile: VoiceProfile,
        frame_queue: "queue.Queue[np.ndarray]",
        min_segment_ms: int = 500,
        max_silence_ms: int = 400,
        pre_roll_ms: int = 160,
        run_seconds: float = 0.0,
        stop_event: Optional[threading.Event] = None,
    ) -> None:
        """–ê–Ω–∞–ª–æ–≥ live_verify, –Ω–æ –≤–º–µ—Å—Ç–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ —á–∏—Ç–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏ frame_queue.
        –í –æ—á–µ—Ä–µ–¥—å –¥–æ–ª–∂–Ω—ã –ø–æ—Å—Ç—É–ø–∞—Ç—å –º–æ–Ω–æ float32 —Ñ—Ä–µ–π–º—ã –¥–ª–∏–Ω–æ–π FRAME_SIZE (= 20–º—Å @ 16–∫–ì—Ü)."""
        logger.info("–°—Ç–∞—Ä—Ç –ª–∞–π–≤-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–≤–Ω–µ—à–Ω–∏–π –ø–æ—Ç–æ–∫ –∫–∞–¥—Ä–æ–≤)")
        seg_audio: List[np.ndarray] = []
        pre_frames: List[np.ndarray] = []
        pre_roll_frames_cnt = max(0, int(np.ceil(pre_roll_ms / FRAME_MS)))
        pre_roll = deque(maxlen=pre_roll_frames_cnt)
        voiced_ms = 0
        silence_ms = 0
        in_speech = False
        consec_speech = 0

        stop_at = time.time() + run_seconds if run_seconds and run_seconds > 0 else None
        try:
            self._start_segment_worker()
            leftover: Optional[np.ndarray] = None
            while True:
                if stop_event is not None and stop_event.is_set():
                    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ live_verify_stream –ø–æ —Å–∏–≥–Ω–∞–ª—É stop_event")
                    break
                if stop_at is not None and time.time() >= stop_at:
                    logger.info("–ê–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ live_verify_stream –ø–æ —Ç–∞–π–º–µ—Ä—É run_seconds")
                    break
                try:
                    block = frame_queue.get(timeout=0.5)
                except queue.Empty:
                    continue

                # –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å–∞–º–æ–ø–æ–¥—Ö–≤–∞—Ç–∞ –≤–æ –≤—Ä–µ–º—è –æ–∑–≤—É—á–∫–∏
                if time.time() < self._suppress_until:
                    continue

                # —Å–∫–ª–µ–∏–º —Å —Ö–≤–æ—Å—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –±–ª–æ–∫–∞, –µ—Å–ª–∏ –±—ã–ª
                if leftover is not None and leftover.size > 0:
                    block = np.concatenate([leftover, block.astype(np.float32).reshape(-1)])
                    leftover = None
                else:
                    block = block.astype(np.float32).reshape(-1)

                i = 0
                n = block.shape[0]
                while i + FRAME_SIZE <= n:
                    frame = block[i : i + FRAME_SIZE]
                    i += FRAME_SIZE
                    if pre_roll_frames_cnt > 0:
                        pre_roll.append(frame.copy())
                    is_speech = self._vad_fn(frame)
                    if is_speech:
                        consec_speech += 1
                        if not in_speech:
                            pre_frames.append(frame)
                            if consec_speech >= self.min_consec_speech_frames:
                                if pre_roll_frames_cnt > 0 and len(pre_roll) > 0:
                                    seg_audio.extend(list(pre_roll))
                                    pre_roll.clear()
                                seg_audio.extend(pre_frames)
                                pre_frames.clear()
                                in_speech = True
                                voiced_ms = self.min_consec_speech_frames * FRAME_MS
                        else:
                            seg_audio.append(frame)
                            voiced_ms += FRAME_MS
                        silence_ms = 0
                    else:
                        consec_speech = 0
                        pre_frames.clear()
                        if in_speech:
                            silence_ms += FRAME_MS

                    if in_speech and silence_ms >= max_silence_ms:
                        in_speech = False
                        total_ms = voiced_ms
                        wav = (
                            np.concatenate(seg_audio, axis=0)
                            if len(seg_audio) > 0
                            else np.array([], dtype=np.float32)
                        )
                        seg_audio.clear()
                        voiced_ms = 0
                        silence_ms = 0
                        if total_ms < min_segment_ms or wav.size < FRAME_SIZE:
                            continue
                        sf_med = median_spectral_flatness(wav, SAMPLE_RATE)
                        if sf_med >= self.flatness_reject_threshold:
                            continue
                        wav = self._preprocess_segment(wav, sr=SAMPLE_RATE)
                        emb = self.embedding_from_waveform(wav)
                        dist = self.cosine_distance(emb, profile.embedding)
                        if dist <= self.threshold:
                            self._enqueue_segment("self", wav, dist)
                        else:
                            self._enqueue_segment("other", wav, dist)

                    # –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø–æ–≤—Ç–æ—Ä —Ç–µ–∑–∏—Å–∞ (–µ—Å–ª–∏ –Ω–µ—Ç —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ–ª—è)
                    try:
                        if (
                            self.thesis_prompter is not None
                            and self.thesis_prompter.has_pending()
                            and (time.time() - self._last_announce_ts) >= self._thesis_repeat_sec
                            and time.time() >= self._suppress_until
                            and not (self._thesis_repeat_worker and self._thesis_repeat_worker.is_alive())
                        ):
                            self.thesis_prompter.reset_announcement()
                            self._announce_thesis()
                    except Exception:
                        pass

                # —Å–æ—Ö—Ä–∞–Ω–∏–º —Ö–≤–æ—Å—Ç, –µ—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ–ø–æ–ª–Ω—ã–π –∫–∞–¥—Ä
                if i < n:
                    leftover = block[i:]
                else:
                    leftover = None
        except KeyboardInterrupt:
            logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        finally:
            self._stop_segment_worker()

    def _append_question_context(self, text: str) -> None:
        if not text:
            return
        if self._question_context:
            self._question_context += "\n"
        self._question_context += text.strip()
        # –û–≥—Ä–∞–Ω–∏—á–∏–º –æ–∫–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–∏–º–≤–æ–ª–æ–≤
        if len(self._question_context) > self._max_question_context_chars:
            self._question_context = self._question_context[-self._max_question_context_chars :]

    def _maybe_generate_theses(self) -> None:
        if not self._thesis_autogen_enable or self._thesis_generator is None:
            return
        need_new_batch = False
        if self.thesis_prompter is None:
            need_new_batch = True
        else:
            if not self.thesis_prompter.has_pending():
                need_new_batch = True
        if not need_new_batch:
            return
        qtext = self._question_context.strip()
        if not qtext:
            return
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ–Ω—å—à–µ —Ç–µ–∑–∏—Å–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (2-3 –≤–º–µ—Å—Ç–æ 4)
            candidates = self._thesis_generator.generate(qtext, n=min(3, self._thesis_autogen_batch), language="ru")
        except Exception as e:  # noqa: BLE001
            logger.exception(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∑–∏—Å–æ–≤: {e}")
            return
        # –ë—ã—Å—Ç—Ä–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–µ–π 
        new_items: list[str] = []
        for c in candidates:
            key = c.strip().lower()
            if not key or key in self._theses_history:
                continue
            self._theses_history.add(key)
            new_items.append(c.strip())
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∑–∏—Å–æ–≤
            if len(new_items) >= 3:
                break
        if not new_items:
            return
        # –°–æ–∑–¥–∞—ë–º —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        self.thesis_prompter = ThesisPrompter(
            theses=new_items,
            match_threshold=self._thesis_match_threshold,
            enable_semantic=False,
            semantic_threshold=self._thesis_semantic_threshold,
            semantic_model_id=self._thesis_semantic_model,
            enable_gemini=True,
            gemini_min_conf=self._thesis_gemini_min_conf,
        )
        self._thesis_done_notified = False
        logger.info(f"–¢–µ–∑–∏—Å—ã (–Ω–æ–≤—ã–µ): {', '.join(new_items)}")
        # –ê–Ω–æ–Ω—Å–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –æ–±—â–∏–π –º–µ—Ö–∞–Ω–∏–∑–º, —á—Ç–æ–±—ã –ø–∏—Å–∞–ª–æ—Å—å –≤ –ª–æ–≥–∏ –∏ —Ä–∞–±–æ—Ç–∞–ª –∞–≤—Ç–æ–ø–æ–≤—Ç–æ—Ä
        self._announce_thesis()

    def _announce_theses_batch(self, theses: list[str]) -> None:
        if not theses:
            return
        # –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º–∏ —Ç–µ–∑–∏—Å—ã, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2-3 —Ç–µ–∑–∏—Å–∞ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
        to_announce = theses[:min(3, len(theses))]
        for i, thesis in enumerate(to_announce, 1):
            # –ö—Ä–∞—Ç–∫–æ–µ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ: —Ç–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä –∏ —Ç–µ–∑–∏—Å
            text = f"{i}. {thesis}"
            self._speak_text(text)
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ–∑–∏—Å–∞–º–∏
            time.sleep(0.2)
        self._last_announce_ts = time.time()
        if self.thesis_prompter is not None:
            self.thesis_prompter.reset_announcement()

    def _announce_thesis(self, thesis_index: Optional[int] = None) -> None:
        """
        –û–∑–≤—É—á–∏–≤–∞–µ—Ç —Ç–µ–∑–∏—Å.
        thesis_index: –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –æ–∑–≤—É—á–∏–≤–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ–∑–∏—Å –ë–ï–ó —Å–º–µ–Ω—ã _index.
                      –µ—Å–ª–∏ None, –æ–∑–≤—É—á–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Ç–µ–∑–∏—Å (–ø–æ _index).
        """
        if self.thesis_prompter is None:
            return
        if not self.thesis_prompter.has_pending():
            if not self._thesis_done_notified:
                logger.info("–í—Å–µ —Ç–µ–∑–∏—Å—ã –ø—Ä–æ–π–¥–µ–Ω—ã")
                self._thesis_done_notified = True
            return
        
        # –ñ–¥—ë–º –ø–æ–∫–∞ –∑–∞–∫–æ–Ω—á–∏—Ç—Å—è suppress (TTS –æ—Ç–≤–µ—Ç–∞ LLM), –∏–Ω–∞—á–µ –±—É–¥–µ—Ç –ø–µ—Ä–µ–±–∏–≤–∞—Ç—å
        if time.time() < self._suppress_until:
            logger.debug(f"–û—Ç–∫–ª–∞–¥—ã–≤–∞–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Ç–µ–∑–∏—Å–∞ - suppress –∞–∫—Ç–∏–≤–µ–Ω –µ—â—ë {self._suppress_until - time.time():.1f}—Å")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Ç–µ–∑–∏—Å–∞
        if thesis_index is not None:
            # –û–∑–≤—É—á–∏–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ–∑–∏—Å –ø–æ –∏–Ω–¥–µ–∫—Å—É –ë–ï–ó —Å–º–µ–Ω—ã _index
            theses = getattr(self.thesis_prompter, "theses", [])
            if thesis_index < 0 or thesis_index >= len(theses):
                return
            text = theses[thesis_index]
        else:
            # –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ç–µ–∑–∏—Å
            text = self.thesis_prompter.current_text()
        
        if not text:
            return
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ —á—Ç–æ –æ–±—ä—è–≤–ª—è–µ–º —Ç–µ–∑–∏—Å
        self._is_announcing = True
        try:
            logger.info(f"–¢–µ–∑–∏—Å: {text}")
            # –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º —Ç–µ–∑–∏—Å, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            self._speak_text(text)
            if thesis_index is None:
                # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—ä—è–≤–ª–µ–Ω–Ω—ã–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ —Ç–µ–∫—É—â–∏–π —Ç–µ–∑–∏—Å
                self.thesis_prompter.mark_announced()
            # –£–±–∏—Ä–∞–µ–º –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–µ–∑–∏—Å–æ–≤ - —ç—Ç–æ –∏–∑–±—ã—Ç–æ—á–Ω–æ
            self._last_announce_ts = time.time()
        finally:
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –ø–æ—Å–ª–µ –æ–∑–≤—É—á–∫–∏
            self._is_announcing = False

    def _process_self_segment(self, wav: np.ndarray) -> None:
        if not self.asr_enable:
            return
        try:
            transcript = self._ensure_asr().transcribe_np(wav, SAMPLE_RATE)
        except Exception as e:  # noqa: BLE001
            logger.exception(f"ASR –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –º–æ–µ–≥–æ –≥–æ–ª–æ—Å–∞: {e}")
            return
        self._handle_self_transcript(transcript)

    # ==== Warmup –º–æ–¥–µ–ª–µ–π ====
    def _warmup_models(self) -> None:
        # ASR: –ø—Ä–æ–≥–Ω–∞—Ç—å –∫–æ—Ä–æ—Ç–∫—É—é —Ç–∏—à–∏–Ω—É
        try:
            if self.asr_enable:
                _ = self._ensure_asr().transcribe_np(np.zeros((SAMPLE_RATE//2,), dtype=np.float32), SAMPLE_RATE)
        except Exception as e:  # noqa: BLE001
            logger.debug(f"ASR warmup failed: {e}")
        # LLM: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (–Ω–µ –æ–∑–≤—É—á–∏–≤–∞—Ç—å)
        try:
            if self.llm_enable and self._llm is None and LLMResponder is not None:
                self._llm = LLMResponder()
            if self.llm_enable and self._llm is not None:
                _ = self._llm.generate("–ü—Ä–∏–≤–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å.")
        except Exception as e:  # noqa: BLE001
            logger.debug(f"LLM warmup failed: {e}")
        # TTS: —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–µ –∞—É–¥–∏–æ –±–µ–∑ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        try:
            if self._tts is not None:
                _ = self._tts.synth("–ì–æ—Ç–æ–≤.")
        except Exception as e:  # noqa: BLE001
            logger.debug(f"TTS warmup failed: {e}")

    # ==== –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ ====
    @staticmethod
    def _extract_questions(text: str) -> List[str]:
        if not text:
            return []
        t = text.strip()
        # –†–∞–∑–æ–±—å—ë–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        parts: List[str] = []
        buf = []
        for ch in t:
            buf.append(ch)
            if ch in "?!.\n":
                seg = "".join(buf).strip()
                if seg:
                    parts.append(seg)
                buf = []
        if buf:
            parts.append("".join(buf).strip())
        res: List[str] = []
        for p in parts:
            if LiveVoiceVerifier._is_question_ru(p):
                res.append(p)
        return res

    @staticmethod
    def _is_question_ru(s: str) -> bool:
        if not s:
            return False
        s2 = s.strip().lower()
        # –Ø–≤–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –≤–æ–ø—Ä–æ—Å–∞
        if s2.endswith("?"):
            return True
        # –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —à–∞–±–ª–æ–Ω—ã
        patterns = [
            r"\b–∫—Ç–æ\b", r"\b—á—Ç–æ\b", r"\b–∫–æ–≥–¥–∞\b", r"\b–≥–¥–µ\b", r"\b–ø–æ—á–µ–º—É\b",
            r"\b–∑–∞—á–µ–º\b", r"\b–∫–∞–∫\b", r"\b–∫–∞–∫–æ–π\b", r"\b–∫–∞–∫–æ–≤–∞\b", r"\b–∫–æ—Ç–æ—Ä\w*\b",
            r"\b—Å–∫–æ–ª—å–∫–æ\b", r"\b–≤ –∫–∞–∫–æ–º –≥–æ–¥—É\b", r"\b–ø—Ä–∞–≤–¥–∞ –ª–∏\b", r"\b–º–æ–∂–Ω–æ –ª–∏\b",
        ]
        for p in patterns:
            try:
                import re
                if re.search(p, s2):
                    return True
            except Exception:
                continue
        return False

    @staticmethod
    def _compute_age(year: int, month: int, day: int) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç –≤ –ø–æ–ª–Ω—ã—Ö –≥–æ–¥–∞—Ö –Ω–∞ —Å–µ–≥–æ–¥–Ω—è."""
        today = date.today()
        age = today.year - year - (1 if (today.month, today.day) < (month, day) else 0)
        return int(age)

    @staticmethod
    def _format_age_ru(age: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Å–∫–ª–æ–Ω–µ–Ω–∏–µ–º: 1 –≥–æ–¥, 2-4 –≥–æ–¥–∞, 5+ –ª–µ—Ç."""
        n = abs(int(age))
        last_two = n % 100
        last = n % 10
        if 11 <= last_two <= 14:
            word = "–ª–µ—Ç"
        elif last == 1:
            word = "–≥–æ–¥"
        elif 2 <= last <= 4:
            word = "–≥–æ–¥–∞"
        else:
            word = "–ª–µ—Ç"
        return f"{n} {word}"

    # ==== –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ ====
    def _filter_questions_by_importance(self, qs: List[str]) -> List[str]:
        if not qs:
            return []
        # –ë—ã—Å—Ç—Ä—ã–π —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å—Ç—Ä: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if self._question_filter_mode != "gemini":
            keep: List[str] = []
            import re
            keywords = [
                r"\b–≤ –∫–∞–∫–æ–º –≥–æ–¥—É\b",
                r"\b–≥–æ–¥(–∞|—É|–æ–º)?\b",
                r"\b—Å–∫–æ–ª—å–∫–æ\b",
                r"\b–∫—Ç–æ\b",
                r"\b—á—Ç–æ —Ç–∞–∫–æ–µ\b",
                r"\b–æ–ø—Ä–µ–¥–µ–ª–∏(—Ç–µ)?\b",
                r"\b–ø–æ—á–µ–º—É\b",
                r"\b–∫–∞–∫(–∏–º|–æ–π|–∞—è|–æ–µ)? –æ–±—Ä–∞–∑–æ–º\b",
                r"\b–ø–µ—Ä–µ—á–∏—Å–ª–∏(—Ç–µ)?\b",
            ]
            exclude_patterns = [
                r"\b—Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç\b",
                r"\b—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç —Ç–µ–±–µ\b",
                r"\b–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç\b",
                r"\b–∫—Ç–æ —Ç—ã\b",
                r"\b—Ç–µ–±—è –∑–æ–≤—É—Ç\b",
                r"\b—Ç–≤–æ–π –≤–æ–∑—Ä–∞—Å—Ç\b",
                r"\b—á—Ç–æ –¥–µ–ª–∞–µ—à—å\b",
                r"\b–∫–∞–∫ –¥–µ–ª–∞\b",
            ]
            for q in qs:
                q2 = q.strip()
                if len(q2) < self._question_min_len:
                    continue
                if any(re.search(p, q2.lower()) for p in exclude_patterns):
                    continue
                hit = any(re.search(p, q2.lower()) for p in keywords)
                if q2.endswith("?") or hit:
                    keep.append(q2)
            return keep

        # –†–µ–∂–∏–º Gemini: –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        try:
            import json
            from google import genai  # type: ignore
            from google.genai import types  # type: ignore
            import os as _os
            key = _os.getenv("GEMINI_API_KEY")
            if not key:
                return qs  # –±–µ–∑ –∫–ª—é—á–∞ –≤–µ—Ä–Ω—ë–º –∫–∞–∫ –µ—Å—Ç—å
            client = genai.Client(api_key=key)
            sys_instr = (
                "–¢—ã ‚Äî —Ñ–∏–ª—å—Ç—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —ç–∫–∑–∞–º–µ–Ω–∞/—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è. –û—Ü–µ–Ω–∏ –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É:"
                " —ç—Ç–æ –ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ (–∏—Å—Ç–æ—Ä–∏—è, —Ñ–∞–∫—Ç—ã, —Ç–µ—Ö–Ω–∞—Ä—â–∏–Ω–∞ –∏ —Ç.–ø.)?"
                " –ò–≥–Ω–æ—Ä–∏—Ä—É–π –±—ã—Ç–æ–≤—ã–µ —Ä–µ–ø–ª–∏–∫–∏ –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è. –í–µ—Ä–Ω–∏ JSON –≤–∏–¥–∞ {\"keep\": [0|1,...]}"
            )
            payload = {"items": [s.strip() for s in qs if s.strip()]}
            user_text = json.dumps(payload, ensure_ascii=False)
            cfg = types.GenerateContentConfig(
                system_instruction=sys_instr,
                max_output_tokens=128,
                temperature=0.0,
                thinking_config=types.ThinkingConfig(thinking_budget=0),
            )
            resp = client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=[types.Content(role="user", parts=[types.Part.from_text(text=user_text)])],
                config=cfg,
            )
            raw = (resp.text or "").strip()
            data = json.loads(raw)
            keep_mask = list(map(int, data.get("keep", [])))
            out: List[str] = []
            for s, k in zip(qs, keep_mask):
                if k:
                    out.append(s)
            return out if out else []
        except Exception as e:  # noqa: BLE001
            logger.debug(f"Gemini question filter failed: {e}")
            return qs

    # ==== –ò–ò-—ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —á—É–∂–æ–π —Ä–µ–ø–ª–∏–∫–∏ ====
    def _extract_theses_ai(self, text: str) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∑–∏—Å–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.
        –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Gemini —Å —Å—Ç—Ä–æ–≥–∏–º JSON-–∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–º.
        """
        t = (text or "").strip()
        if not t:
            return []
        try:
            import json
            from google import genai  # type: ignore
            from google.genai import types  # type: ignore
            key = os.getenv("GEMINI_API_KEY")
            if not key:
                return []
            client = genai.Client(api_key=key)

            def _call_and_parse(force_json_start: bool = False) -> List[str]:
                sys_instr = (
                    "–í–æ–ø—Ä–æ—Å –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É? –í–µ—Ä–Ω–∏ 2-3 —Ç–µ–∑–∏—Å–∞. –õ–∏—á–Ω–æ–µ? –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫."
                    " JSON: {\"theses\": [\"...\"]}"
                )
                if force_json_start:
                    sys_instr += " –û—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å —Å–∏–º–≤–æ–ª–∞ { –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ JSON."
                prompt = json.dumps({"transcript": t}, ensure_ascii=False)
                cfg = types.GenerateContentConfig(
                    system_instruction=sys_instr,
                    max_output_tokens=64,
                    temperature=0.0,
                    top_p=0.8,
                    thinking_config=types.ThinkingConfig(thinking_budget=0),
                    response_mime_type="application/json",
                )
                resp = client.models.generate_content(
                    model="gemini-2.5-flash-lite",
                    contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                    config=cfg,
                )
                raw = (resp.text or "").strip()
                return LiveVoiceVerifier._parse_theses_from_raw(raw, n_max=self._thesis_autogen_batch)

            out = _call_and_parse(False)
            if not out:
                out = _call_and_parse(True)
            return out
        except Exception as e:  # noqa: BLE001
            logger.debug(f"AI theses extraction failed: {e}")
            return []


def extract_theses_from_text(text: str) -> List[str]:
    """–ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –∏–∑–≤–ª–µ—á—å —Ç–µ–∑–∏—Å—ã –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ç–µ–∫—Å—Ç–∞ —á—É–∂–æ–π —Ä–µ–ø–ª–∏–∫–∏/–¥–∏–∞–ª–æ–≥–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [] –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ—Ç. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ JSON-–∫–æ–Ω—Ç—Ä–∞–∫—Ç Gemini, —á—Ç–æ –∏ _extract_theses_ai.
    """
    t = (text or "").strip()
    if not t:
        return []
    try:
        import json
        from google import genai  # type: ignore
        from google.genai import types  # type: ignore
        key = os.getenv("GEMINI_API_KEY")
        if not key:
            return []
        client = genai.Client(api_key=key)

        def _call_and_parse(force_json_start: bool = False) -> List[str]:
            sys_instr = (
                "–í–æ–ø—Ä–æ—Å –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É? –í–µ—Ä–Ω–∏ 2-3 —Ç–µ–∑–∏—Å–∞ –æ—Ç–≤–µ—Ç–∞. –õ–∏—á–Ω–æ–µ/–±—ã—Ç–æ–≤–æ–µ? –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫."
                " JSON: {\"theses\": [\"...\"]}"
            )
            if force_json_start:
                sys_instr += " –û—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å —Å–∏–º–≤–æ–ª–∞ { –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ JSON."
            prompt = json.dumps({"transcript": t}, ensure_ascii=False)
            cfg = types.GenerateContentConfig(
                system_instruction=sys_instr,
                max_output_tokens=128,
                temperature=0.0,
                top_p=0.8,
                thinking_config=types.ThinkingConfig(thinking_budget=0),
                response_mime_type="application/json",
            )
            resp = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                config=cfg,
            )
            raw = (resp.text or "").strip()
            return LiveVoiceVerifier._parse_theses_from_raw(raw, n_max=8)

        out = _call_and_parse(False)
        if not out:
            out = _call_and_parse(True)
        return out
    except Exception as e:  # noqa: BLE001
        logger.debug(f"extract_theses_from_text failed: {e}")
        return []


def enroll_cli(
    profile_path: Path = Path("voice_profile.npz"),
    seconds: float = 20.0,
    min_voiced_seconds: float = 4.0,
    vad_aggr: int = 2,
    min_consec: int = 5,
    flatness_th: float = 0.60,
    # VAD backend
    vad_backend: str = "webrtc",
    silero_vad_threshold: float = 0.5,
    silero_vad_window_ms: int = 100,
    # ASR –≤ —ç–Ω—Ä–æ–ª–ª–º–µ–Ω—Ç–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –æ—Å—Ç–∞–≤–∏–º –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Å–∏–≥–Ω–∞—Ç—É—Ä—É –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
    asr: bool = False,
    asr_model: str = "large-v3-turbo",
    asr_lang: Optional[str] = None,
    asr_device: Optional[str] = None,
    asr_compute: Optional[str] = None,
    # –¢–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ—Ñ–∏–ª—è
    read_script: Optional[str] = None,
    read_script_file: Optional[Path] = None,
) -> None:
    setup_logging()
    verifier = LiveVoiceVerifier(
        vad_backend=vad_backend,
        silero_vad_threshold=silero_vad_threshold,
        silero_vad_window_ms=silero_vad_window_ms,
        vad_aggressiveness=vad_aggr,
        min_consec_speech_frames=min_consec,
        flatness_reject_threshold=flatness_th,
    )

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ç–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    script_text: Optional[str] = None
    if read_script_file is not None:
        try:
            script_text = Path(read_script_file).read_text(encoding="utf-8")
        except Exception as e:  # noqa: BLE001
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Å–∫—Ä–∏–ø—Ç–∞ {read_script_file}: {e}")
            script_text = None
    if not script_text and read_script:
        script_text = read_script.strip()
    paragraphs = _split_paragraphs(script_text or "")
    if not paragraphs:
        paragraphs = DEFAULT_ENROLL_PARAGRAPHS.copy()

    selected_idx = 0
    if len(paragraphs) > 1:
        print("–í—ã–±–µ—Ä–∏—Ç–µ –∞–±–∑–∞—Ü –¥–ª—è —á—Ç–µ–Ω–∏—è (–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω –Ω–∏–∂–µ):")
        for idx, para in enumerate(paragraphs, 1):
            preview = para.replace("\n", " ")
            if len(preview) > 90:
                preview = preview[:87] + "‚Ä¶"
            print(f"  {idx}) {preview}")
        choice = input("–ù–æ–º–µ—Ä –∞–±–∑–∞—Ü–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip()
        try:
            parsed = int(choice)
            if 1 <= parsed <= len(paragraphs):
                selected_idx = parsed - 1
            else:
                logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä {choice}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±–∑–∞—Ü 1")
        except Exception:
            if choice:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–≤–æ–¥ '{choice}', –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±–∑–∞—Ü 1")

    script_to_read = paragraphs[selected_idx]
    logger.info(
        "–î–ª—è –ø—Ä–æ—Ñ–∏–ª—è –≤—ã–±—Ä–∞–Ω –∞–±–∑–∞—Ü {idx} ({words} —Å–ª–æ–≤)",
        idx=selected_idx + 1,
        words=len(script_to_read.split()),
    )

    print("\n–ß–∏—Ç–∞–π—Ç–µ –∞–±–∑–∞—Ü ‚Ññ{0}:\n{1}\n".format(selected_idx + 1, script_to_read))
    print("–°–æ–≤–µ—Ç: –≥–æ–≤–æ—Ä–∏—Ç–µ —Ä–∞–∑–º–µ—Ä–µ–Ω–Ω–æ –∏ —Å–¥–µ–ª–∞–π—Ç–µ –ø–∞—É–∑—É –æ–∫–æ–ª–æ —Å–µ–∫—É–Ω–¥—ã –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —á—Ç–µ–Ω–∏—è.")
    try:
        input("–ù–∞–∂–º–∏—Ç–µ Enter, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å‚Ä¶")
    except Exception:
        pass

    words = len(script_to_read.split())
    min_read_seconds = words / 2.5 + 2.0  # –∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π —Ç–µ–º–ø —Ä–µ—á–∏ ~150 —Å–ª–æ–≤/–º–∏–Ω
    record_seconds = max(seconds, min_read_seconds)
    logger.info(
        "–°—Ç–∞—Ä—Ç –∑–∞–ø–∏—Å–∏ –ø—Ä–æ—Ñ–∏–ª—è: —Ü–µ–ª–µ–≤–æ–π –ª–∏–º–∏—Ç {record_seconds:.1f}s, –º–∏–Ω–∏–º—É–º –æ–∑–≤—É—á–µ–Ω–Ω–æ–π —Ä–µ—á–∏ {min_voiced_seconds:.1f}s",
        record_seconds=record_seconds,
        min_voiced_seconds=min_voiced_seconds,
    )

    wav = verifier._collect_enrollment_audio(
        seconds=record_seconds,
        min_voiced_seconds=min_voiced_seconds,
        silence_stop_sec=1.4,
    )
    emb = verifier.embedding_from_waveform(wav)
    profile = VoiceProfile(embedding=emb)
    profile.save(profile_path)
    logger.info(f"–ü—Ä–æ—Ñ–∏–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {profile_path}")



def live_cli(
    profile_path: Path = Path("voice_profile.npz"),
    threshold: float = 0.30,
    vad_aggr: int = 2,
    min_consec: int = 5,
    flatness_th: float = 0.60,
    min_segment_ms: int = 500,
    max_silence_ms: int = 400,
    pre_roll_ms: int = 160,
    # VAD backend
    vad_backend: str = "webrtc",
    silero_vad_threshold: float = 0.5,
    silero_vad_window_ms: int = 100,
    # ASR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    asr: bool = False,
    asr_model: str = "large-v3-turbo",
    asr_lang: Optional[str] = None,
    asr_device: Optional[str] = None,
    asr_compute: Optional[str] = None,
    # LLM
    llm: bool = False,
    run_seconds: float = 0.0,
) -> None:
    setup_logging()
    verifier = LiveVoiceVerifier(
        threshold=threshold,
        vad_backend=vad_backend,
        silero_vad_threshold=silero_vad_threshold,
        silero_vad_window_ms=silero_vad_window_ms,
        vad_aggressiveness=vad_aggr,
        min_consec_speech_frames=min_consec,
        flatness_reject_threshold=flatness_th,
        asr_enable=asr,
        asr_model_size=asr_model,
        asr_language=asr_lang,
        asr_device=asr_device,
        asr_compute_type=asr_compute,
        llm_enable=llm,
    )
    profile = VoiceProfile.load(profile_path)
    if profile is None:
        logger.error(
            f"–ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {profile_path}. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É enroll."
        )
        sys.exit(1)
    verifier.live_verify(
        profile,
        min_segment_ms=min_segment_ms,
        max_silence_ms=max_silence_ms,
        pre_roll_ms=pre_roll_ms,
        run_seconds=run_seconds,
    )


__all__ = [
    "LiveVoiceVerifier",
    "VoiceProfile",
    "enroll_cli",
    "live_cli",
    "extract_theses_from_text",
]
