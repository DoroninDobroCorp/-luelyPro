from __future__ import annotations

import os
import queue
import sys
import threading
import time
from dataclasses import dataclass
from collections import deque
from pathlib import Path
from typing import Optional, List, Callable
from datetime import date

import numpy as np
import io
import wave
from loguru import logger

# –ú—è–≥–∫–∏–µ –∏–º–ø–æ—Ä—Ç—ã —Ç—è–∂—ë–ª—ã—Ö/–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, —á—Ç–æ–±—ã —é–Ω–∏—Ç-—Ç–µ—Å—Ç—ã —Ä–∞–±–æ—Ç–∞–ª–∏ –æ—Ñ—Ñ–ª–∞–π–Ω
try:  # sound I/O
    import sounddevice as sd  # type: ignore
except Exception:  # noqa: BLE001
    sd = None  # type: ignore

try:  # torch (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ CI)
    import torch  # type: ignore
except Exception:  # noqa: BLE001
    torch = None  # type: ignore

try:  # WebRTC VAD
    import webrtcvad  # type: ignore
except Exception:  # noqa: BLE001
    webrtcvad = None  # type: ignore

try:  # —ç–º–±–µ–¥–¥–µ—Ä –≥–æ–ª–æ—Å–∞
    from pyannote.audio.pipelines.speaker_verification import (  # type: ignore
        PretrainedSpeakerEmbedding,
    )
except Exception:  # noqa: BLE001
    PretrainedSpeakerEmbedding = None  # type: ignore

try:  # ASR (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from asr_transcriber import FasterWhisperTranscriber  # type: ignore
except Exception:  # noqa: BLE001
    FasterWhisperTranscriber = None  # type: ignore
try:  # LLM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from llm_answer import LLMResponder  # type: ignore
except Exception:  # noqa: BLE001
    LLMResponder = None  # type: ignore
try:  # OpenAI TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from tts_openai import OpenAITTS, OPENAI_AVAILABLE  # type: ignore
except Exception:  # noqa: BLE001
    OpenAITTS = None  # type: ignore
    OPENAI_AVAILABLE = False
try:  # Google TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from tts_google import GoogleTTS, GOOGLE_TTS_AVAILABLE  # type: ignore
except Exception:  # noqa: BLE001
    GoogleTTS = None  # type: ignore
    GOOGLE_TTS_AVAILABLE = False
try:  # Silero TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from tts_silero import SileroTTS  # type: ignore
except Exception:  # noqa: BLE001
    SileroTTS = None  # type: ignore
try:  # Silero VAD (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    from vad_silero import SileroVAD  # type: ignore
except Exception:  # noqa: BLE001
    SileroVAD = None  # type: ignore
try:
    from thesis_generator import GeminiThesisGenerator  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
except Exception:  # noqa: BLE001
    GeminiThesisGenerator = None  # type: ignore


LOGGING_CONFIGURED = False
CURRENT_LOG_DIR: Optional[Path] = None


def setup_logging(
    log_dir: Optional[Path] = None,
    console_level: str = os.getenv("CONSOLE_LOG_LEVEL", "INFO"),
    file_level: str = os.getenv("FILE_LOG_LEVEL", "DEBUG"),
) -> Path:
    """Configure loguru sinks and return the file sink path.
    If log_dir is provided, reconfigure sinks to write there.
    """
    global LOGGING_CONFIGURED, CURRENT_LOG_DIR
    target_dir = Path(log_dir or os.getenv("LOG_DIR", "logs"))
    # Reconfigure if not configured yet OR explicit log_dir differs from current
    need_reconfigure = (not LOGGING_CONFIGURED) or (
        log_dir is not None and (CURRENT_LOG_DIR is None or target_dir != CURRENT_LOG_DIR)
    )
    if not need_reconfigure and CURRENT_LOG_DIR is not None:
        return CURRENT_LOG_DIR / "assistant.log"

    target_dir.mkdir(parents=True, exist_ok=True)
    log_file = target_dir / "assistant.log"

    logger.remove()
    logger.add(sys.stderr, level=console_level.upper(), enqueue=True, backtrace=False)
    logger.add(
        log_file,
        level=file_level.upper(),
        enqueue=False,  # —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å, —á—Ç–æ–±—ã —Ñ–∞–π–ª –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å–æ–∑–¥–∞–≤–∞–ª—Å—è –≤ —Ç–µ—Å—Ç–∞—Ö
        mode="w",
        encoding="utf-8",
        backtrace=True,
        diagnose=True,
    )
    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏—è sink
    try:
        log_file.touch(exist_ok=True)
    except Exception:
        pass
    logger.info(f"–õ–æ–≥–∏ –ø–∏—à—É—Ç—Å—è –≤ {log_file.resolve()}")
    LOGGING_CONFIGURED = True
    CURRENT_LOG_DIR = target_dir
    return log_file


DEFAULT_ENROLL_PARAGRAPHS: list[str] = [
    (
        "–≠—Ç–æ—Ç –∞–±–∑–∞—Ü –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã —Å–∏—Å—Ç–µ–º–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ –∑–∞–ø–æ–º–Ω–∏–ª–∞ –º–æ–π –≥–æ–ª–æ—Å. "
        "–Ø –≥–æ–≤–æ—Ä—é —Ä–∞–∑–º–µ—Ä–µ–Ω–Ω–æ, –¥–µ—Ä–∂—É –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ –Ω–µ —Å–ø–µ—à—É. "
        "–í –∫–æ–Ω—Ü–µ –¥–µ–ª–∞—é –∫–æ—Ä–æ—Ç–∫—É—é –ø–∞—É–∑—É, —á—Ç–æ–±—ã –∑–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ."
    ),
    (
        "–í —Ä–∞–±–æ—á–µ–º –¥–Ω–µ –º–Ω–µ —á–∞—Å—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –æ–±—ä—è—Å–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∏–¥–µ–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º. "
        "–ü–æ—ç—Ç–æ–º—É –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —á—ë—Ç–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–ª –º–æ–∏ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ –∏ —Ç–µ–º–±—Ä. "
        "–Ø –ø—Ä–æ–∏–∑–Ω–æ—à—É —Å–ª–æ–≤–∞ —è—Å–Ω–æ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ, —Å–ª–æ–≤–Ω–æ –æ—Ç–≤–µ—á–∞—é –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞."
    ),
    (
        "–ß—Ç–æ–±—ã –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—É—á–∏–ª—Å—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º, —è —á–∏—Ç–∞—é —Ç–µ–∫—Å—Ç, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä –æ –ø—Ä–æ–µ–∫—Ç–∞—Ö. "
        "–Ø –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—Å—ã–≤–∞—é –∑–∞–¥–∞—á–∏, —Ä–µ—à–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –∂–∏–≤—É—é –∏ —Å–ø–æ–∫–æ–π–Ω—É—é —Ä–µ—á—å. "
        "–¢–∞–∫ –∞–ª–≥–æ—Ä–∏—Ç–º —É–ª–æ–≤–∏—Ç –º–æ–π —Ä–µ–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è."
    ),
]


def _split_paragraphs(text: str) -> list[str]:
    if not text:
        return []
    parts = [p.strip() for p in text.replace("\r", "").split("\n\n")]
    return [p for p in parts if p]


SAMPLE_RATE = 16000  # required by WebRTC VAD and recommended for embeddings
FRAME_MS = 20  # WebRTC VAD supports 10, 20, or 30 ms
FRAME_SIZE = int(SAMPLE_RATE * FRAME_MS / 1000)  # samples per frame
CHANNELS = 1


def float_to_pcm16(x: np.ndarray) -> bytes:
    """Convert float32 (-1..1) to 16-bit PCM bytes."""
    x = np.clip(x, -1.0, 1.0)
    x_int16 = (x * 32767.0).astype(np.int16)
    return x_int16.tobytes()


def median_spectral_flatness(
    wav: np.ndarray, sample_rate: int = SAMPLE_RATE, frame_len: int = 512, hop: int = 256
) -> float:
    """–û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—É—é –ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ—Å—Ç—å (0..1), –≥–¥–µ –±–ª–∏–∂–µ –∫ 1 ‚Äî —à—É–º–æ–ø–æ–¥–æ–±–Ω—ã–π —Å–∏–≥–Ω–∞–ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–µ–¥–∏–∞–Ω—É –ø–æ –æ–∫–Ω–∞–º.
    """
    if wav.ndim != 1:
        wav = wav.reshape(-1)
    if wav.size < frame_len:
        return 1.0  # —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ ‚Äî —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ —à—É–º
    # –û–∫–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    n_frames = 1 + (wav.size - frame_len) // hop
    if n_frames <= 0:
        return 1.0
    window = np.hanning(frame_len).astype(np.float32)
    sf_values: list[float] = []
    eps = 1e-10
    for i in range(n_frames):
        start = i * hop
        frame = wav[start : start + frame_len]
        if frame.size < frame_len:
            break
        frame = frame * window
        spec = np.fft.rfft(frame)
        p = (spec.real ** 2 + spec.imag ** 2) + eps
        # –ú–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–ª–æ—Å—É [80..4000] –ì—Ü, —á—Ç–æ–±—ã —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–µ—á–∏
        freqs = np.fft.rfftfreq(frame_len, d=1.0 / sample_rate)
        band = (freqs >= 80) & (freqs <= 4000)
        p_band = p[band]
        if p_band.size == 0:
            continue
        gm = np.exp(np.mean(np.log(p_band)))
        am = np.mean(p_band)
        sf = float(gm / (am + eps))
        sf_values.append(sf)
    if not sf_values:
        return 1.0
    return float(np.median(np.asarray(sf_values)))


@dataclass
class VoiceProfile:
    embedding: np.ndarray  # shape (d,)

    @staticmethod
    def load(path: Path) -> Optional["VoiceProfile"]:
        if not path.exists():
            return None
        data = np.load(path)
        return VoiceProfile(embedding=data["embedding"])  # type: ignore[index]

    def save(self, path: Path) -> None:
        path.parent.mkdir(parents=True, exist_ok=True)
        np.savez_compressed(path, embedding=self.embedding)


@dataclass
class QueuedSegment:
    kind: str
    audio: np.ndarray
    timestamp: float
    distance: float = 0.0


class ThesisManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä —Ç–µ–∑–∏—Å–æ–≤ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–∑–≤—É—á–∫–æ–π –∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º —É–≥–ª—É–±–ª–µ–Ω–∏–µ–º.
    
    –õ–æ–≥–∏–∫–∞:
    - –ü—Ä–∏ –Ω–æ–≤–æ–º –≤–æ–ø—Ä–æ—Å–µ: –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è 5 —Ç–µ–∑–∏—Å–æ–≤ (–∏–ª–∏ 1 –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ)
    - –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å –æ–∑–≤—É—á–∏–≤–∞–µ—Ç—Å—è 2 —Ä–∞–∑–∞
    - –ü–æ—Å–ª–µ 3-–≥–æ —Ç–µ–∑–∏—Å–∞ (2-–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ): –∑–∞–ø—Ä–æ—Å 5 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ–∑–∏—Å–æ–≤ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    - –£–≥–ª—É–±–ª–µ–Ω–∏–µ –¥–æ 7 –∏—Ç–µ—Ä–∞—Ü–∏–π –º–∞–∫—Å–∏–º—É–º
    - –ü—Ä–∏ –Ω–æ–≤–æ–º –≤–æ–ø—Ä–æ—Å–µ —Å –Ω–æ–≤—ã–º–∏ —Ç–µ–∑–∏—Å–∞–º–∏: –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö
    
    ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è TTS –¥–ª—è —Ç–µ–∑–∏—Å–æ–≤
    - –ü—Ä–∏ start_new_question –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è TTS –¥–ª—è –ø–µ—Ä–≤—ã—Ö 2-3 —Ç–µ–∑–∏—Å–æ–≤
    - –ü–æ–∫–∞ –æ–∑–≤—É—á–∏–≤–∞–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π —Ç–µ–∑–∏—Å, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ
    - –£—Å–∫–æ—Ä–µ–Ω–∏–µ 40-50% –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è. –°–º. OPTIMIZATION_TABLE.md - –∫–æ–¥ 2B
    """
    
    def __init__(
        self,
        generator: Optional["GeminiThesisGenerator"],
        max_depth_iterations: int = 7,
        deeper_trigger_idx: int = 2,
        tts_engine: Optional[object] = None,  # TTS –¥–ª—è –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    ):
        self.generator = generator
        self.max_depth_iterations = max_depth_iterations
        self.deeper_trigger_idx = deeper_trigger_idx
        self.tts_engine = tts_engine  # –°—Å—ã–ª–∫–∞ –Ω–∞ TTS
        
        # –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.theses: List[str] = []  # –í—Å–µ —Ç–µ–∑–∏—Å—ã (–ø–µ—Ä–≤—ã–µ + —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–µ)
        self.current_question: str = ""  # –¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
        self.context: Optional[str] = None  # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        self.current_idx: int = 0  # –ò–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ–∑–∏—Å–∞ (0-based)
        self.current_repeat: int = 1  # –ù–æ–º–µ—Ä –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è (1 –∏–ª–∏ 2)
        self.depth_iterations: int = 0  # –°—á–µ—Ç—á–∏–∫ –∏—Ç–µ—Ä–∞—Ü–∏–π —É–≥–ª—É–±–ª–µ–Ω–∏—è
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —É–≥–ª—É–±–ª–µ–Ω–∏–µ
        self.deeper_request_in_progress: bool = False
        self.deeper_request_thread: Optional[threading.Thread] = None
        self.pending_deeper_theses: List[str] = []  # –ì–æ—Ç–æ–≤—ã–µ –¥–æ–ø.—Ç–µ–∑–∏—Å—ã
        self.lock = threading.Lock()  # –ó–∞—â–∏—Ç–∞ –æ—Ç –≥–æ–Ω–∫–∏
        
        # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –ö—ç—à –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞—É–¥–∏–æ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è TTS)
        from concurrent.futures import ThreadPoolExecutor, Future
        self.audio_cache: dict[int, Future] = {}  # {–∏–Ω–¥–µ–∫—Å_—Ç–µ–∑–∏—Å–∞: Future[audio_np]}
        self.tts_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="tts-prefetch")
        self.prefetch_enabled = True  # –§–ª–∞–≥ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è/–≤—ã–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    
    def start_new_question(
        self, 
        question: str, 
        theses: List[str], 
        context: Optional[str] = None
    ) -> None:
        """–ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å (—Å–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è, –Ω–æ–≤—ã–µ —Ç–µ–∑–∏—Å—ã)"""
        with self.lock:
            self.current_question = question
            self.theses = theses.copy()
            self.context = context
            self.current_idx = 0
            self.current_repeat = 1
            self.depth_iterations = 0
            self.deeper_request_in_progress = False
            self.pending_deeper_theses = []
            
            # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π –∫—ç—à –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏—é TTS
            self.audio_cache.clear()
            if self.prefetch_enabled and self.tts_engine is not None and len(theses) > 0:
                # –ü—Ä–µ–¥–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS –¥–ª—è –ø–µ—Ä–≤—ã—Ö 2-3 —Ç–µ–∑–∏—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                prefetch_count = min(3, len(theses))
                for i in range(prefetch_count):
                    future = self.tts_executor.submit(self._generate_tts_audio, theses[i])
                    self.audio_cache[i] = future
                logger.debug(f"üéµ –ó–∞–ø—É—â–µ–Ω–∞ –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏—è TTS –¥–ª—è {prefetch_count} —Ç–µ–∑–∏—Å–æ–≤")
            
            logger.info(f"üé§ –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å: {len(theses)} —Ç–µ–∑–∏—Å–æ–≤")
    
    def get_next_thesis(self) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∑–∏—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏"""
        with self.lock:
            if self.current_idx >= len(self.theses):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≥–æ—Ç–æ–≤—ã–µ —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–µ —Ç–µ–∑–∏—Å—ã
                if self.pending_deeper_theses:
                    self.theses.extend(self.pending_deeper_theses)
                    self.pending_deeper_theses = []
                    logger.info(f"üìö –£–≥–ª—É–±–ª–µ–Ω–∏–µ {self.depth_iterations}/{self.max_depth_iterations}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(self.theses) - self.current_idx} –¥–æ–ø.—Ç–µ–∑–∏—Å–æ–≤")
                else:
                    # –ù–µ—Ç —Ç–µ–∑–∏—Å–æ–≤
                    return None
            
            if self.current_idx >= len(self.theses):
                return None
            
            return self.theses[self.current_idx]
    
    def advance(self) -> None:
        """–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—é/—Ç–µ–∑–∏—Å—É"""
        with self.lock:
            if self.current_repeat == 1:
                self.current_repeat = 2
            else:
                self.current_repeat = 1
                self.current_idx += 1
    
    def should_trigger_deeper(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —É–≥–ª—É–±–ª–µ–Ω–∏–µ"""
        with self.lock:
            # –¢—Ä–∏–≥–≥–µ—Ä: 3-–π —Ç–µ–∑–∏—Å (–∏–Ω–¥–µ–∫—Å 2), 2-–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ
            return (
                self.current_idx == self.deeper_trigger_idx and
                self.current_repeat == 2 and
                self.depth_iterations < self.max_depth_iterations and
                not self.deeper_request_in_progress and
                self.generator is not None
            )
    
    def trigger_deeper_async(self) -> None:
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —É–≥–ª—É–±–ª–µ–Ω–∏—è"""
        if not self.should_trigger_deeper():
            return
        
        with self.lock:
            self.deeper_request_in_progress = True
            self.depth_iterations += 1
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        def request_deeper():
            try:
                all_theses = self.theses.copy()
                question = self.current_question
                context = self.context
                
                logger.debug(f"üìö –£–≥–ª—É–±–ª–µ–Ω–∏–µ {self.depth_iterations}/{self.max_depth_iterations}: –∑–∞–ø—Ä–æ—Å 5 –¥–æ–ø.—Ç–µ–∑–∏—Å–æ–≤...")
                
                deeper_theses = self.generator.generate_deeper(
                    previous_theses=all_theses,
                    question=question,
                    context=context,
                    n=5,
                    language="ru"
                )
                
                if deeper_theses:
                    with self.lock:
                        self.pending_deeper_theses = deeper_theses
                        logger.info(f"‚úÖ –£–≥–ª—É–±–ª–µ–Ω–∏–µ {self.depth_iterations}: –ø–æ–ª—É—á–µ–Ω–æ {len(deeper_theses)} –¥–æ–ø.—Ç–µ–∑–∏—Å–æ–≤")
                        logger.info(f"–£–≥–ª—É–±–ª–µ–Ω–Ω—ã–µ —Ç–µ–∑–∏—Å—ã ({len(deeper_theses)}): {deeper_theses}")
                else:
                    logger.warning(f"‚ö†Ô∏è –£–≥–ª—É–±–ª–µ–Ω–∏–µ {self.depth_iterations}: –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —É–≥–ª—É–±–ª–µ–Ω–∏—è: {e}")
            finally:
                with self.lock:
                    self.deeper_request_in_progress = False
        
        self.deeper_request_thread = threading.Thread(
            target=request_deeper,
            name=f"deeper-{self.depth_iterations}",
            daemon=True
        )
        self.deeper_request_thread.start()
    
    def _generate_tts_audio(self, text: str) -> Optional[np.ndarray]:
        """
        ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è TTS –∞—É–¥–∏–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∑–∏—Å–∞ (–¥–ª—è ThreadPoolExecutor)
        """
        if not self.tts_engine or not text:
            return None
        
        try:
            tts_start = time.time()
            audio = self.tts_engine.synth(text)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bytes (Google TTS) –≤ numpy array
            if isinstance(audio, bytes):
                if len(audio) == 0:
                    return None
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º WAV bytes –≤ numpy
                with wave.open(io.BytesIO(audio), 'rb') as wf:
                    frames = wf.readframes(wf.getnframes())
                    audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
            
            tts_elapsed = (time.time() - tts_start) * 1000
            logger.debug(f"‚úì TTS –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏—è: {tts_elapsed:.0f}–º—Å ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return audio
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS: {e}")
            return None
    
    def get_cached_audio(self, index: int) -> Optional[np.ndarray]:
        """
        ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –ü–æ–ª—É—á–∏—Ç—å –≥–æ—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ –∏–∑ –∫—ç—à–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ –∫—ç—à –ø—É—Å—Ç–æ–π –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –µ—â–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
        """
        with self.lock:
            if index not in self.audio_cache:
                return None
            
            future = self.audio_cache[index]
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å (–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏)
        if not future.done():
            return None
        
        try:
            return future.result(timeout=0.1)
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ: {e}")
            return None
    
    def has_more_theses(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ –µ—â–µ —Ç–µ–∑–∏—Å—ã –∏–ª–∏ –æ–∂–∏–¥–∞—é—Ç—Å—è —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–µ"""
        with self.lock:
            return (
                self.current_idx < len(self.theses) or
                len(self.pending_deeper_theses) > 0 or
                self.deeper_request_in_progress
            )


class LiveVoiceVerifier:
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ª–∞–π–≤-–º–æ–¥—É–ª—å:
    - WebRTC VAD, —á—Ç–æ–±—ã –æ—Ç–¥–µ–ª—è—Ç—å —Ä–µ—á—å –æ—Ç —à—É–º–æ–≤/—Ç–∏—à–∏–Ω—ã.
    - –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ (ECAPA) –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–æ—Ñ–∏–ª–µ–º –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏.
    - –í—ã–≤–æ–¥: "–º–æ–π –≥–æ–ª–æ—Å" / "–Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å".
    """

    def __init__(
        self,
        model_id: str = "speechbrain/spkrec-ecapa-voxceleb",
        device: Optional[str] = None,
        embedder: Optional[PretrainedSpeakerEmbedding] = None,
        vad_aggressiveness: int = 2,
        vad_backend: str = "webrtc",  # "webrtc" | "silero"
        silero_vad_threshold: float = 0.5,
        silero_vad_window_ms: int = 100,
        threshold: float = 0.30,  # cosine distance threshold: <= is my voice
        min_consec_speech_frames: int = 5,  # >=5 * 20ms = 100ms –ø–æ–¥—Ä—è–¥ —Ä–µ—á–∏ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
        flatness_reject_threshold: float = 0.60,  # > -> —à—É–º, —Å–µ–≥–º–µ–Ω—Ç –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º
        # ASR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        asr_enable: bool = False,
        asr_model_size: str = "large-v3-turbo",
        asr_language: Optional[str] = None,
        asr_device: Optional[str] = None,
        asr_compute_type: Optional[str] = None,
        # LLM –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        llm_enable: bool = False,
        # Thesis –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç—ã –∏–∑ ThesisConfig)
        thesis_match_threshold: float = 0.6,
        thesis_gemini_enable: bool = True,
        thesis_gemini_min_conf: float = 0.60,
        thesis_autogen_enable: bool = True,
        thesis_autogen_batch: int = 3,
    ) -> None:
        if device is None:
            # –ë–µ–∑ torch —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ CPU
            if 'cuda' in str(os.getenv('ASR_DEVICE', '')).lower():
                device = 'cuda'
            else:
                try:
                    device = "cuda" if (torch is not None and getattr(torch, "cuda", None) and torch.cuda.is_available()) else "cpu"
                except Exception:
                    device = "cpu"
        # –ï—Å–ª–∏ torch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫—É, –∏–Ω–∞—á–µ torch.device
        self.device = torch.device(device) if torch is not None else device  # type: ignore[assignment]
        self._device_str = self.device.type
        self._embedder_model_id = model_id
        self._embedder: Optional[PretrainedSpeakerEmbedding] = embedder
        # VAD backend selection
        self.vad_backend = vad_backend.lower().strip()
        if self.vad_backend not in ("webrtc", "silero"):
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π vad_backend={vad_backend}, –∏—Å–ø–æ–ª—å–∑—É–µ–º 'webrtc'")
            self.vad_backend = "webrtc"
        if self.vad_backend == "webrtc":
            if webrtcvad is None:
                logger.warning("webrtcvad –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî VAD –≤—ã–∫–ª—é—á–µ–Ω –¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω-—Ç–µ—Å—Ç–æ–≤")
                self._vad_fn = lambda frame: False
            else:
                self.vad_webrtc = webrtcvad.Vad(vad_aggressiveness)
                self._vad_fn = lambda frame: self.vad_webrtc.is_speech(
                    float_to_pcm16(frame), SAMPLE_RATE
                )
        else:
            if SileroVAD is None:
                logger.warning("SileroVAD –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî VAD –≤—ã–∫–ª—é—á–µ–Ω –¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω-—Ç–µ—Å—Ç–æ–≤")
                self._vad_fn = lambda frame: False
            else:
                self.vad_silero = SileroVAD(
                    sample_rate=SAMPLE_RATE,
                    threshold=float(silero_vad_threshold),
                    window_ms=int(silero_vad_window_ms),
                    device=self._device_str,
                )
                self._vad_fn = lambda frame: self.vad_silero.is_speech(frame)
        self.threshold = threshold
        self.min_consec_speech_frames = max(1, int(min_consec_speech_frames))
        self.flatness_reject_threshold = float(flatness_reject_threshold)
        # ASR
        self.asr_enable = bool(asr_enable)
        self.asr_model_size = asr_model_size
        self.asr_language = asr_language
        self.asr_device = asr_device
        self.asr_compute_type = asr_compute_type
        self._asr: Optional[FasterWhisperTranscriber] = None
        # LLM
        self.llm_enable = bool(llm_enable)
        self._llm: Optional[LLMResponder] = None
        # TTS –¥–ª—è –æ–∑–≤—É—á–∫–∏ –æ—Ç–≤–µ—Ç–∞ LLM
        self._tts: Optional[SileroTTS] = None
        self._suppress_until: float = 0.0  # –ø–æ–¥–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Ö–æ–¥–∞ –Ω–∞ –≤—Ä–µ–º—è TTS
        self._is_announcing: bool = False  # —Ñ–ª–∞–≥ —á—Ç–æ —Å–µ–π—á–∞—Å –æ–∑–≤—É—á–∏–≤–∞–µ—Ç—Å—è —Ç–µ–∑–∏—Å
        self._tts_interrupt: threading.Event = threading.Event()  # —Ñ–ª–∞–≥ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è TTS
        self._tts_lock: threading.Lock = threading.Lock()  # –∑–∞—â–∏—Ç–∞ –æ—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        self._stop_requested: threading.Event = threading.Event()  # –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        self._thesis_thread: Optional[threading.Thread] = None  # —Ç–µ–∫—É—â–∏–π –ø–æ—Ç–æ–∫ –æ–∑–≤—É—á–∫–∏ —Ç–µ–∑–∏—Å–æ–≤
        self._tts_generation: int = 0  # —Å—á–µ—Ç—á–∏–∫ –ø–æ–∫–æ–ª–µ–Ω–∏–π –æ–∑–≤—É—á–∫–∏ (–¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —Å—Ç–∞—Ä—ã—Ö –ø–æ—Ç–æ–∫–æ–≤)
        # –í–Ω–µ—à–Ω–∏–π –ø–æ–ª—É—á–∞—Ç–µ–ª—å –∞—É–¥–∏–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, WebSocket-–∫–ª–∏–µ–Ω—Ç). –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ‚Äî
        # TTS –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Ç—É–¥–∞, –∞ –Ω–µ –ø—Ä–æ–∏–≥—Ä—ã–≤–∞—Ç—å—Å—è –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ sounddevice
        self._audio_sink: Optional[Callable[[bytes, int], None]] = None

        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ–∑–∏—Å–æ–≤ –¥–ª—è –ø–æ–¥—Å–∫–∞–∑–æ–∫
        self._thesis_generator: Optional[GeminiThesisGenerator] = None
        self._max_theses_history: int = 50  # –õ–∏–º–∏—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ç–µ–∑–∏—Å–æ–≤
        self._last_announce_ts: float = 0.0
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 —Å–µ–∫—É–Ω–¥ (–¥–ª—è –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–π)
        self._dialogue_context: list[tuple[float, str]] = []  # [(timestamp, text), ...]
        self._context_window_sec: float = 30.0  # –û–∫–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 6C: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ—á–µ—Ä–µ–¥–∏ - maxsize 20 ‚Üí 8
        # 2 –≤–æ—Ä–∫–µ—Ä–∞ √ó 3 —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ + 2 –≤ –æ—á–µ—Ä–µ–¥–∏ = 8 (–≤–º–µ—Å—Ç–æ 20)
        # –°–Ω–∏–∂–∞–µ—Ç memory –∏ latency –ø—Ä–∏ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–µ. –°–º. OPTIMIZATION_TABLE.md - –∫–æ–¥ 6C
        self._segment_queue: "queue.Queue[QueuedSegment]" = queue.Queue(maxsize=8)
        self._segment_workers: List[threading.Thread] = []  # –°–ø–∏—Å–æ–∫ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self._segment_stop = threading.Event()
        self._num_asr_workers: int = int(os.getenv("ASR_WORKERS", "2"))  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è ¬´–Ω–µ-–≤–æ–ø—Ä–æ—Å–æ–≤¬ª: heuristic | gemini (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gemini)
        self._question_filter_mode: str = os.getenv("QUESTION_FILTER_MODE", "gemini").strip().lower()
        try:
            self._question_min_len: int = int(os.getenv("QUESTION_MIN_LEN", "8"))
        except Exception:
            self._question_min_len = 8
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∫ –æ—Ç–≤–µ—Ç—É LLM (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª)
        try:
            _aq = os.getenv("APPEND_QUESTION_TO_ANSWER", "0").strip().lower()
            self._append_question_to_answer: bool = _aq in ("1", "true", "yes", "on")
        except Exception:
            self._append_question_to_answer = False
        # –†–µ–∂–∏–º: –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –ò–ò-—ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –∏–∑ —á—É–∂–æ–π —Ä–µ—á–∏
        self._ai_only_thesis: bool = os.getenv("AI_ONLY_THESIS", "1").strip() not in ("0", "false", "False")
        # –ù–æ–≤—ã–π —Ä–µ–∂–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–∫—Ç-–∑–∞–º–µ—Ç–∫–∏ –¥–∞–∂–µ –±–µ–∑ —è–≤–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        self._commentary_mode: bool = os.getenv("COMMENTARY_MODE", "0").strip() not in ("0", "false", "False", "no", "No")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—É—à–Ω–∏–∫–∏ (True = –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞)
        self._use_headphones: bool = os.getenv("USE_HEADPHONES", "1").strip() not in ("0", "false", "False")
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Ç–µ–∑–∏—Å–æ–≤ (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω)
        if GeminiThesisGenerator is not None:
            try:
                self._thesis_generator = GeminiThesisGenerator()  # type: ignore
                logger.info("–ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ Gemini –≤–∫–ª—é—á–µ–Ω–∞")
            except Exception as e:  # noqa: BLE001
                logger.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å ThesisGenerator: {e}")
        else:
            logger.warning("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ–∑–∏—Å–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ thesis_generator/google-genai")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Ç–µ–∑–∏—Å–æ–≤
        from config import ThesisConfig
        thesis_cfg = ThesisConfig()
        self._thesis_manager = ThesisManager(
            generator=self._thesis_generator,
            max_depth_iterations=thesis_cfg.max_depth_iterations,
            deeper_trigger_idx=thesis_cfg.deeper_trigger_idx,
        )
        logger.info(f"ThesisManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: –º–∞–∫—Å —É–≥–ª—É–±–ª–µ–Ω–∏–µ={thesis_cfg.max_depth_iterations}")

        if self.asr_enable:
            try:
                self._ensure_asr()
            except Exception as e:  # noqa: BLE001
                logger.exception(f"ASR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

        if self.llm_enable and LLMResponder is not None:
            try:
                # –£–º–µ–Ω—å—à–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é LLM —Å 8 –¥–æ 4 –ø–∞—Ä –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
                self._llm = LLMResponder(history_max_turns=4)
            except Exception as e:  # noqa: BLE001
                logger.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å LLMResponder: {e}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º TTS (RU –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –µ—Å–ª–∏ –æ–Ω –Ω—É–∂–µ–Ω –¥–ª—è LLM
        if self.llm_enable:
            # –í—ã–±–æ—Ä TTS –¥–≤–∏–∂–∫–∞ —á–µ—Ä–µ–∑ USE_TTS_ENGINE (openai | google | silero)
            tts_engine = os.getenv("USE_TTS_ENGINE", "silero").lower()
            
            # –°–∫–æ—Ä–æ—Å—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (0.25-4.0, 1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
            # 1.3-1.5 –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ–∑–∏—Å–æ–≤ - –±—ã—Å—Ç—Ä–æ, –Ω–æ —Ä–∞–∑–±–æ—Ä—á–∏–≤–æ
            try:
                tts_speed = float(os.getenv("TTS_SPEED", "1.35"))
                tts_speed = max(0.25, min(4.0, tts_speed))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
            except ValueError:
                tts_speed = 1.35
            
            # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2A: OpenAI TTS - –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø (—É—Å–∫–æ—Ä–µ–Ω–∏–µ 3-5x vs Silero)
            # OpenAI TTS –≤ 3-5 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ Silero (300-800–º—Å vs 2-5—Å–µ–∫ –Ω–∞ —Ç–µ–∑–∏—Å).
            # –°–º. OPTIMIZATION_TABLE.md - –∫–æ–¥ 2A
            if tts_engine == "openai" and OpenAITTS is not None and OPENAI_AVAILABLE:
                try:
                    self._tts = OpenAITTS(
                        model="tts-1",           # ‚úÖ 2D: tts-1 (–±—ã—Å—Ç—Ä–æ) | tts-1-hd (–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ)
                        voice="onyx",            # onyx (–º—É–∂—Å–∫–æ–π) | nova (–∂–µ–Ω—Å–∫–∏–π)
                        speed=tts_speed,
                    )
                    logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI TTS (—Å–∫–æ—Ä–æ—Å—Ç—å {tts_speed}x)")
                except Exception as e:  # noqa: BLE001
                    logger.warning(f"OpenAI TTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Silero TTS")
                    self._tts = None
            
            # Google TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω Service Account)
            elif tts_engine == "google" and self._tts is None and GoogleTTS is not None and GOOGLE_TTS_AVAILABLE:
                try:
                    self._tts = GoogleTTS(
                        language="ru-RU",
                        voice_name="ru-RU-Wavenet-D",  # –ú—É–∂—Å–∫–æ–π, –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–π
                        speaking_rate=tts_speed,  # –£—Å–∫–æ—Ä–µ–Ω–Ω–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –±–µ–∑ –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ–Ω–∞
                    )
                    logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Google TTS (—Å–∫–æ—Ä–æ—Å—Ç—å {tts_speed}x)")
                except Exception as e:  # noqa: BLE001
                    logger.warning(f"Google TTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Silero TTS")
                    self._tts = None
            
            # Silero TTS (fallback - —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–∑ –∫–æ—Ä–æ–±–∫–∏, –æ—Ñ–ª–∞–π–Ω)
            if self._tts is None and SileroTTS is not None:
                try:
                    self._tts = SileroTTS(
                        language="ru", model_id="v4_ru", speaker="eugene", sample_rate=24000
                    )
                    if tts_engine in ("openai", "google"):
                        logger.info(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Silero TTS ({tts_engine.upper()} TTS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")
                    else:
                        logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Silero TTS")
                except Exception as e:  # noqa: BLE001
                    logger.exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å TTS: {e}")
            
            if self._tts is None:
                logger.warning("‚ùå TTS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ–∑–≤—É—á–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            
            # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –û–±–Ω–æ–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ TTS –≤ ThesisManager
            if self._tts is not None:
                self._thesis_manager.tts_engine = self._tts
                logger.debug("‚úì ThesisManager –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ TTS –¥–ª—è –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

        logger.info(
            f"LiveVoiceVerifier initialized | model={model_id}, device={self.device}, threshold={threshold}, VAD={self.vad_backend}"
        )

        # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–µ–π, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å –∑–∞–¥–µ—Ä–∂–∫—É –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏
        try:
            self._warmup_models()
        except Exception as e:  # noqa: BLE001
            logger.debug(f"Warmup error (ignored): {e}")

    # ==== –í–Ω–µ—à–Ω–∏–π –ø—Ä–∏—ë–º–Ω–∏–∫ –∞—É–¥–∏–æ (–¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã) ====
    def set_audio_sink(self, sink: Callable[[bytes, int], None]) -> None:
        """–ó–∞–¥–∞—Ç—å –≤–Ω–µ—à–Ω–∏–π –ø—Ä–∏—ë–º–Ω–∏–∫ –∞—É–¥–∏–æ.
        sink –ø—Ä–∏–Ω–∏–º–∞–µ—Ç (wav_bytes, sample_rate). –ï—Å–ª–∏ –∑–∞–¥–∞–Ω, TTS –±—É–¥–µ—Ç
        –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Ç—É–¥–∞ –≤–º–µ—Å—Ç–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è."""
        self._audio_sink = sink

    @staticmethod
    def cosine_distance(a: np.ndarray, b: np.ndarray) -> float:
        a = a / (np.linalg.norm(a) + 1e-8)
        b = b / (np.linalg.norm(b) + 1e-8)
        return float(1.0 - np.dot(a, b))

    def _ensure_embedder(self) -> PretrainedSpeakerEmbedding:
        if self._embedder is None:
            self._embedder = PretrainedSpeakerEmbedding(
                self._embedder_model_id,
                device=self.device,
            )
        return self._embedder

    def embedding_from_waveform(self, wav: np.ndarray) -> np.ndarray:
        """wav: mono float32 in [-1, 1], shape (n_samples,) at 16kHz"""
        if wav.ndim != 1:
            wav = wav.reshape(-1)
        # Ensure tensor shape (batch=1, channels=1, samples)
        if torch is not None and hasattr(torch, "from_numpy"):
            tensor = torch.from_numpy(wav).float().unsqueeze(0).unsqueeze(0)  # (1,1,n)
            ctx = getattr(torch, "inference_mode", None)
            if callable(ctx):
                cm = ctx()
            else:
                class _Dummy:
                    def __enter__(self):
                        return None
                    def __exit__(self, exc_type, exc, tb):
                        return False
                cm = _Dummy()
            with cm:  # type: ignore
                out = self._ensure_embedder()(tensor)  # expected shape (1, dim)
        else:
            # –§–æ–ª–ª–±—ç–∫: —ç–º–±–µ–¥–¥–µ—Ä—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—ä–µ–∫—Ç–∞ —Å shape, DummyEmbedder –∏–∑ —Ç–µ—Å—Ç–æ–≤ —ç—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
            class _DummyTensor:
                def __init__(self, n: int):
                    self.shape = (1, 1, n)
            out = self._ensure_embedder()(_DummyTensor(wav.size))  # type: ignore
        # out can be numpy array or torch tensor depending on backend
        if isinstance(out, np.ndarray):
            return out[0]
        else:
            try:
                return out[0].detach().cpu().numpy()
            except Exception:
                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ np.ndarray –∏–ª–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ç–∏–ø
                try:
                    return np.asarray(out)[0]
                except Exception:
                    # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ ‚Äî –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                    return np.zeros((192,), dtype=np.float32)

    # ==== –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ====
    def _start_segment_worker(self) -> None:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ –∂–∏–≤—ã–µ –≤–æ—Ä–∫–µ—Ä—ã
        if any(w.is_alive() for w in self._segment_workers):
            return
        
        self._segment_stop.clear()
        self._segment_workers = []
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º N –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
        for i in range(self._num_asr_workers):
            worker = threading.Thread(
                target=self._segment_worker_loop,
                name=f"segment-worker-{i}",
                daemon=True,
            )
            worker.start()
            self._segment_workers.append(worker)
        
        logger.info(f"üöÄ –ó–∞–ø—É—â–µ–Ω–æ {self._num_asr_workers} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö ASR –≤–æ—Ä–∫–µ—Ä–æ–≤")

    def _stop_segment_worker(self) -> None:
        self._segment_stop.set()
        self._stop_requested.set()  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        
        # –ü—Ä–µ—Ä—ã–≤–∞–µ–º TTS –∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º sounddevice
        self._tts_interrupt.set()
        if sd is not None:
            try:
                sd.stop()
            except Exception:
                pass
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –≤–æ—Ä–∫–µ—Ä—ã
        for worker in self._segment_workers:
            if worker is not None:
                worker.join(timeout=2.0)
                if worker.is_alive():
                    logger.warning(f"Worker {worker.name} –Ω–µ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –∑–∞ 2—Å")
        
        self._segment_workers = []
        
        # –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å
        while not self._segment_queue.empty():
            try:
                self._segment_queue.get_nowait()
                self._segment_queue.task_done()
            except queue.Empty:
                break

    def _enqueue_segment(self, kind: str, audio: np.ndarray, distance: float = 0.0) -> None:
        if audio.size == 0:
            return
        segment = QueuedSegment(kind=kind, audio=audio, timestamp=time.time(), distance=distance)
        try:
            self._segment_queue.put_nowait(segment)
        except queue.Full:
            try:
                dropped = self._segment_queue.get_nowait()
                self._segment_queue.task_done()
                logger.warning(
                    f"–û—á–µ—Ä–µ–¥—å —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞, –æ—Ç–±—Ä–∞—Å—ã–≤–∞—é {dropped.kind} —Å–µ–≥–º–µ–Ω—Ç"
                )
            except queue.Empty:
                pass
            try:
                self._segment_queue.put_nowait(segment)
            except queue.Full:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç –≤ –æ—á–µ—Ä–µ–¥—å ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é —Å–∏–≥–Ω–∞–ª")

    def _segment_worker_loop(self) -> None:
        # –°–æ–∑–¥–∞—ë–º –ª–æ–∫–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ASR –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞ (thread-safe)
        local_asr: Optional[FasterWhisperTranscriber] = None
        if self.asr_enable and FasterWhisperTranscriber is not None:
            try:
                local_asr = FasterWhisperTranscriber(
                    model_size=self.asr_model_size,
                    device=self.asr_device,
                    compute_type=self.asr_compute_type,
                    language=self.asr_language,
                )
                worker_name = threading.current_thread().name
                logger.info(f"‚úì {worker_name}: –ª–æ–∫–∞–ª—å–Ω—ã–π ASR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π ASR: {e}")
        
        while not self._segment_stop.is_set() and not self._stop_requested.is_set():
            try:
                segment = self._segment_queue.get(timeout=0.2)
            except queue.Empty:
                continue
            
            # –í–ê–ñ–ù–û: –í–æ –≤—Ä–µ–º—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∑–∏—Å–æ–≤ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –°–í–û–ò —Å–µ–≥–º–µ–Ω—Ç—ã
            # (—á—Ç–æ–±—ã –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Ç–µ–∑–∏—Å–æ–≤)
            # –ß–£–ñ–ò–ï —Å–µ–≥–º–µ–Ω—Ç—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º (—ç—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞)
            if self._is_announcing and segment.kind == "self":
                logger.debug("‚è∏Ô∏è –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–≤–æ–π –≥–æ–ª–æ—Å –≤–æ –≤—Ä–µ–º—è –æ–∑–≤—É—á–∫–∏ —Ç–µ–∑–∏—Å–æ–≤")
                self._segment_queue.task_done()
                continue
            
            try:
                if segment.kind == "self":
                    # –°–≤–æ–π –≥–æ–ª–æ—Å –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                    logger.debug("–º–æ–π –≥–æ–ª–æ—Å (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º)")
                else:
                    self._handle_foreign_segment_with_asr(segment, local_asr)
            except Exception as e:  # noqa: BLE001
                logger.exception(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            finally:
                self._segment_queue.task_done()

    def _handle_foreign_segment_with_asr(self, segment: QueuedSegment, local_asr: Optional[FasterWhisperTranscriber]) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á—É–∂–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º ASR (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤)"""
        segment_duration = segment.audio.size / SAMPLE_RATE
        logger.debug(f"üìè –î–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: {segment_duration:.2f}—Å")
        
        if self.asr_enable and local_asr is not None:
            try:
                # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 8A: –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è –î–û ASR –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
                processing_start = time.time()
                
                asr_start = time.time()
                text = local_asr.transcribe_np(segment.audio, SAMPLE_RATE)
                asr_elapsed = (time.time() - asr_start) * 1000
                worker_name = threading.current_thread().name
                logger.debug(f"‚è±Ô∏è  [{worker_name}] ASR –æ–±—Ä–∞–±–æ—Ç–∫–∞: {asr_elapsed:.0f}–º—Å (–∞—É–¥–∏–æ {segment_duration:.2f}—Å)")
            except Exception as e:  # noqa: BLE001
                logger.exception(f"ASR –æ—à–∏–±–∫–∞: {e}")
                return
            self._handle_foreign_text(text, asr_elapsed=asr_elapsed, processing_start=processing_start)
        else:
            logger.info("–Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å")

    def _handle_foreign_text(self, text: Optional[str], asr_elapsed: float = 0.0, processing_start: Optional[float] = None) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á—É–∂–æ–≥–æ –≥–æ–ª–æ—Å–∞: ASR ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ ‚Üí LLM –æ—Ç–≤–µ—Ç ‚Üí TTS
        
        Args:
            text: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç ASR
            asr_elapsed: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ASR –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            processing_start: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–æ ASR), –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        """
        if processing_start is None:
            processing_start = time.time()
        
        t = (text or "").strip()
        if not t:
            logger.info("–ß—É–∂–æ–π –≥–æ–ª–æ—Å (ASR: –ø—É—Å—Ç–æ)")
            return
        
        # –ù–ï –±–ª–æ–∫–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —á—É–∂–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ - –æ–Ω–∏ –í–°–ï–ì–î–ê –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è
        # –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–∞–º–æ–ø–æ–¥—Ö–≤–∞—Ç–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ VAD (–≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ live_verify)
        # –∏ —á–µ—Ä–µ–∑ —Ñ–ª–∞–≥ _is_announcing (–≤ segment_worker_loop)
        
        logger.info(f"–ß—É–∂–æ–π –≥–æ–ª–æ—Å (ASR): {t}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        now = time.time()
        self._dialogue_context.append((now, t))
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (>30 —Å–µ–∫)
        cutoff_time = now - self._context_window_sec
        self._dialogue_context = [(ts, txt) for ts, txt in self._dialogue_context if ts >= cutoff_time]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–ø–ª–∏–∫–∏) –∏ —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –û–¢–î–ï–õ–¨–ù–û
        if len(self._dialogue_context) > 1:
            # –ï—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–ø–ª–∏–∫–∏ - –ø–µ—Ä–µ–¥–∞—ë–º –∏—Ö –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context_items = [txt for _, txt in self._dialogue_context[:-1]]
            context_text = "\n".join(context_items)
            current_question = t
        else:
            # –ü–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å - –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç
            context_text = None
            current_question = t
        
        logger.debug(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {len(self._dialogue_context)-1} —Ä–µ–ø–ª–∏–∫, —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: {current_question}")
        
        # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 3C: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ + –ø—Ä–æ–≥—Ä–µ–≤ TTS
        # –ó–∞–ø—É—Å–∫–∞–µ–º Gemini –∏ TTS warmup –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ‚Üí —É—Å–∫–æ—Ä–µ–Ω–∏–µ 15-25%
        # –°–º. OPTIMIZATION_TABLE.md - –∫–æ–¥ 3C
        if self._thesis_generator is None and GeminiThesisGenerator is not None:
            try:
                self._thesis_generator = GeminiThesisGenerator()
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å thesis_generator: {e}")
        
        if self._thesis_generator:
            try:
                from concurrent.futures import ThreadPoolExecutor, as_completed
                
                gemini_start = time.time()
                
                # –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∑–∏—Å–æ–≤
                def generate_theses():
                    return self._thesis_generator.generate(
                        current_question, 
                        n=5, 
                        language="ru",
                        context=context_text
                    )
                
                # –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–µ–≤–∞ TTS (—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–µ –∞—É–¥–∏–æ)
                def warmup_tts():
                    if self._tts is not None:
                        try:
                            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞ –º–æ–¥–µ–ª–∏
                            warmup_text = "—Ç–µ—Å—Ç"
                            warmup_audio = self._tts.synth(warmup_text)
                            
                            # –ï—Å–ª–∏ bytes - –¥–µ–∫–æ–¥–∏—Ä—É–µ–º
                            if isinstance(warmup_audio, bytes) and len(warmup_audio) > 0:
                                with wave.open(io.BytesIO(warmup_audio), 'rb') as wf:
                                    frames = wf.readframes(wf.getnframes())
                                    warmup_audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                            
                            logger.debug("‚úì TTS –ø—Ä–æ–≥—Ä–µ—Ç")
                            return True
                        except Exception as e:
                            logger.debug(f"TTS warmup –æ—à–∏–±–∫–∞: {e}")
                            return False
                    return False
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ ThreadPoolExecutor
                with ThreadPoolExecutor(max_workers=2, thread_name_prefix="gen-warmup") as executor:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–µ –∑–∞–¥–∞—á–∏
                    thesis_future = executor.submit(generate_theses)
                    warmup_future = executor.submit(warmup_tts)
                    
                    # –ñ–¥—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (Gemini –æ–±—ã—á–Ω–æ –¥–æ–ª—å—à–µ, –ø–æ—ç—Ç–æ–º—É –∂–¥—ë–º –µ–≥–æ)
                    theses_raw = thesis_future.result(timeout=5.0)
                    # TTS warmup –º–æ–∂–µ—Ç –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è –±—ã—Å—Ç—Ä–µ–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º
                    try:
                        warmup_future.result(timeout=0.1)
                    except Exception:
                        pass
                
                llm_elapsed = (time.time() - gemini_start) * 1000
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π –¥–≤–∏–∂–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è
                llm_name = "LLM"
                if hasattr(self._thesis_generator, 'primary_engine'):
                    if self._thesis_generator.primary_engine == "cerebras":
                        llm_name = "Cerebras"
                    elif self._thesis_generator.primary_engine == "gemini":
                        llm_name = "Gemini"
                
                logger.debug(f"‚è±Ô∏è  {llm_name} API (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å TTS warmup): {llm_elapsed:.0f}–º—Å")
                
                # –ü–∞—Ä—Å–∏–º —Ç–µ–∑–∏—Å—ã - –æ–∂–∏–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏–ª–∏ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å |||
                theses = []
                if isinstance(theses_raw, list):
                    # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ - –ø–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ
                    for item in theses_raw:
                        if "|||" in item:
                            theses.extend([t.strip() for t in item.split("|||") if t.strip()])
                        else:
                            theses.append(item.strip())
                elif isinstance(theses_raw, str):
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ - –ø–∞—Ä—Å–∏–º –ø–æ |||
                    theses = [t.strip() for t in theses_raw.split("|||") if t.strip()]
                
                if theses:
                    logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ç–µ–∑–∏—Å—ã ({len(theses)}): {theses}")
                    
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ThesisManager –Ω–æ–≤—ã–º –≤–æ–ø—Ä–æ—Å–æ–º
                    self._thesis_manager.start_new_question(
                        question=current_question,
                        theses=theses,
                        context=context_text
                    )
                    
                    # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –æ–∑–≤—É—á–∫—É (–Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º–∏ —Ç–µ–∑–∏—Å–∞–º–∏) - –º–≥–Ω–æ–≤–µ–Ω–Ω–æ!
                    if self._is_announcing:
                        logger.info("üö® –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º–∏ —Ç–µ–∑–∏—Å–∞–º–∏ - –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ç–µ–∑–∏—Å—ã")
                        
                        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–∫–æ–ª–µ–Ω–∏–π - —Å—Ç–∞—Ä—ã–π –ø–æ—Ç–æ–∫ —É–≤–∏–¥–∏—Ç —á—Ç–æ —É—Å—Ç–∞—Ä–µ–ª
                        self._tts_generation += 1
                        
                        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                        self._tts_interrupt.set()
                        
                        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (–ø—Ä–µ—Ä—ã–≤–∞–µ–º sd.wait())
                        if sd is not None:
                            try:
                                sd.stop()
                                logger.debug("sd.stop() –≤—ã–∑–≤–∞–Ω –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –æ–∑–≤—É—á–∫–∏")
                            except Exception as e:
                                logger.debug(f"sd.stop() –æ—à–∏–±–∫–∞: {e}")
                        
                        # –î–∞–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä–æ–º—É –ø–æ—Ç–æ–∫—É –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                        if self._thesis_thread is not None and self._thesis_thread.is_alive():
                            logger.debug("–ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å—Ç–∞—Ä–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –æ–∑–≤—É—á–∫–∏...")
                            self._thesis_thread.join(timeout=0.5)
                            
                            if self._thesis_thread.is_alive():
                                logger.warning("‚ö†Ô∏è –°—Ç–∞—Ä—ã–π –ø–æ—Ç–æ–∫ –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–π (–≤–µ—Ä—Å–∏–æ–Ω–Ω–æ—Å—Ç—å)")
                    
                    # –í—Å–µ–≥–¥–∞ –æ—á–∏—â–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                    self._tts_interrupt.clear()
                    
                    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º —Ç–µ–∫—É—â–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞
                    current_generation = self._tts_generation
                    
                    # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 8A: –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞
                    total_elapsed = (time.time() - processing_start) * 1000
                    # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–ª—é –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
                    asr_pct = (asr_elapsed / total_elapsed * 100) if total_elapsed > 0 else 0
                    llm_pct = (llm_elapsed / total_elapsed * 100) if total_elapsed > 0 else 0
                    other_pct = 100 - asr_pct - llm_pct
                    
                    logger.info(
                        f"‚è±Ô∏è  –ú–ï–¢–†–ò–ö–ò –û–ë–†–ê–ë–û–¢–ö–ò –í–û–ü–†–û–°–ê:\n"
                        f"  ‚Ä¢ ASR:     {asr_elapsed:6.0f}–º—Å ({asr_pct:5.1f}%)\n"
                        f"  ‚Ä¢ {llm_name:8s} {llm_elapsed:6.0f}–º—Å ({llm_pct:5.1f}%)\n"
                        f"  ‚Ä¢ –î—Ä—É–≥–æ–µ:  {other_pct:5.1f}% (–ø–∞—Ä—Å–∏–Ω–≥, –∫–æ–Ω—Ç–µ–∫—Å—Ç)\n"
                        f"  ‚Ä¢ –ò–¢–û–ì–û:   {total_elapsed:6.0f}–º—Å"
                    )
                    
                    # –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∑–∏—Å—ã –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–µ–º –Ω–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
                    def announce_theses():
                        my_generation = current_generation  # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º —Å–≤–æ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ
                        self._is_announcing = True
                        logger.debug(f"üé§ –ù–∞—á–∏–Ω–∞—é –æ–∑–≤—É—á–∫—É —Ç–µ–∑–∏—Å–æ–≤ (–ø–æ–∫–æ–ª–µ–Ω–∏–µ {my_generation})")
                        try:
                            # –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∑–∏—Å—ã —á–µ—Ä–µ–∑ ThesisManager
                            while self._thesis_manager.has_more_theses():
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ (–Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º–∏ —Ç–µ–∑–∏—Å–∞–º–∏)
                                if self._tts_generation > my_generation or self._tts_interrupt.is_set() or self._stop_requested.is_set():
                                    logger.info(f"‚ö†Ô∏è –û–∑–≤—É—á–∫–∞ —Ç–µ–∑–∏—Å–æ–≤ –ø—Ä–µ—Ä–≤–∞–Ω–∞ (gen {my_generation} -> {self._tts_generation})")
                                    break
                                
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ç–µ–∑–∏—Å
                                thesis = self._thesis_manager.get_next_thesis()
                                if not thesis:
                                    # –ù–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö —Ç–µ–∑–∏—Å–æ–≤, –∂–¥–µ–º —É–≥–ª—É–±–ª–µ–Ω–Ω—ã—Ö
                                    time.sleep(0.1)
                                    continue
                                
                                # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                                with self._thesis_manager.lock:
                                    idx = self._thesis_manager.current_idx + 1
                                    repeat = self._thesis_manager.current_repeat
                                    total = len(self._thesis_manager.theses)
                                
                                logger.debug(f"üîä –¢–µ–∑–∏—Å {idx}/{total} ({repeat}/2): {thesis[:50]}...")
                                
                                # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –û–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∑–∏—Å —Å –∏–Ω–¥–µ–∫—Å–æ–º –¥–ª—è –∫—ç—à–∞
                                self._speak_text(thesis, generation=my_generation, thesis_index=self._thesis_manager.current_idx)
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –æ–∑–≤—É—á–∫–∏
                                if self._tts_generation > my_generation or self._tts_interrupt.is_set() or self._stop_requested.is_set():
                                    logger.info(f"‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ—Å–ª–µ –æ–∑–≤—É—á–∫–∏ —Ç–µ–∑–∏—Å–∞ {idx} ({repeat}/2)")
                                    break
                                
                                # –¢—Ä–∏–≥–≥–µ—Ä —É–≥–ª—É–±–ª–µ–Ω–∏—è (–ø–æ—Å–ª–µ 3-–≥–æ —Ç–µ–∑–∏—Å–∞, 2-–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ)
                                if self._thesis_manager.should_trigger_deeper():
                                    logger.info(f"üöÄ –¢—Ä–∏–≥–≥–µ—Ä —É–≥–ª—É–±–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ç–µ–∑–∏—Å–∞ {idx} (repeat {repeat})")
                                    self._thesis_manager.trigger_deeper_async()
                                
                                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—é/—Ç–µ–∑–∏—Å—É
                                self._thesis_manager.advance()
                                
                                # –ü–∞—É–∑—ã –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏ –∏ —Ç–µ–∑–∏—Å–∞–º–∏
                                with self._thesis_manager.lock:
                                    next_repeat = self._thesis_manager.current_repeat
                                if next_repeat == 1:
                                    # –ü–µ—Ä–µ—à–ª–∏ –∫ –Ω–æ–≤–æ–º—É —Ç–µ–∑–∏—Å—É - –ø–∞—É–∑–∞ –¥–ª–∏–Ω–Ω–µ–µ
                                    time.sleep(0.3)
                                else:
                                    # –ú–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏ - –ø–∞—É–∑–∞ –∫–æ—Ä–æ—á–µ
                                    time.sleep(0.15)
                            
                            if self._tts_generation == my_generation and not (self._tts_interrupt.is_set() or self._stop_requested.is_set()):
                                logger.debug(f"‚úÖ –û–∑–≤—É—á–∫–∞ –≤—Å–µ—Ö —Ç–µ–∑–∏—Å–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (gen {my_generation})")
                        finally:
                            self._is_announcing = False
                            logger.debug(f"üé§ –û–∑–≤—É—á–∫–∞ —Ç–µ–∑–∏—Å–æ–≤ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ (gen {my_generation})")
                    
                    self._thesis_thread = threading.Thread(target=announce_theses, name="thesis-announcer", daemon=True)
                    self._thesis_thread.start()
                else:
                    logger.warning("–¢–µ–∑–∏—Å—ã –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã (–ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∑–∏—Å–æ–≤: {e}")

    @staticmethod
    def _should_ignore_non_question_text(text: str) -> bool:
        """–§–∏–ª—å—Ç—Ä —è–≤–Ω—ã—Ö –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞–¥–æ —Ç—Ä–∞–∫—Ç–æ–≤–∞—Ç—å –∫–∞–∫ –≤–æ–ø—Ä–æ—Å—ã.
        –ü—Ä–∏–º–µ—Ä—ã: "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è –º—É–∑—ã–∫–∞", "–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –º—É–∑—ã–∫–∞" –∏ —Ç.–ø.
        """
        if not text:
            return False
        import re
        s = text.strip().lower()
        patterns = [
            r"\b–¥–∏–Ω–∞–º–∏—á\w*\s+–º—É–∑—ã–∫\w*\b",
        ]
        for p in patterns:
            try:
                if re.search(p, s):
                    return True
            except Exception:
                continue
        return False

    def _handle_self_transcript(self, transcript: Optional[str]) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–≤–æ–µ–π —Ä–µ—á–∏ - –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º."""
        t = (transcript or "").strip()
        if not t:
            return
        logger.info(f"–ú–æ—è —Ä–µ—á—å (—Ñ–∏–ª—å—Ç—Ä—É–µ–º): {t}")

    def simulate_dialogue(self, events: List[tuple[str, str]]) -> None:
        """–ü—Ä–æ–≥–æ–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–µ–ø–ª–∏–∫ –±–µ–∑ –∞—É–¥–∏–æ.

        events: —Å–ø–∏—Å–æ–∫ ("self"|"other", —Ç–µ–∫—Å—Ç), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–æ–≥–Ω–∞—Ç—å
        –∫–æ–Ω–≤–µ–π–µ—Ä —Å –≥–æ—Ç–æ–≤—ã–º–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞–º–∏. –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤.
        """
        for role, content in events:
            kind = (role or "").strip().lower()
            if kind in {"self", "me", "candidate"}:
                self._handle_self_transcript(content)
            elif kind in {"other", "interviewer", "question"}:
                self._handle_foreign_text(content)

    # ==== –ê—É–¥–∏–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: –ø—Ä–æ—Å—Ç–æ–π highpass + AGC –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ====
    @staticmethod
    def _highpass_simple(wav: np.ndarray, sr: int = SAMPLE_RATE, cutoff_hz: int = 80) -> np.ndarray:
        if wav.ndim != 1:
            wav = wav.reshape(-1)
        # –û–¥–Ω–æ–ø–æ–ª—é—Å–Ω—ã–π HPF
        rc = 1.0 / (2 * np.pi * float(cutoff_hz))
        dt = 1.0 / float(sr)
        alpha = rc / (rc + dt)
        y = np.zeros_like(wav, dtype=np.float32)
        prev_y = 0.0
        prev_x = 0.0
        for i in range(wav.size):
            x = float(wav[i])
            hp = alpha * (prev_y + x - prev_x)
            y[i] = hp
            prev_y = hp
            prev_x = x
        return y

    @staticmethod
    def _apply_agc(wav: np.ndarray, target_rms: float = 0.03, max_gain: float = 10.0) -> np.ndarray:
        if wav.ndim != 1:
            wav = wav.reshape(-1)
        rms = float(np.sqrt(np.mean(np.square(wav)) + 1e-12))
        if rms <= 1e-6:
            return wav
        gain = min(max_gain, max(0.1, target_rms / rms))
        out = np.clip(wav * gain, -1.0, 1.0)
        return out.astype(np.float32)

    @staticmethod
    def _preprocess_segment(wav: np.ndarray, sr: int = SAMPLE_RATE) -> np.ndarray:
        y = LiveVoiceVerifier._highpass_simple(wav, sr=sr, cutoff_hz=80)
        y = LiveVoiceVerifier._apply_agc(y, target_rms=0.03)
        return y

    # ==== –£—Å—Ç–æ–π—á–∏–≤—ã–π –ø–∞—Ä—Å–µ—Ä —Ç–µ–∑–∏—Å–æ–≤ –∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ ====
    @staticmethod
    def _parse_theses_from_raw(raw: str, n_max: int = 3) -> List[str]:
        import json, re
        s = (raw or "").strip()
        if not s:
            return []
        # –£–±–µ—Ä—ë–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ–±—Ä–∞–º–ª—è—é—â–∏–µ –∫–∞–≤—ã—á–∫–∏, –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –µ—Å—Ç—å —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏
        if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
            if '{' in s and '}' in s:
                s = s[1:-1].strip()

        def _from_dict(d: dict) -> List[str]:
            items = d.get("theses", []) if isinstance(d, dict) else []
            out: List[str] = []
            for it in items:
                if isinstance(it, str):
                    t = it.strip()
                    if t:
                        out.append(t)
            return out

        # –°–Ω–∏–º–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ code fences ```...```
        if s.startswith("```"):
            # –≤–æ–∑—å–º—ë–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–µ–∂–¥—É –ø–µ—Ä–≤–æ–π –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç—Ä–æ–π–Ω–æ–π –∫–∞–≤—ã—á–∫–æ–π
            m = re.findall(r"```[a-zA-Z]*\n([\s\S]*?)\n```", s)
            if m:
                s = m[-1].strip()

        # –ü–æ–ø—ã—Ç–∫–∞ 1: –ø—Ä—è–º–æ–π JSON / –∏–ª–∏ JSON-—Å—Ç—Ä–æ–∫–∞
        try:
            obj = json.loads(s)
            if isinstance(obj, str):
                # –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞ JSON
                try:
                    obj2 = json.loads(obj)
                    if isinstance(obj2, dict):
                        vals = _from_dict(obj2)
                        if vals:
                            return vals[:n_max]
                except Exception:
                    pass
            elif isinstance(obj, dict):
                vals = _from_dict(obj)
                if vals:
                    return vals[:n_max]
            elif isinstance(obj, list):
                # –∏–Ω–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—ë—Ç –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
                out: List[str] = []
                for it in obj:
                    if isinstance(it, str):
                        t = it.strip()
                        if t:
                            out.append(t)
                if out:
                    return out[:n_max]
        except Exception:
            pass

        # –ü–æ–ø—ã—Ç–∫–∞ 2: –≤—ã—Ç–∞—â–∏—Ç—å –ø–µ—Ä–≤—ã–π JSON-–æ–±—ä–µ–∫—Ç –ø–æ —Ñ–∏–≥—É—Ä–Ω—ã–º —Å–∫–æ–±–∫–∞–º
        try:
            start = s.find("{")
            end = s.rfind("}")
            if start != -1 and end != -1 and end > start:
                sub = s[start : end + 1]
                d = json.loads(sub)
                vals = _from_dict(d)
                if vals:
                    return vals[:n_max]
        except Exception:
            pass

        # –ü–æ–ø—ã—Ç–∫–∞ 3: —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
        parts: List[str] = []
        s2 = s.replace(";", "\n")
        for line in s2.splitlines():
            t = line.strip()
            # –£–±–µ—Ä—ë–º –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤ –∏ –Ω—É–º–µ—Ä–∞—Ü–∏—é
            t = re.sub(r"^[\-‚Ä¢*\s]*", "", t)
            t = re.sub(r"^\d+[\).]\s*", "", t)
            # –û—Ç–±—Ä–æ—Å–∏–º —è–≤–Ω—ã–µ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if not t or t in {"[", "]", "{", "}", "},", "],"}:
                continue
            # –ü—Ä–æ–ø—É—Å—Ç–∏–º —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è/–∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–µ—Å—è —Å–∫–æ–±–∫–∞–º–∏ ‚Äî —ç—Ç–æ, –≤–µ—Ä–æ—è—Ç–Ω–æ, JSON
            if t.startswith("{") or t.startswith("[") or t.endswith("}") or t.endswith("]"):
                continue
            # –£–±–µ—Ä—ë–º –∑–∞–≤–µ—Ä—à–∞—é—â–∏–µ –∑–∞–ø—è—Ç—ã–µ
            if t.endswith(","):
                t = t[:-1].strip()
            # –£–±–µ—Ä—ë–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
            if (t.startswith('"') and t.endswith('"')) or (t.startswith("'") and t.endswith("'")):
                t = t[1:-1].strip()
            # –ü—Ä–æ–ø—É—Å—Ç–∏–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ key: value (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ JSON-–∫–ª—é—á–∏, –Ω–∞–ø—Ä. "theses": [)
            if re.match(r'^"?[A-Za-z_][\w\s\-]*"?\s*:\s*', t):
                continue
            # –ü—Ä–æ–ø—É—Å—Ç–∏–º –ø—É—Å—Ç—è–∫–æ–≤—ã–µ —Å–∫–æ–±–∫–∏
            if t in {"[", "]"}:
                continue
            # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç c –±—É–∫–≤–∞–º–∏
            if not any(ch.isalpha() for ch in t):
                continue
            parts.append(t)
        return parts[:n_max]

    def _collect_enrollment_audio(
        self,
        seconds: float = 5.0,
        min_voiced_seconds: float = 2.0,
        silence_stop_sec: float = 1.2,
    ) -> np.ndarray:
        """–°–æ–±–∏—Ä–∞–µ–º —Å–∏–≥–Ω–∞–ª —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ–∑–≤—É—á–µ–Ω–Ω—ã–µ (VAD) —Ñ—Ä–µ–π–º—ã."""
        q: "queue.Queue[np.ndarray]" = queue.Queue()

        def callback(indata, frames, time_info, status):  # noqa: ANN001
            if status:
                logger.warning(f"InputStream status: {status}")
            q.put(indata.copy())

        voiced_samples: List[np.ndarray] = []
        voiced_duration = 0.0
        silence_stop_sec = max(0.6, float(silence_stop_sec))
        target_end = time.time() + max(1.0, float(seconds))
        last_voiced_ts: Optional[float] = None

        with sd.InputStream(
            channels=CHANNELS,
            samplerate=SAMPLE_RATE,
            dtype="float32",
            blocksize=FRAME_SIZE,  # deliver 20ms blocks
            callback=callback,
        ):
            logger.info("–ì–æ–≤–æ—Ä–∏—Ç–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –ø—Ä–æ—Ñ–∏–ª—è...")
            while True:
                now = time.time()
                if now >= target_end:
                    logger.debug("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –ø—Ä–æ—Ñ–∏–ª—è: –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
                    break
                if (
                    voiced_duration >= min_voiced_seconds
                    and last_voiced_ts is not None
                    and (now - last_voiced_ts) >= silence_stop_sec
                ):
                    logger.debug("–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –ø—Ä–æ—Ñ–∏–ª—è: –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ —Ç–∏—à–∏–Ω–∞ –ø–æ—Å–ª–µ —Ä–µ—á–∏")
                    break
                try:
                    block = q.get(timeout=0.5)[:, 0]  # mono
                except queue.Empty:
                    continue
                # VAD on 20ms subframes
                # block may be larger than FRAME_SIZE if sounddevice batches; split it
                i = 0
                while i + FRAME_SIZE <= len(block):
                    frame = block[i : i + FRAME_SIZE]
                    i += FRAME_SIZE
                    is_speech = self._vad_fn(frame)
                    if is_speech:
                        voiced_samples.append(frame)
                        voiced_duration += FRAME_MS / 1000.0
                        last_voiced_ts = time.time()

        if voiced_duration < min_voiced_seconds:
            logger.warning(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—á–∏ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è: {voiced_duration:.2f}s < {min_voiced_seconds:.2f}s"
            )

        if len(voiced_samples) == 0:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –≥–æ–ª–æ—Å –¥–ª—è —ç–Ω—Ä–æ–ª–ª–º–µ–Ω—Ç–∞")

        logger.info(
            "–°–µ–≥–º–µ–Ω—Ç –ø—Ä–æ—Ñ–∏–ª—è —Å–æ–±—Ä–∞–Ω: –æ–∑–≤—É—á–µ–Ω–æ {dur:.2f}s, –∫–∞–¥—Ä–æ–≤ {frames}",
            dur=voiced_duration,
            frames=len(voiced_samples),
        )

        return np.concatenate(voiced_samples, axis=0)

    def enroll(
        self,
        path: Path,
        seconds: float = 20.0,
        min_voiced_seconds: float = 2.0,
        silence_stop_sec: float = 1.2,
    ) -> VoiceProfile:
        wav = self._collect_enrollment_audio(
            seconds=seconds,
            min_voiced_seconds=min_voiced_seconds,
            silence_stop_sec=silence_stop_sec,
        )
        emb = self.embedding_from_waveform(wav)
        profile = VoiceProfile(embedding=emb)
        profile.save(path)
        logger.info(f"–ü—Ä–æ—Ñ–∏–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path}")
        return profile

    def live_verify(
        self,
        profile: VoiceProfile,
        min_segment_ms: int = 1500,  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ (1.5s = —Ñ–∏–ª—å—Ç—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö —à—É–º–æ–≤)
        max_silence_ms: int = 400,  # –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –ø–∞—É–∑—ã
        pre_roll_ms: int = 160,     # –ø—Ä–µ–¥–∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –¥–æ —Å—Ç–∞—Ä—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
        run_seconds: float = 0.0,   # –∞–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ (0 = –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ)
    ) -> None:
        """–°–ª—É—à–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º —Ä–µ—á–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        —Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ —Ä–µ—à–∞–µ–º: –º–æ–π –≥–æ–ª–æ—Å –∏–ª–∏ –Ω–µ–∑–Ω–∞–∫–æ–º—ã–π –≥–æ–ª–æ—Å.
        –ü–µ—á–∞—Ç–∞–µ–º –≤—ã–≤–æ–¥ —Å—Ä–∞–∑—É –≤ –∫–æ–Ω—Å–æ–ª—å.
        """

        q: "queue.Queue[np.ndarray]" = queue.Queue()

        def callback(indata, frames, time_info, status):  # noqa: ANN001
            if status:
                logger.warning(f"InputStream status: {status}")
            q.put(indata.copy())

        seg_audio: List[np.ndarray] = []
        pre_frames: List[np.ndarray] = []  # –±—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–∞–ø–ª–∏–≤–∞–Ω–∏—è –ø–æ–¥—Ä—è–¥ —Ä–µ—á–µ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤ –¥–æ —Å—Ç–∞—Ä—Ç–∞
        # –ë—É—Ñ–µ—Ä –ø—Ä–µ–¥–∑–∞—Ö–≤–∞—Ç–∞: –ø–æ—Å–ª–µ–¥–Ω–∏–µ pre_roll_ms –¥–æ —Å—Ç–∞—Ä—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–∞
        pre_roll_frames_cnt = max(0, int(np.ceil(pre_roll_ms / FRAME_MS)))
        pre_roll = deque(maxlen=pre_roll_frames_cnt)
        voiced_ms = 0
        silence_ms = 0
        in_speech = False
        consec_speech = 0

        logger.info(
            "–°—Ç–∞—Ä—Ç –ª–∞–π–≤-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è. –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏. –ì–æ–≤–æ—Ä–∏—Ç–µ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω."
        )
        # –ù–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º —Ç–µ–∑–∏—Å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ - –∂–¥—ë–º –≤–æ–ø—Ä–æ—Å–∞

        stop_at = time.time() + run_seconds if run_seconds and run_seconds > 0 else None
        stream = None
        try:
            self._start_segment_worker()
            stream = sd.InputStream(
                channels=CHANNELS,
                samplerate=SAMPLE_RATE,
                dtype="float32",
                blocksize=FRAME_SIZE,  # deliver 20ms blocks
                callback=callback,
            )
            with stream:
                while True:
                    if self._stop_requested.is_set():
                        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ —Ñ–ª–∞–≥—É _stop_requested")
                        break
                    if stop_at is not None and time.time() >= stop_at:
                        logger.info("–ê–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ —Ç–∞–π–º–µ—Ä—É run_seconds")
                        break
                    try:
                        block = q.get(timeout=0.5)[:, 0]
                    except queue.Empty:
                        continue

                    # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å–∞–º–æ–ø–æ–¥—Ö–≤–∞—Ç–∞: –±–ª–æ–∫–∏—Ä—É–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∏–Ω–∞–º–∏–∫–∏
                    # –° –Ω–∞—É—à–Ω–∏–∫–∞–º–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–µ—à–∞–µ—Ç –ª–æ–≤–∏—Ç—å –Ω–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                    if not self._use_headphones and time.time() < self._suppress_until:
                        continue

                    i = 0
                    while i + FRAME_SIZE <= len(block):
                        frame = block[i : i + FRAME_SIZE]
                        # –æ–±–Ω–æ–≤–ª—è–µ–º pre-roll –≤—Å–µ–≥–¥–∞ (–≤ —Ç–æ–º —á–∏—Å–ª–µ –≤ —Ç–∏—à–∏–Ω–µ)
                        if pre_roll_frames_cnt > 0:
                            pre_roll.append(frame.copy())
                        i += FRAME_SIZE
                        is_speech = self._vad_fn(frame)

                        if is_speech:
                            consec_speech += 1
                            if not in_speech:
                                # –µ—â—ë –Ω–µ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª–∏ —Å–µ–≥–º–µ–Ω—Ç: –∫–æ–ø–∏–º pre_frames
                                pre_frames.append(frame)
                                if consec_speech >= self.min_consec_speech_frames:
                                    # —Å—Ç–∞—Ä—Ç —Å–µ–≥–º–µ–Ω—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–∑–∞—Ö–≤–∞—Ç, –∑–∞—Ç–µ–º pre_frames
                                    if pre_roll_frames_cnt > 0 and len(pre_roll) > 0:
                                        seg_audio.extend(list(pre_roll))
                                        pre_roll.clear()
                                    seg_audio.extend(pre_frames)
                                    pre_frames.clear()
                                    in_speech = True
                                    voiced_ms = self.min_consec_speech_frames * FRAME_MS
                            else:
                                seg_audio.append(frame)
                                voiced_ms += FRAME_MS
                            silence_ms = 0
                        else:
                            consec_speech = 0
                            pre_frames.clear()
                            if in_speech:
                                silence_ms += FRAME_MS

                        # –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞
                        if in_speech and silence_ms >= max_silence_ms:
                            in_speech = False
                            total_ms = voiced_ms
                            wav = (
                                np.concatenate(seg_audio, axis=0)
                                if len(seg_audio) > 0
                                else np.array([], dtype=np.float32)
                            )
                            seg_audio.clear()
                            voiced_ms = 0
                            silence_ms = 0

                            if total_ms < min_segment_ms or wav.size < FRAME_SIZE:
                                # —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                                continue

                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–±—Ä–∞–∫–æ–≤–∫–∞ —à—É–º–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–π –ø–ª–æ—Å–∫–æ—Å—Ç–Ω–æ—Å—Ç–∏
                            sf_med = median_spectral_flatness(wav, SAMPLE_RATE)
                            if sf_med >= self.flatness_reject_threshold:
                                # —à—É–º–æ–ø–æ–¥–æ–±–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–µ–∑ –≤—ã–≤–æ–¥–∞
                                continue

                            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: highpass + AGC
                            wav = self._preprocess_segment(wav, sr=SAMPLE_RATE)

                            # —Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
                            emb = self.embedding_from_waveform(wav)
                            dist = self.cosine_distance(emb, profile.embedding)
                            if dist <= self.threshold:
                                self._enqueue_segment("self", wav, dist)
                            else:
                                self._enqueue_segment("other", wav, dist)

        except KeyboardInterrupt:
            logger.info("‚ö†Ô∏è –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
            self._stop_requested.set()
        finally:
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º stream —è–≤–Ω–æ
            if stream is not None:
                try:
                    stream.stop()
                    stream.close()
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ stream: {e}")
            
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–æ—Ä–∫–µ—Ä—ã –∏ –æ—á–µ—Ä–µ–¥–∏
            self._stop_segment_worker()
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ sounddevice
            if sd is not None:
                try:
                    sd.stop()
                except Exception:
                    pass
            
            logger.info("‚úÖ –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def _ensure_asr(self) -> FasterWhisperTranscriber:
        if self._asr is None:
            if FasterWhisperTranscriber is None:
                raise RuntimeError("ASR –º–æ–¥—É–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            self._asr = FasterWhisperTranscriber(
                model_size=self.asr_model_size,
                device=self.asr_device,
                compute_type=self.asr_compute_type,
                language=self.asr_language,
            )
        return self._asr  # type: ignore[return-value]
    
    def _play_cached_audio(self, audio: np.ndarray, generation: Optional[int] = None) -> None:
        """
        ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –∏–∑ –∫—ç—à–∞
        """
        if audio.size <= 0 or self._tts is None:
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ
        if generation is not None and self._tts_generation > generation:
            logger.debug("–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –ø—Ä–µ—Ä–≤–∞–Ω–æ (—É—Å—Ç–∞—Ä–µ–≤—à–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ)")
            return
        
        if self._tts_interrupt.is_set() or self._stop_requested.is_set():
            logger.debug("–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –ø—Ä–µ—Ä–≤–∞–Ω–æ")
            return
        
        duration = float(audio.shape[0]) / float(self._tts.sample_rate)
        
        # –ë–ª–æ–∫–∏—Ä—É–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –¥–∏–Ω–∞–º–∏–∫–∏
        if not self._use_headphones:
            self._suppress_until = time.time() + duration + 0.2
            logger.debug(f"–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–∞ {duration + 0.2:.1f}—Å (–∫—ç—à)")
        
        # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º
        if sd is None:
            return
        
        with self._tts_lock:
            if self._tts_interrupt.is_set() or self._stop_requested.is_set():
                logger.debug("–ü—Ä–µ—Ä–≤–∞–Ω–æ –¥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–∫—ç—à)")
                try:
                    sd.stop()
                except Exception:
                    pass
                return
            
            sd.play(audio, samplerate=self._tts.sample_rate, device=None)
            sd.wait()
            
            if self._tts_interrupt.is_set() or self._stop_requested.is_set():
                logger.debug("–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ—Å–ª–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–∫—ç—à)")
                return

    def _speak_text(self, text: str, generation: Optional[int] = None, thesis_index: Optional[int] = None) -> None:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ TTS –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚Äî –≤—ã—Ö–æ–¥–∏–º
        if not text or self._tts is None:
            return
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫–æ–ª–µ–Ω–∏–µ - –µ—Å–ª–∏ —É—Å—Ç–∞—Ä–µ–ª–∏, –≤—ã—Ö–æ–¥–∏–º
        if generation is not None and self._tts_generation > generation:
            logger.debug(f"TTS –ø—Ä–µ—Ä–≤–∞–Ω–æ (—É—Å—Ç–∞—Ä–µ–≤—à–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ: {generation} < {self._tts_generation})")
            return
        # –í–ê–ñ–ù–û: –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã - –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º
        if not text.strip():
            logger.debug("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç - –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º")
            return
        
        # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 2B: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –ø—Ä–µ–¥–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        cached_audio = None
        if thesis_index is not None:
            cached_audio = self._thesis_manager.get_cached_audio(thesis_index)
            if cached_audio is not None:
                logger.debug(f"‚úì –ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –¥–ª—è —Ç–µ–∑–∏—Å–∞ {thesis_index}")
                # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –Ω–∞–ø—Ä—è–º—É—é
                self._play_cached_audio(cached_audio, generation)
                return
        try:
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º JSON-–ø–æ–¥–æ–±–Ω—ã–µ –∫–ª—é—á–∏ –∏ –ø—É—Å—Ç—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            s = (text or "").strip()
            if not s:
                return
            # –£–¥–∞–ª–∏–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
            if (s.startswith('"') and s.endswith('"')) or (s.startswith("'") and s.endswith("'")):
                s = s[1:-1].strip()
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ: –Ω–µ –æ–∑–≤—É—á–∏–≤–∞–µ–º —Å–ª—É–∂–µ–±–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ,
            # –∞ —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ–º –µ–≥–æ
            try:
                if "–ø—Ä—è–º—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ" in s.lower():
                    logger.info("–ø—Ä—è–º—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                    return
            except Exception:
                # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –¥–∞–∂–µ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ
                # —Å—Ç—Ä–æ–∫–∏ ‚Äî –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ª–æ–≥–∏–∫—É
                pass
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "theses": [], –∞ —Ç–∞–∫–∂–µ –ª—é–±—ã–µ –∫–ª—é—á: –∑–Ω–∞—á–µ–Ω–∏–µ –±–µ–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            import re as _re
            if _re.match(r'^"?\w+"?\s*:\s*(\[.*\]|\{.*\}|".*"|\d+|true|false|null)?\s*$', s, flags=_re.IGNORECASE):
                return
            # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –±—É–∫–≤—ã (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞)
            if not any(ch.isalpha() for ch in s):
                return
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ—Ä–∞–∑—ã, —á—Ç–æ–±—ã TTS –Ω–µ –æ–±—Ä–µ–∑–∞–ª—Å—è –∏ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª –±—ã—Å—Ç—Ä–µ–µ
            def _split_for_tts(t: str, max_len: int = 180) -> list[str]:
                parts: list[str] = []
                # –¥–µ–ª–∏–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
                sent = _re.split(r'([\.\!\?]+\s+)', t)
                buf = ""
                for i in range(0, len(sent), 2):
                    chunk = sent[i]
                    sep = sent[i + 1] if i + 1 < len(sent) else ""
                    piece = (chunk + sep).strip()
                    if not piece:
                        continue
                    if len((buf + " " + piece).strip()) <= max_len:
                        buf = (buf + " " + piece).strip()
                    else:
                        if buf:
                            parts.append(buf)
                        if len(piece) > max_len:
                            words = piece.split()
                            cur = ""
                            for w in words:
                                if len((cur + " " + w).strip()) <= max_len:
                                    cur = (cur + " " + w).strip()
                                else:
                                    if cur:
                                        parts.append(cur)
                                    cur = w
                            if cur:
                                parts.append(cur)
                            buf = ""
                        else:
                            buf = piece
                if buf:
                    parts.append(buf)
                return parts or [t]

            chunks = _split_for_tts(s)

            # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 8A: –ú–µ—Ç—Ä–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ TTS
            tts_start = time.time()
            
            for part in chunks:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ü–ï–†–ï–î —Å–∏–Ω—Ç–µ–∑–æ–º (–Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å)
                if self._tts_interrupt.is_set() or self._stop_requested.is_set():
                    logger.debug("TTS –ø—Ä–µ—Ä–≤–∞–Ω–æ –¥–æ —Å–∏–Ω—Ç–µ–∑–∞")
                    return
                
                chunk_start = time.time()
                audio = self._tts.synth(part)
                chunk_elapsed = (time.time() - chunk_start) * 1000
                logger.debug(f"‚è±Ô∏è  TTS chunk: {chunk_elapsed:.0f}–º—Å ({len(part)} —Å–∏–º–≤–æ–ª–æ–≤)")
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bytes (Google TTS) –≤ numpy array
                if isinstance(audio, bytes):
                    if len(audio) == 0:
                        continue
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º WAV bytes –≤ numpy
                    import io, wave
                    with wave.open(io.BytesIO(audio), 'rb') as wf:
                        frames = wf.readframes(wf.getnframes())
                        audio = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                
                if audio.size <= 0:
                    continue
                duration = float(audio.shape[0]) / float(self._tts.sample_rate)
                # –ë–ª–æ–∫–∏—Ä—É–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –¥–∏–Ω–∞–º–∏–∫–∏ (–Ω–µ –Ω–∞—É—à–Ω–∏–∫–∏)
                # –° –Ω–∞—É—à–Ω–∏–∫–∞–º–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–µ—à–∞–µ—Ç –ª–æ–≤–∏—Ç—å –Ω–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                if not self._use_headphones:
                    # –î–ª—è –¥–∏–Ω–∞–º–∏–∫–æ–≤: –±–ª–æ–∫–∏—Ä—É–µ–º –Ω–∞ –≤—Ä–µ–º—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è + –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∑–∞–ø–∞—Å
                    self._suppress_until = time.time() + duration + 0.2
                    logger.debug(f"–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–∞ {duration + 0.2:.1f}—Å (–¥–∏–Ω–∞–º–∏–∫–∏)")
                else:
                    # –î–ª—è –Ω–∞—É—à–Ω–∏–∫–æ–≤: –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤—Å–µ–≥–¥–∞ –æ—Ç–∫—Ä—ã—Ç
                    logger.debug(f"–ù–∞—É—à–Ω–∏–∫–∏ - –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Å–ª—É—à–∞—Ç—å (TTS {duration:.1f}—Å)")
                if self._audio_sink is not None:
                    import io, wave
                    pcm16 = (np.clip(audio, -1.0, 1.0) * 32767.0).astype(np.int16)
                    buf = io.BytesIO()
                    with wave.open(buf, "wb") as wf:
                        wf.setnchannels(1)
                        wf.setsampwidth(2)
                        wf.setframerate(int(self._tts.sample_rate))
                        wf.writeframes(pcm16.tobytes())
                    wav_bytes = buf.getvalue()
                    try:
                        self._audio_sink(wav_bytes, int(self._tts.sample_rate))
                    except Exception as _e:  # noqa: F841, BLE001
                        logger.debug("Audio sink send failed", _e)
                else:
                    if sd is None:
                        continue
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Lock —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ PaMacCore
                    with self._tts_lock:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º
                        if self._tts_interrupt.is_set() or self._stop_requested.is_set():
                            logger.debug("TTS –ø—Ä–µ—Ä–≤–∞–Ω–æ")
                            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ –µ—Å–ª–∏ –ø—Ä–µ—Ä–≤–∞–Ω–æ
                            try:
                                sd.stop()
                            except Exception:
                                pass
                            continue
                        
                        # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º–Ω—ã–π –≤—ã–≤–æ–¥ (–Ω–∞—É—à–Ω–∏–∫–∏ –µ—Å–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω—ã, –∏–Ω–∞—á–µ –¥–∏–Ω–∞–º–∏–∫–∏)
                        sd.play(audio, samplerate=self._tts.sample_rate, device=None)
                        sd.wait()  # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ü–û–°–õ–ï –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ sd.stop() —Å—Ä–∞–±–æ—Ç–∞–ª –≤–æ –≤—Ä–µ–º—è wait)
                        if self._tts_interrupt.is_set() or self._stop_requested.is_set():
                            logger.debug("TTS –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ—Å–ª–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è")
                            return
            
            # ‚úÖ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø 8A: –ò—Ç–æ–≥–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ TTS
            tts_elapsed = (time.time() - tts_start) * 1000
            logger.debug(f"‚è±Ô∏è  TTS –ò–¢–û–ì–û: {tts_elapsed:.0f}–º—Å ({len(chunks)} chunks)")
            
        except Exception as e:  # noqa: BLE001
            logger.exception(f"TTS –æ—à–∏–±–∫–∞: {e}")

    # ==== –õ–∞–π–≤ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –ø–æ—Ç–æ–∫–∞ –∫–∞–¥—Ä–æ–≤ (20–º—Å) ====
    def live_verify_stream(
        self,
        profile: VoiceProfile,
        frame_queue: "queue.Queue[np.ndarray]",
        min_segment_ms: int = 1500,
        max_silence_ms: int = 400,
        pre_roll_ms: int = 160,
        run_seconds: float = 0.0,
        stop_event: Optional[threading.Event] = None,
    ) -> None:
        """–ê–Ω–∞–ª–æ–≥ live_verify, –Ω–æ –≤–º–µ—Å—Ç–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ —á–∏—Ç–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏ frame_queue.
        –í –æ—á–µ—Ä–µ–¥—å –¥–æ–ª–∂–Ω—ã –ø–æ—Å—Ç—É–ø–∞—Ç—å –º–æ–Ω–æ float32 —Ñ—Ä–µ–π–º—ã –¥–ª–∏–Ω–æ–π FRAME_SIZE (= 20–º—Å @ 16–∫–ì—Ü)."""
        logger.info("–°—Ç–∞—Ä—Ç –ª–∞–π–≤-—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (–≤–Ω–µ—à–Ω–∏–π –ø–æ—Ç–æ–∫ –∫–∞–¥—Ä–æ–≤)")
        seg_audio: List[np.ndarray] = []
        pre_frames: List[np.ndarray] = []
        pre_roll_frames_cnt = max(0, int(np.ceil(pre_roll_ms / FRAME_MS)))
        pre_roll = deque(maxlen=pre_roll_frames_cnt)
        voiced_ms = 0
        silence_ms = 0
        in_speech = False
        consec_speech = 0

        stop_at = time.time() + run_seconds if run_seconds and run_seconds > 0 else None
        try:
            self._start_segment_worker()
            leftover: Optional[np.ndarray] = None
            while True:
                if stop_event is not None and stop_event.is_set():
                    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ live_verify_stream –ø–æ —Å–∏–≥–Ω–∞–ª—É stop_event")
                    break
                if stop_at is not None and time.time() >= stop_at:
                    logger.info("–ê–≤—Ç–æ-–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ live_verify_stream –ø–æ —Ç–∞–π–º–µ—Ä—É run_seconds")
                    break
                try:
                    block = frame_queue.get(timeout=0.5)
                except queue.Empty:
                    continue

                # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å–∞–º–æ–ø–æ–¥—Ö–≤–∞—Ç–∞: –±–ª–æ–∫–∏—Ä—É–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∏–Ω–∞–º–∏–∫–∏
                # –° –Ω–∞—É—à–Ω–∏–∫–∞–º–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Å–ª—ã—à–∏—Ç TTS, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–µ—à–∞–µ—Ç –ª–æ–≤–∏—Ç—å –Ω–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                if not self._use_headphones and time.time() < self._suppress_until:
                    continue

                # —Å–∫–ª–µ–∏–º —Å —Ö–≤–æ—Å—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –±–ª–æ–∫–∞, –µ—Å–ª–∏ –±—ã–ª
                if leftover is not None and leftover.size > 0:
                    block = np.concatenate([leftover, block.astype(np.float32).reshape(-1)])
                    leftover = None
                else:
                    block = block.astype(np.float32).reshape(-1)

                i = 0
                n = block.shape[0]
                while i + FRAME_SIZE <= n:
                    frame = block[i : i + FRAME_SIZE]
                    i += FRAME_SIZE
                    if pre_roll_frames_cnt > 0:
                        pre_roll.append(frame.copy())
                    is_speech = self._vad_fn(frame)
                    if is_speech:
                        consec_speech += 1
                        if not in_speech:
                            pre_frames.append(frame)
                            if consec_speech >= self.min_consec_speech_frames:
                                if pre_roll_frames_cnt > 0 and len(pre_roll) > 0:
                                    seg_audio.extend(list(pre_roll))
                                    pre_roll.clear()
                                seg_audio.extend(pre_frames)
                                pre_frames.clear()
                                in_speech = True
                                voiced_ms = self.min_consec_speech_frames * FRAME_MS
                        else:
                            seg_audio.append(frame)
                            voiced_ms += FRAME_MS
                        silence_ms = 0
                    else:
                        consec_speech = 0
                        pre_frames.clear()
                        if in_speech:
                            silence_ms += FRAME_MS

                    if in_speech and silence_ms >= max_silence_ms:
                        in_speech = False
                        total_ms = voiced_ms
                        wav = (
                            np.concatenate(seg_audio, axis=0)
                            if len(seg_audio) > 0
                            else np.array([], dtype=np.float32)
                        )
                        seg_audio.clear()
                        voiced_ms = 0
                        silence_ms = 0
                        if total_ms < min_segment_ms or wav.size < FRAME_SIZE:
                            continue
                        sf_med = median_spectral_flatness(wav, SAMPLE_RATE)
                        if sf_med >= self.flatness_reject_threshold:
                            continue
                        wav = self._preprocess_segment(wav, sr=SAMPLE_RATE)
                        emb = self.embedding_from_waveform(wav)
                        dist = self.cosine_distance(emb, profile.embedding)
                        if dist <= self.threshold:
                            self._enqueue_segment("self", wav, dist)
                        else:
                            self._enqueue_segment("other", wav, dist)

                # —Å–æ—Ö—Ä–∞–Ω–∏–º —Ö–≤–æ—Å—Ç, –µ—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è –Ω–µ–ø–æ–ª–Ω—ã–π –∫–∞–¥—Ä
                if i < n:
                    leftover = block[i:]
                else:
                    leftover = None
        except KeyboardInterrupt:
            logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        finally:
            self._stop_segment_worker()

    def _append_question_context(self, text: str) -> None:
        if not text:
            return
        if self._question_context:
            self._question_context += "\n"
        self._question_context += text.strip()
        # –û–≥—Ä–∞–Ω–∏—á–∏–º –æ–∫–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–∏–º–≤–æ–ª–æ–≤
        if len(self._question_context) > self._max_question_context_chars:
            self._question_context = self._question_context[-self._max_question_context_chars :]
        # –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–∑–∏—Å–æ–≤ –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏ (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º —É—Ç–µ—á–∫—É –ø–∞–º—è—Ç–∏)
        if len(self._theses_history) > self._max_theses_history:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Ç–µ–∑–∏—Å–æ–≤
            recent = list(self._theses_history)[-self._max_theses_history:]
            self._theses_history = set(recent)

    def _process_self_segment(self, wav: np.ndarray) -> None:
        if not self.asr_enable:
            return
        try:
            transcript = self._ensure_asr().transcribe_np(wav, SAMPLE_RATE)
        except Exception as e:  # noqa: BLE001
            logger.exception(f"ASR –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –º–æ–µ–≥–æ –≥–æ–ª–æ—Å–∞: {e}")
            return
        self._handle_self_transcript(transcript)

    # ==== Warmup –º–æ–¥–µ–ª–µ–π ====
    def _warmup_models(self) -> None:
        # ASR: –ø—Ä–æ–≥–Ω–∞—Ç—å –∫–æ—Ä–æ—Ç–∫—É—é —Ç–∏—à–∏–Ω—É
        try:
            if self.asr_enable:
                _ = self._ensure_asr().transcribe_np(np.zeros((SAMPLE_RATE//2,), dtype=np.float32), SAMPLE_RATE)
        except Exception as e:  # noqa: BLE001
            logger.debug(f"ASR warmup failed: {e}")
        # LLM: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (–Ω–µ –æ–∑–≤—É—á–∏–≤–∞—Ç—å)
        try:
            if self.llm_enable and self._llm is None and LLMResponder is not None:
                self._llm = LLMResponder()
            if self.llm_enable and self._llm is not None:
                _ = self._llm.generate("–ü—Ä–∏–≤–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å.")
        except Exception as e:  # noqa: BLE001
            logger.debug(f"LLM warmup failed: {e}")
        # TTS: —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–µ –∞—É–¥–∏–æ –±–µ–∑ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        try:
            if self._tts is not None:
                _ = self._tts.synth("–ì–æ—Ç–æ–≤.")
        except Exception as e:  # noqa: BLE001
            logger.debug(f"TTS warmup failed: {e}")

    # ==== –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ ====
    @staticmethod
    def _extract_questions(text: str) -> List[str]:
        if not text:
            return []
        t = text.strip()
        # –†–∞–∑–æ–±—å—ë–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        parts: List[str] = []
        buf = []
        for ch in t:
            buf.append(ch)
            if ch in "?!.\n":
                seg = "".join(buf).strip()
                if seg:
                    parts.append(seg)
                buf = []
        if buf:
            parts.append("".join(buf).strip())
        res: List[str] = []
        for p in parts:
            if LiveVoiceVerifier._is_question_ru(p):
                res.append(p)
        return res

    @staticmethod
    def _is_question_ru(s: str) -> bool:
        if not s:
            return False
        s2 = s.strip().lower()
        # –Ø–≤–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –≤–æ–ø—Ä–æ—Å–∞
        if s2.endswith("?"):
            return True
        # –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —à–∞–±–ª–æ–Ω—ã
        patterns = [
            r"\b–∫—Ç–æ\b", r"\b—á—Ç–æ\b", r"\b–∫–æ–≥–¥–∞\b", r"\b–≥–¥–µ\b", r"\b–ø–æ—á–µ–º—É\b",
            r"\b–∑–∞—á–µ–º\b", r"\b–∫–∞–∫\b", r"\b–∫–∞–∫–æ–π\b", r"\b–∫–∞–∫–æ–≤–∞\b", r"\b–∫–æ—Ç–æ—Ä\w*\b",
            r"\b—Å–∫–æ–ª—å–∫–æ\b", r"\b–≤ –∫–∞–∫–æ–º –≥–æ–¥—É\b", r"\b–ø—Ä–∞–≤–¥–∞ –ª–∏\b", r"\b–º–æ–∂–Ω–æ –ª–∏\b",
        ]
        for p in patterns:
            try:
                import re
                if re.search(p, s2):
                    return True
            except Exception:
                continue
        return False

    @staticmethod
    def _compute_age(year: int, month: int, day: int) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç –≤ –ø–æ–ª–Ω—ã—Ö –≥–æ–¥–∞—Ö –Ω–∞ —Å–µ–≥–æ–¥–Ω—è."""
        today = date.today()
        age = today.year - year - (1 if (today.month, today.day) < (month, day) else 0)
        return int(age)

    @staticmethod
    def _format_age_ru(age: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Å–∫–ª–æ–Ω–µ–Ω–∏–µ–º: 1 –≥–æ–¥, 2-4 –≥–æ–¥–∞, 5+ –ª–µ—Ç."""
        n = abs(int(age))
        last_two = n % 100
        last = n % 10
        if 11 <= last_two <= 14:
            word = "–ª–µ—Ç"
        elif last == 1:
            word = "–≥–æ–¥"
        elif 2 <= last <= 4:
            word = "–≥–æ–¥–∞"
        else:
            word = "–ª–µ—Ç"
        return f"{n} {word}"

    # ==== –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ ====
    def _filter_questions_by_importance(self, qs: List[str]) -> List[str]:
        if not qs:
            return []
        # –ë—ã—Å—Ç—Ä—ã–π —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∏–ª—å—Ç—Ä: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        if self._question_filter_mode != "gemini":
            keep: List[str] = []
            import re
            keywords = [
                r"\b–≤ –∫–∞–∫–æ–º –≥–æ–¥—É\b",
                r"\b–≥–æ–¥(–∞|—É|–æ–º)?\b",
                r"\b—Å–∫–æ–ª—å–∫–æ\b",
                r"\b–∫—Ç–æ\b",
                r"\b—á—Ç–æ —Ç–∞–∫–æ–µ\b",
                r"\b–æ–ø—Ä–µ–¥–µ–ª–∏(—Ç–µ)?\b",
                r"\b–ø–æ—á–µ–º—É\b",
                r"\b–∫–∞–∫(–∏–º|–æ–π|–∞—è|–æ–µ)? –æ–±—Ä–∞–∑–æ–º\b",
                r"\b–ø–µ—Ä–µ—á–∏—Å–ª–∏(—Ç–µ)?\b",
            ]
            exclude_patterns = [
                r"\b—Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç\b",
                r"\b—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç —Ç–µ–±–µ\b",
                r"\b–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç\b",
                r"\b–∫—Ç–æ —Ç—ã\b",
                r"\b—Ç–µ–±—è –∑–æ–≤—É—Ç\b",
                r"\b—Ç–≤–æ–π –≤–æ–∑—Ä–∞—Å—Ç\b",
                r"\b—á—Ç–æ –¥–µ–ª–∞–µ—à—å\b",
                r"\b–∫–∞–∫ –¥–µ–ª–∞\b",
            ]
            for q in qs:
                q2 = q.strip()
                if len(q2) < self._question_min_len:
                    continue
                if any(re.search(p, q2.lower()) for p in exclude_patterns):
                    continue
                hit = any(re.search(p, q2.lower()) for p in keywords)
                if q2.endswith("?") or hit:
                    keep.append(q2)
            return keep

        # –†–µ–∂–∏–º Gemini: –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        try:
            import json
            from google import genai  # type: ignore
            from google.genai import types  # type: ignore
            import os as _os
            key = _os.getenv("GEMINI_API_KEY")
            if not key:
                return qs  # –±–µ–∑ –∫–ª—é—á–∞ –≤–µ—Ä–Ω—ë–º –∫–∞–∫ –µ—Å—Ç—å
            client = genai.Client(api_key=key)
            sys_instr = (
                "–¢—ã ‚Äî —Ñ–∏–ª—å—Ç—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —ç–∫–∑–∞–º–µ–Ω–∞/—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è. –û—Ü–µ–Ω–∏ –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É:"
                " —ç—Ç–æ –ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Ç–µ–º–µ (–∏—Å—Ç–æ—Ä–∏—è, —Ñ–∞–∫—Ç—ã, —Ç–µ—Ö–Ω–∞—Ä—â–∏–Ω–∞ –∏ —Ç.–ø.)?"
                " –ò–≥–Ω–æ—Ä–∏—Ä—É–π –±—ã—Ç–æ–≤—ã–µ —Ä–µ–ø–ª–∏–∫–∏ –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è. –í–µ—Ä–Ω–∏ JSON –≤–∏–¥–∞ {\"keep\": [0|1,...]}"
            )
            payload = {"items": [s.strip() for s in qs if s.strip()]}
            user_text = json.dumps(payload, ensure_ascii=False)
            cfg = types.GenerateContentConfig(
                system_instruction=sys_instr,
                max_output_tokens=128,
                temperature=0.0,
                thinking_config=types.ThinkingConfig(thinking_budget=0),
            )
            resp = client.models.generate_content(
                model="gemini-flash-lite-latest",
                contents=[types.Content(role="user", parts=[types.Part.from_text(text=user_text)])],
                config=cfg,
            )
            raw = (resp.text or "").strip()
            data = json.loads(raw)
            keep_mask = list(map(int, data.get("keep", [])))
            out: List[str] = []
            for s, k in zip(qs, keep_mask):
                if k:
                    out.append(s)
            return out if out else []
        except Exception as e:  # noqa: BLE001
            logger.debug(f"Gemini question filter failed: {e}")
            return qs

    # ==== –ò–ò-—ç–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∑–∏—Å–æ–≤ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —á—É–∂–æ–π —Ä–µ–ø–ª–∏–∫–∏ ====
    def _extract_theses_ai(self, text: str) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–µ–∑–∏—Å–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.
        –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Gemini —Å —Å—Ç—Ä–æ–≥–∏–º JSON-–∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–º.
        """
        t = (text or "").strip()
        if not t:
            return []
        try:
            import json
            from google import genai  # type: ignore
            from google.genai import types  # type: ignore
            key = os.getenv("GEMINI_API_KEY")
            if not key:
                return []
            client = genai.Client(api_key=key)

            def _call_and_parse(force_json_start: bool = False) -> List[str]:
                sys_instr = (
                    "–í–æ–ø—Ä–æ—Å –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É? –í–µ—Ä–Ω–∏ 2-3 —Ç–µ–∑–∏—Å–∞. –õ–∏—á–Ω–æ–µ? –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫."
                    " JSON: {\"theses\": [\"...\"]}"
                )
                if force_json_start:
                    sys_instr += " –û—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å —Å–∏–º–≤–æ–ª–∞ { –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ JSON."
                prompt = json.dumps({"transcript": t}, ensure_ascii=False)
                cfg = types.GenerateContentConfig(
                    system_instruction=sys_instr,
                    max_output_tokens=64,
                    temperature=0.0,
                    top_p=0.8,
                    thinking_config=types.ThinkingConfig(thinking_budget=0),
                    response_mime_type="application/json",
                )
                resp = client.models.generate_content(
                    model="gemini-flash-lite-latest",
                    contents=[types.Content(role="user", parts=[types.Part.from_text(text=prompt)])],
                    config=cfg,
                )
                raw = (resp.text or "").strip()
                return LiveVoiceVerifier._parse_theses_from_raw(raw, n_max=self._thesis_autogen_batch)

            out = _call_and_parse(False)
            if not out:
                out = _call_and_parse(True)
            return out
        except Exception as e:  # noqa: BLE001
            logger.debug(f"AI theses extraction failed: {e}")
            return []


def enroll_cli(
    profile_path: Path = Path("voice_profile.npz"),
    seconds: float = 20.0,
    min_voiced_seconds: float = 4.0,
    vad_aggr: int = 2,
    min_consec: int = 5,
    flatness_th: float = 0.60,
    # VAD backend
    vad_backend: str = "webrtc",
    silero_vad_threshold: float = 0.5,
    silero_vad_window_ms: int = 100,
    # ASR –≤ —ç–Ω—Ä–æ–ª–ª–º–µ–Ω—Ç–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –æ—Å—Ç–∞–≤–∏–º –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Å–∏–≥–Ω–∞—Ç—É—Ä—É –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
    asr: bool = False,
    asr_model: str = "large-v3-turbo",
    asr_lang: Optional[str] = None,
    asr_device: Optional[str] = None,
    asr_compute: Optional[str] = None,
    # –¢–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ—Ñ–∏–ª—è
    read_script: Optional[str] = None,
    read_script_file: Optional[Path] = None,
) -> None:
    setup_logging()
    verifier = LiveVoiceVerifier(
        vad_backend=vad_backend,
        silero_vad_threshold=silero_vad_threshold,
        silero_vad_window_ms=silero_vad_window_ms,
        vad_aggressiveness=vad_aggr,
        min_consec_speech_frames=min_consec,
        flatness_reject_threshold=flatness_th,
    )

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ç–µ–∫—Å—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    script_text: Optional[str] = None
    if read_script_file is not None:
        try:
            script_text = Path(read_script_file).read_text(encoding="utf-8")
        except Exception as e:  # noqa: BLE001
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Å–∫—Ä–∏–ø—Ç–∞ {read_script_file}: {e}")
            script_text = None
    if not script_text and read_script:
        script_text = read_script.strip()
    paragraphs = _split_paragraphs(script_text or "")
    if not paragraphs:
        paragraphs = DEFAULT_ENROLL_PARAGRAPHS.copy()

    selected_idx = 0
    if len(paragraphs) > 1:
        print("–í—ã–±–µ—Ä–∏—Ç–µ –∞–±–∑–∞—Ü –¥–ª—è —á—Ç–µ–Ω–∏—è (–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω –Ω–∏–∂–µ):")
        for idx, para in enumerate(paragraphs, 1):
            preview = para.replace("\n", " ")
            if len(preview) > 90:
                preview = preview[:87] + "‚Ä¶"
            print(f"  {idx}) {preview}")
        choice = input("–ù–æ–º–µ—Ä –∞–±–∑–∞—Ü–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1): ").strip()
        try:
            parsed = int(choice)
            if 1 <= parsed <= len(paragraphs):
                selected_idx = parsed - 1
            else:
                logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä {choice}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±–∑–∞—Ü 1")
        except Exception:
            if choice:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–≤–æ–¥ '{choice}', –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±–∑–∞—Ü 1")

    script_to_read = paragraphs[selected_idx]
    logger.info(
        "–î–ª—è –ø—Ä–æ—Ñ–∏–ª—è –≤—ã–±—Ä–∞–Ω –∞–±–∑–∞—Ü {idx} ({words} —Å–ª–æ–≤)",
        idx=selected_idx + 1,
        words=len(script_to_read.split()),
    )

    print("\n–ß–∏—Ç–∞–π—Ç–µ –∞–±–∑–∞—Ü ‚Ññ{0}:\n{1}\n".format(selected_idx + 1, script_to_read))
    print("–°–æ–≤–µ—Ç: –≥–æ–≤–æ—Ä–∏—Ç–µ —Ä–∞–∑–º–µ—Ä–µ–Ω–Ω–æ –∏ —Å–¥–µ–ª–∞–π—Ç–µ –ø–∞—É–∑—É –æ–∫–æ–ª–æ —Å–µ–∫—É–Ω–¥—ã –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —á—Ç–µ–Ω–∏—è.")
    try:
        input("–ù–∞–∂–º–∏—Ç–µ Enter, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å‚Ä¶")
    except Exception:
        pass

    words = len(script_to_read.split())
    min_read_seconds = words / 2.5 + 2.0  # –∫–æ–º—Ñ–æ—Ä—Ç–Ω—ã–π —Ç–µ–º–ø —Ä–µ—á–∏ ~150 —Å–ª–æ–≤/–º–∏–Ω
    record_seconds = max(seconds, min_read_seconds)
    logger.info(
        "–°—Ç–∞—Ä—Ç –∑–∞–ø–∏—Å–∏ –ø—Ä–æ—Ñ–∏–ª—è: —Ü–µ–ª–µ–≤–æ–π –ª–∏–º–∏—Ç {record_seconds:.1f}s, –º–∏–Ω–∏–º—É–º –æ–∑–≤—É—á–µ–Ω–Ω–æ–π —Ä–µ—á–∏ {min_voiced_seconds:.1f}s",
        record_seconds=record_seconds,
        min_voiced_seconds=min_voiced_seconds,
    )

    wav = verifier._collect_enrollment_audio(
        seconds=record_seconds,
        min_voiced_seconds=min_voiced_seconds,
        silence_stop_sec=1.4,
    )
    emb = verifier.embedding_from_waveform(wav)
    profile = VoiceProfile(embedding=emb)
    profile.save(profile_path)
    logger.info(f"–ü—Ä–æ—Ñ–∏–ª—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {profile_path}")



def live_cli(
    profile_path: Path = Path("voice_profile.npz"),
    threshold: float = 0.30,
    vad_aggr: int = 2,
    min_consec: int = 5,
    flatness_th: float = 0.60,
    min_segment_ms: int = 1500,
    max_silence_ms: int = 400,
    pre_roll_ms: int = 160,
    # VAD backend
    vad_backend: str = "webrtc",
    silero_vad_threshold: float = 0.5,
    silero_vad_window_ms: int = 100,
    # ASR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    asr: bool = False,
    asr_model: str = "large-v3-turbo",
    asr_lang: Optional[str] = None,
    asr_device: Optional[str] = None,
    asr_compute: Optional[str] = None,
    # LLM
    llm: bool = False,
    run_seconds: float = 0.0,
) -> None:
    setup_logging()
    verifier = LiveVoiceVerifier(
        threshold=threshold,
        vad_backend=vad_backend,
        silero_vad_threshold=silero_vad_threshold,
        silero_vad_window_ms=silero_vad_window_ms,
        vad_aggressiveness=vad_aggr,
        min_consec_speech_frames=min_consec,
        flatness_reject_threshold=flatness_th,
        asr_enable=asr,
        asr_model_size=asr_model,
        asr_language=asr_lang,
        asr_device=asr_device,
        asr_compute_type=asr_compute,
        llm_enable=llm,
    )
    profile = VoiceProfile.load(profile_path)
    if profile is None:
        logger.error(
            f"–ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {profile_path}. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É enroll."
        )
        sys.exit(1)
    verifier.live_verify(
        profile,
        min_segment_ms=min_segment_ms,
        max_silence_ms=max_silence_ms,
        pre_roll_ms=pre_roll_ms,
        run_seconds=run_seconds,
    )


__all__ = [
    "LiveVoiceVerifier",
    "VoiceProfile",
    "enroll_cli",
    "live_cli",
]
