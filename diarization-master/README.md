# diarization: лайв-распознавание «свой/чужой» + ASR + короткий LLM-ответ с озвучкой

Проект для лайв-обработки аудио с микрофона:

- «Свой/чужой» по голосу с использованием эмбеддингов ECAPA (`speechbrain/spkrec-ecapa-voxceleb`).
- Детекция речи WebRTC VAD + фильтрация шумов (минимум подряд речевых кадров, спектральная плоскостность).
- Для «чужого» голоса: транскрибация сегмента через `faster-whisper` c анти-галлюциногенным промптом и постфильтрами.
- Опционально: краткий ответ LLM (по умолчанию Qwen/Qwen2.5-1.5B-Instruct) и мгновенная озвучка ответа через Silero TTS.

Основные файлы:

- `main.py` — CLI: команды `enroll` (создать голосовой профиль) и `live` (лайв-верификация/ASR/LLM/TTS).
- `live_recognizer.py` — класс `LiveVoiceVerifier`: VAD, сегментация, эмбеддинги, сравнение, запуск ASR/LLM/TTS в лайве.
- `asr_transcriber.py` — модуль ASR на `faster-whisper` с `initial_prompt`, отключением переноса контекста и бан-листом.
- `llm_answer.py` — модуль LLM (по умолчанию Qwen/Qwen2.5-1.5B-Instruct) для коротких ответов.
- `tts_silero.py` — модуль озвучки ответов LLM через Silero TTS.

## Требования

- Python 3.12+
- Рекомендуется менеджер `uv` (используем `pyproject.toml` и `uv.lock`).
- Микрофон с поддержкой 16 kHz, mono.
- Опционально CUDA/GPU для ускорения ASR/LLM (при проблемах с CUDA у ASR есть авто-фоллбэк на CPU).
- Для загрузки некоторых LLM или ускорения — аккаунт Hugging Face (при необходимости `huggingface-cli login`).

## Установка

1) Установить зависимости (через uv):

    ```bash
    uv sync
    ```

2) Проверить запуск CLI:

    ```bash
    uv run python main.py --help
    ```

## Быстрый старт

### 1. Энроллмент: записать ваш голосовой профиль

```bash
uv run python main.py enroll \
--seconds 8 \
--vad-aggr 3 \
--min-consec 7 \
--flatness-th 0.55
```

- Это запишет 8 секунд, оставив только озвученные фрагменты и сохранит профиль в `voice_profile.npz`.
- Параметры VAD/шумоподавления можно не указывать — приведены строгие настройки как пример.

### 2. Лайв-режим: «свой/чужой», ASR чужих, LLM-ответ и его озвучка

```bash
uv run python main.py live \
--asr --asr-lang ru \
--llm \
--threshold 0.75 \
--vad-aggr 3 \
--min-consec 7 \
--flatness-th 0.55
```

Что будет происходить:

- Идёт непрерывный захват аудио, VAD сегментирует речь, фильтр плоскостности отбрасывает шумоподобные куски.
- Для каждого речевого сегмента считается эмбеддинг и сравнение с профилем:
  - Если косинусная дистанция ≤ `threshold` — печатает «мой голос».
  - Иначе — «незнакомый голос».
- Если включён `--asr`, незнакомый сегмент транскрибируется через `faster-whisper` (RU промпт и фильтры от галлюцинаций включены).
- Если включён `--llm`, на текст от ASR даётся краткий ответ LLM и он сразу озвучивается через Silero TTS.
- На время проигрывания TTS вход микрофона подавляется, чтобы избежать самоподхвата.

## Полезные опции CLI

Команда `enroll`:

- `--profile` — путь к профилю (по умолчанию `voice_profile.npz`).
- `--seconds` — длительность записи для профиля (сек).
- `--vad-aggr` — агрессивность WebRTC VAD [0..3] (выше — строже к шумам).
- `--min-consec` — минимум подряд речевых кадров (20 мс каждый) до старта сегмента.
- `--flatness-th` — порог спектральной плоскостности (меньше — строже к шумам).

Команда `live`:

- Базовые:
  - `--profile` — путь к профилю (по умолчанию `voice_profile.npz`).
  - `--threshold` — порог косинусной дистанции «свой/чужой» (≤ — «мой голос»).
  - `--min-segment-ms` — минимальная длительность речевого сегмента.
  - `--max-silence-ms` — пауза (мс) до завершения сегмента.
- Шумоподавление:
  - `--vad-aggr`, `--min-consec`, `--flatness-th` — как в `enroll`.
- ASR:
  - `--asr` — включить транскрибацию незнакомых сегментов.
  - `--asr-model` — размер модели `faster-whisper` (например, `small`).
  - `--asr-lang` — язык (например, `ru`).
  - `--asr-device` — `cuda|cpu` (по умолчанию авто). При ошибке CUDA производится авто-фоллбэк на CPU.
  - `--asr-compute` — тип вычислений (`float16|int8` и др.).
- LLM:
  - `--llm` — включить краткий ответ LLM (по умолчанию используется модель из `llm_answer.py`).

Примеры настроек

- Строже к шумам:

```bash
    --vad-aggr 3 --min-consec 8 --flatness-th 0.50
```

- Мягче к шумам (если речь часто «обрывается»):

```bash
    --vad-aggr 2 --min-consec 5 --flatness-th 0.65
```

## Архитектура и детали

- VAD — `webrtcvad` с 20 мс окнами, сегмент считается завершённым после `max_silence_ms` паузы.
- Фильтр шумов — медианная спектральная плоскостность в полосе 80–4000 Гц; сегменты с плоскостностью выше порога отбрасываются.
- Эмбеддинги — `speechbrain/spkrec-ecapa-voxceleb`, верификация по косинусной дистанции.
- ASR — `faster-whisper`:
  - `initial_prompt` (для `ru` предзадан анти-галлюциногенный текст),
  - `condition_on_previous_text=False`, `temperature=0.0`,
  - постобработка: бан-лист ключевых слов/фраз, дедупликация подряд идущих слов, отсечение слишком коротких результатов.
- LLM — по умолчанию `Qwen/Qwen2.5-1.5B-Instruct` (можно заменить в `llm_answer.py`),
  - системный промпт на короткие русские ответы,
  - генерация с небольшим `temperature` и `top_p`.
- TTS — Silero `v4_ru` (голос `eugene`) для мгновенной озвучки ответа LLM; вход подавляется на время проигрывания.

## Частые проблемы и решения

- Ошибка cuDNN при ASR на CUDA: `Unable to load libcudnn…` — включится авто-фоллбэк на CPU. Можно явно указать `--asr-device cpu`.
- Модель LLM не грузится/нет доступа — выполните `huggingface-cli login` или используйте открытую модель. По умолчанию стоит Qwen 1.5B Instruct.
- Слишком много ложных срабатываний на шумы — увеличьте `--min-consec`, уменьшите `--flatness-th`, поставьте `--vad-aggr 3`.
- Микрофон — используется 16 kHz mono. Если устройство не поддерживает 16 kHz, скажите — можно добавить ресэмплинг.

## Структура проекта

```tree
.
├── asr_transcriber.py     # ASR (faster-whisper) + фильтрация
├── live_recognizer.py     # лайв-пайплайн: VAD/сегменты/эмбеддинги/ASR/LLM/TTS
├── llm_answer.py          # LLM (Qwen 1.5B Instruct по умолчанию)
├── main.py                # CLI: enroll, live
├── pyproject.toml         # зависимости (uv)
├── tts_silero.py          # Silero TTS для озвучки ответов LLM
└── uv.lock
```

## Лицензии и модели

- Убедитесь, что использование выбранных моделей соответствует их лицензиям и политике Hugging Face.

Если нужны дополнительные флаги (выбор модели LLM/TTS, системный промпт, список бан-слов и т.п.), дайте знать — быстро добавлю.

## Запуск

### Энроллмент

```bash
uv run python main.py enroll --seconds 8 --vad-aggr 3 --min-consec 7 --flatness-th 0.55
```

### Лайв-режим

```bash
uv run python main.py live --asr --asr-model small --asr-lang ru --llm
```
